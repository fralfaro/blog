[
  {
    "objectID": "posts/2022/2022-03-16-polars.html",
    "href": "posts/2022/2022-03-16-polars.html",
    "title": "Polars",
    "section": "",
    "text": "Polars es una librerÃ­a de DataFrames increÃ­blemente rÃ¡pida implementada en Rust utilizando Arrow Columnar Format de Apache como modelo de memoria.\n\nLazy | eager execution\nMulti-threaded\nSIMD (Single Instruction, Multiple Data)\nQuery optimization\nPowerful expression API\nRust | Python\n\nEsta secciÃ³n tiene como objetivos presentarle Polars a travÃ©s de ejemplos y comparÃ¡ndolo con otras soluciones.\n\nNota: Si usted no esta familiarizado con la manipulaciÃ³n de datos en Python, se recomienda partir leyendo sobre la librerÃ­a de Pandas. TambiÃ©n, se deja como referencia mi curso de ManipulaciÃ³n de Datos.\n\n\n\n\n\n\nPara instalar Polars, necesitarÃ¡ usar la lÃ­nea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge polars\nDe lo contrario, puede instalar con pip:\npip install polars\n\nNota: Todos los binarios estÃ¡n preconstruidos para Python v3.6+.\n\n\n\n\n\nPolars es muy rÃ¡pido y, de hecho, es una de las mejores soluciones disponibles. Tomemos como referencia db-benchmark de h2oai. Esta pÃ¡gina tiene como objetivo comparar varias herramientas similares a bases de datos populares en la ciencia de datos de cÃ³digo abierto. Se ejecuta regularmente con las Ãºltimas versiones de estos paquetes y se actualiza automÃ¡ticamente.\nTambiÃ©n se incluye la sintaxis que se cronometra junto con el tiempo. De esta manera, puede ver de inmediato si estÃ¡ realizando estas tareas o no, y si las diferencias de tiempo le importan o no. Una diferencia de 10x puede ser irrelevante si eso es solo 1s frente a 0,1s en el tamaÃ±o de sus datos.\nA modo de ejemplo, veamos algunos ejemplos de performances de distintas librerÃ­as para ejecutar distintos tipos de tareas sobre datasets con distintos tamaÃ±os. Para el caso de tareas bÃ¡sicas sobre un dataset de 50 GB, Polars supera a librerÃ­as espacializadas en distribuciÃ³n de Dataframes como Spark (143 segundos vs 568 segundos). Por otro lado, librerÃ­as conocidas en Python como Pandas o Dask se tiene el problema de out of memory.\n\n\n\n\nPolars tiene un poderoso concepto llamado expresiones. Las expresiones polares se pueden usar en varios contextos y son un mapeo funcional de Fn(Series) -&gt; Series, lo que significa que tienen Series como entrada y Series como salida. Al observar esta definiciÃ³n funcional, podemos ver que la salida de un Expr tambiÃ©n puede servir como entrada de un Expr.\nEso puede sonar un poco extraÃ±o, asÃ­ que vamos a dar un ejemplo.\nLa siguiente es una expresiÃ³n:\npl.col(\"foo\").sort().head(2)\nEl fragmento anterior dice seleccionar la columna \"foo\", luego ordenar esta columna y luego tomar los primeros 2 valores de la salida ordenada. El poder de las expresiones es que cada expresiÃ³n produce una nueva expresiÃ³n y que se pueden canalizar juntas. Puede ejecutar una expresiÃ³n pasÃ¡ndola en uno de los contextos de ejecuciÃ³n polares. AquÃ­ ejecutamos dos expresiones ejecutando df.select:\ndf.select([\n     pl.col(\"foo\").sort().head(2),\n     pl.col(\"barra\").filter(pl.col(\"foo\") == 1).sum()\n])\nTodas las expresiones se ejecutan en paralelo. (Tenga en cuenta que dentro de una expresiÃ³n puede haber mÃ¡s paralelizaciÃ³n).\n\n\nEn esta secciÃ³n veremos algunos ejemplos, pero primero vamos a crear un conjunto de datos:\n\nimport polars as pl\nimport numpy as np\n\n\nnp.random.seed(12)\n\ndf = pl.DataFrame(\n    {\n        \"nrs\": [1, 2, 3, None, 5],\n        \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", None],\n        \"random\": np.random.rand(5),\n        \"groups\": [\"A\", \"A\", \"B\", \"C\", \"B\"],\n    }\n)\nprint(df)\n\nshape: (5, 4)\nâ”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ nrs  â”† names â”† random   â”† groups â”‚\nâ”‚ ---  â”† ---   â”† ---      â”† ---    â”‚\nâ”‚ i64  â”† str   â”† f64      â”† str    â”‚\nâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\nâ”‚ 1    â”† foo   â”† 0.154163 â”† A      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 2    â”† ham   â”† 0.74     â”† A      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 3    â”† spam  â”† 0.263315 â”† B      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ null â”† egg   â”† 0.533739 â”† C      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 5    â”† null  â”† 0.014575 â”† B      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\nPuedes hacer mucho con las expresiones, veamos algunos ejemplos:\n\n\nPodemos contar los valores Ãºnicos en una columna. Tenga en cuenta que estamos creando el mismo resultado de diferentes maneras. Para no tener nombres de columna duplicados en el DataFrame, usamos una expresiÃ³n de alias, que cambia el nombre de una expresiÃ³n.\n\nout = df.select(\n    [\n        pl.col(\"names\").n_unique().alias(\"unique_names_1\"),\n        pl.col(\"names\").unique().count().alias(\"unique_names_2\"),\n    ]\n)\nprint(out)\n\nshape: (1, 2)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ unique_names_1 â”† unique_names_2 â”‚\nâ”‚ ---            â”† ---            â”‚\nâ”‚ u32            â”† u32            â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ 5              â”† 5              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\n\nPodemos hacer varias agregaciones. A continuaciÃ³n mostramos algunas de ellas, pero hay mÃ¡s, como median, mean, first, etc.\n\nout = df.select(\n    [\n        pl.sum(\"random\").alias(\"sum\"),\n        pl.min(\"random\").alias(\"min\"),\n        pl.max(\"random\").alias(\"max\"),\n        pl.col(\"random\").max().alias(\"other_max\"),\n        pl.std(\"random\").alias(\"std dev\"),\n        pl.var(\"random\").alias(\"variance\"),\n    ]\n)\nprint(out)\n\nshape: (1, 6)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ sum      â”† min      â”† max  â”† other_max â”† std dev  â”† variance â”‚\nâ”‚ ---      â”† ---      â”† ---  â”† ---       â”† ---      â”† ---      â”‚\nâ”‚ f64      â”† f64      â”† f64  â”† f64       â”† f64      â”† f64      â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ 1.705842 â”† 0.014575 â”† 0.74 â”† 0.74      â”† 0.293209 â”† 0.085971 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nTambiÃ©n podemos hacer cosas bastante complejas. En el siguiente fragmento, contamos todos los nombres que terminan con la cadena \"am\".\n\nout = df.select(\n    [\n        pl.col(\"names\").filter(pl.col(\"names\").str.contains(r\"am$\")).count(),\n    ]\n)\nprint(out)\n\nshape: (1, 1)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ names â”‚\nâ”‚ ---   â”‚\nâ”‚ u32   â”‚\nâ•â•â•â•â•â•â•â•â•¡\nâ”‚ 2     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nEn el ejemplo a continuaciÃ³n, usamos un condicional para crear una nueva expresiÃ³n when -&gt; then -&gt; otherwise.\nLa funciÃ³n when() requiere una expresiÃ³n de predicado (y, por lo tanto, conduce a una serie booleana), luego espera una expresiÃ³n que se usarÃ¡ en caso de que el predicado se evalÃºe como verdadero y, de lo contrario, espera una expresiÃ³n que se usarÃ¡ en caso de que el predicado se evalÃºe.\nTenga en cuenta que puede pasar cualquier expresiÃ³n, o simplemente expresiones base como pl.col(\"foo\"), pl.lit(3), pl.lit(\"bar\"), etc.\nFinalmente, multiplicamos esto con el resultado de una expresiÃ³n de suma.\n\nout = df.select(\n    [\n        pl.when(pl.col(\"random\") &gt; 0.5).then(0).otherwise(pl.col(\"random\")) * pl.sum(\"nrs\"),\n    ]\n)\nprint(out)\n\nshape: (5, 1)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ literal  â”‚\nâ”‚ ---      â”‚\nâ”‚ f64      â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ 1.695791 â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 0.0      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 2.896465 â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 0.0      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 0.160325 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nUna expresiÃ³n polar tambiÃ©n puede hacer un GROUPBY, AGGREGATION y JOIN implÃ­citos en una sola expresiÃ³n.\nEn los ejemplos a continuaciÃ³n, hacemos un GROUPBY sobre \"groups\" y AGREGATE SUM de \"random\", y en la siguiente expresiÃ³n GROUPBY OVER \"names\" y AGREGATE una lista de \"random\". Estas funciones de ventana se pueden combinar con otras expresiones y son una forma eficaz de determinar estadÃ­sticas de grupo. Vea mÃ¡s expresiones en el siguiente link.\n\nout = df[\n    [\n        pl.col(\"*\"),  # select all\n        pl.col(\"random\").sum().over(\"groups\").alias(\"sum[random]/groups\"),\n        pl.col(\"random\").list().over(\"names\").alias(\"random/name\"),\n    ]\n]\nprint(out)\n\nshape: (5, 6)\nâ”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ nrs  â”† names â”† random   â”† groups â”† sum[random]/groups â”† random/name â”‚\nâ”‚ ---  â”† ---   â”† ---      â”† ---    â”† ---                â”† ---         â”‚\nâ”‚ i64  â”† str   â”† f64      â”† str    â”† f64                â”† list [f64]  â”‚\nâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ 1    â”† foo   â”† 0.154163 â”† A      â”† 0.894213           â”† [0.154163]  â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 2    â”† ham   â”† 0.74     â”† A      â”† 0.894213           â”† [0.74]      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 3    â”† spam  â”† 0.263315 â”† B      â”† 0.2778             â”† [0.263315]  â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ null â”† egg   â”† 0.533739 â”† C      â”† 0.533739           â”† [0.533739]  â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 5    â”† null  â”† 0.014575 â”† B      â”† 0.2778             â”† [0.014575]  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\n\n\n\nUna de las formas mÃ¡s eficientes de procesar datos tabulares es paralelizar su procesamiento a travÃ©s del enfoque â€œdividir-aplicar-combinarâ€. Esta operaciÃ³n es el nÃºcleo de la implementaciÃ³n del agrupamiento de Polars, lo que le permite lograr operaciones ultrarrÃ¡pidas. MÃ¡s especÃ­ficamente, las fases de â€œdivisiÃ³nâ€ y â€œaplicaciÃ³nâ€ se ejecutan de forma multiproceso.\nUna operaciÃ³n de agrupaciÃ³n simple se toma a continuaciÃ³n como ejemplo para ilustrar este enfoque:\n\nPara las operaciones hash realizadas durante la fase de â€œdivisiÃ³nâ€, Polars utiliza un enfoque sin bloqueo de subprocesos mÃºltiples que se ilustra en el siguiente esquema:\n\nÂ¡Esta paralelizaciÃ³n permite que las operaciones de agrupaciÃ³n y uniÃ³n (por ejemplo) sean increÃ­blemente rÃ¡pidas!\n\n\n\nTodos hemos escuchado que Python es lento y â€œno escalaâ€. AdemÃ¡s de la sobrecarga de ejecutar el cÃ³digo de bytes â€œlentoâ€, Python debe permanecer dentro de las restricciones del Global interpreter lock (GIL). Esto significa que si se usa la operaciÃ³n lambda o una funciÃ³n de Python personalizada para aplicar durante una fase de paralelizaciÃ³n, la velocidad de Polars se limita al ejecutar el cÃ³digo de Python, lo que evita que varios subprocesos ejecuten la funciÃ³n.\nTodo esto se siente terriblemente limitante, especialmente porque a menudo necesitamos esos lambda en un paso .groupby(), por ejemplo. Este enfoque aÃºn es compatible con Polars, pero teniendo en cuenta el cÃ³digo de bytes Y el precio GIL deben pagarse.\nPara mitigar esto, Polars implementa una poderosa sintaxis definida no solo en su lazy, sino tambiÃ©n en su uso eager.\n\n\n\nEn la introducciÃ³n de la pÃ¡gina anterior, discutimos que el uso de funciones personalizadas de Python eliminaba la paralelizaciÃ³n y que podemos usar las expresiones de la API diferida para mitigar esto. Echemos un vistazo a lo que eso significa.\nComencemos con el conjunto de datos simple del congreso de EE. UU.\n\nimport polars as pl\n\ndataset = pl.read_csv(\"legislators-current.csv\")\ndataset = dataset.with_column(pl.col(\"birthday\").str.strptime(pl.Date))\nprint(dataset.head())\n\nshape: (5, 34)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ last_name â”† first_name â”† middle_name â”† suffix â”† ... â”† ballotpedia_id â”† washington_post_id â”† icpsr_id â”† wikipedia_id   â”‚\nâ”‚ ---       â”† ---        â”† ---         â”† ---    â”†     â”† ---            â”† ---                â”† ---      â”† ---            â”‚\nâ”‚ str       â”† str        â”† str         â”† str    â”†     â”† str            â”† str                â”† i64      â”† str            â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ Brown     â”† Sherrod    â”† null        â”† null   â”† ... â”† Sherrod Brown  â”† null               â”† 29389    â”† Sherrod Brown  â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Cantwell  â”† Maria      â”† null        â”† null   â”† ... â”† Maria Cantwell â”† null               â”† 39310    â”† Maria Cantwell â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Cardin    â”† Benjamin   â”† L.          â”† null   â”† ... â”† Ben Cardin     â”† null               â”† 15408    â”† Ben Cardin     â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Carper    â”† Thomas     â”† Richard     â”† null   â”† ... â”† Tom Carper     â”† null               â”† 15015    â”† Tom Carper     â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Casey     â”† Robert     â”† P.          â”† Jr.    â”† ... â”† Bob Casey, Jr. â”† null               â”† 40703    â”† Bob Casey Jr.  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nPuede combinar fÃ¡cilmente diferentes agregaciones agregando varias expresiones en una lista. No hay un lÃ­mite superior en el nÃºmero de agregaciones que puede hacer y puede hacer cualquier combinaciÃ³n que desee. En el fragmento a continuaciÃ³n, hacemos las siguientes agregaciones:\nPor grupo \"first_name\":\n\ncuente el nÃºmero de filas en el grupo:\n\nforma abreviada: pl.count(\"party\")\nforma completa: pl.col(\"party\").count()\n\nagregue el grupo de valores de gÃ©nero a una lista:\n\nforma completa: pl.col(\"gender\").list()\n\nobtenga el primer valor de la columna \"last_name\" en el grupo:\n\nforma abreviada: pl.primero(\"last_name\")\nforma completa: pl.col(\"last_name\").first()\n\n\nAdemÃ¡s de la agregaciÃ³n, clasificamos inmediatamente el resultado y lo limitamos a los 5 principales para que tengamos un buen resumen general.\n\nq = (\n    dataset.lazy()\n    .groupby(\"first_name\")\n    .agg(\n        [\n            pl.count(),\n            pl.col(\"gender\").list(),\n            pl.first(\"last_name\"),\n        ]\n    )\n    .sort(\"count\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 4)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ first_name â”† count â”† gender              â”† last_name â”‚\nâ”‚ ---        â”† ---   â”† ---                 â”† ---       â”‚\nâ”‚ str        â”† u32   â”† list [str]          â”† str       â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ John       â”† 19    â”† [\"M\", \"M\", ... \"M\"] â”† Barrasso  â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Mike       â”† 13    â”† [\"M\", \"M\", ... \"M\"] â”† Kelly     â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Michael    â”† 11    â”† [\"M\", \"M\", ... \"M\"] â”† Bennet    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ David      â”† 11    â”† [\"M\", \"M\", ... \"M\"] â”† Cicilline â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ James      â”† 9     â”† [\"M\", \"M\", ... \"M\"] â”† Inhofe    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nOk, eso fue bastante fÃ¡cil, Â¿verdad? Subamos un nivel. Digamos que queremos saber cuÃ¡ntos delegados de un â€œestadoâ€ (state) son administraciÃ³n â€œDemocratâ€ o â€œRepublicanâ€. PodrÃ­amos consultarlo directamente en la agregaciÃ³n sin la necesidad de lambda o arreglar el DataFrame.\n\nq = (\n    dataset.lazy()\n    .groupby(\"state\")\n    .agg(\n        [\n            (pl.col(\"party\") == \"Democrat\").sum().alias(\"demo\"),\n            (pl.col(\"party\") == \"Republican\").sum().alias(\"repu\"),\n        ]\n    )\n    .sort(\"demo\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 3)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”\nâ”‚ state â”† demo â”† repu â”‚\nâ”‚ ---   â”† ---  â”† ---  â”‚\nâ”‚ str   â”† u32  â”† u32  â”‚\nâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•¡\nâ”‚ CA    â”† 44   â”† 10   â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ NY    â”† 21   â”† 8    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ IL    â”† 15   â”† 5    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ TX    â”† 13   â”† 25   â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ NJ    â”† 12   â”† 2    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜\n\n\nPor supuesto, tambiÃ©n se podrÃ­a hacer algo similar con un GROUPBY anidado, pero eso no me permitirÃ­a mostrar estas caracterÃ­sticas agradables. ğŸ˜‰\n\nq = (\n    dataset.lazy()\n    .groupby([\"state\", \"party\"])\n    .agg([pl.count(\"party\").alias(\"count\")])\n    .filter((pl.col(\"party\") == \"Democrat\") | (pl.col(\"party\") == \"Republican\"))\n    .sort(\"count\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 3)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ state â”† party      â”† count â”‚\nâ”‚ ---   â”† ---        â”† ---   â”‚\nâ”‚ str   â”† str        â”† u32   â”‚\nâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\nâ”‚ CA    â”† Democrat   â”† 44    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ TX    â”† Republican â”† 25    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ NY    â”† Democrat   â”† 21    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ FL    â”† Republican â”† 18    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ IL    â”† Democrat   â”† 15    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nTambiÃ©n podemos filtrar los grupos. Digamos que queremos calcular una media por grupo, pero no queremos incluir todos los valores de ese grupo y tampoco queremos filtrar las filas del DataFrame (porque necesitamos esas filas para otra agregaciÃ³n).\nEn el siguiente ejemplo, mostramos cÃ³mo se puede hacer eso. Tenga en cuenta que podemos hacer funciones de Python para mayor claridad. Estas funciones no nos cuestan nada. Esto se debe a que solo creamos Polars expression, no aplicamos una funciÃ³n personalizada sobre Series durante el tiempo de ejecuciÃ³n de la consulta.\n\nfrom datetime import date\n\ndef compute_age() -&gt; pl.Expr:\n    return date(2021, 1, 1).year - pl.col(\"birthday\").dt.year()\n\n\ndef avg_birthday(gender: str) -&gt; pl.Expr:\n    return compute_age().filter(pl.col(\"gender\") == gender).mean().alias(f\"avg {gender} birthday\")\n\n\nq = (\n    dataset.lazy()\n    .groupby([\"state\"])\n    .agg(\n        [\n            avg_birthday(\"M\"),\n            avg_birthday(\"F\"),\n            (pl.col(\"gender\") == \"M\").sum().alias(\"# male\"),\n            (pl.col(\"gender\") == \"F\").sum().alias(\"# female\"),\n        ]\n    )\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 5)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ state â”† avg M birthday â”† avg F birthday â”† # male â”† # female â”‚\nâ”‚ ---   â”† ---            â”† ---            â”† ---    â”† ---      â”‚\nâ”‚ str   â”† f64            â”† f64            â”† u32    â”† u32      â”‚\nâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ MS    â”† 60.0           â”† 62.0           â”† 5      â”† 1        â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ NV    â”† 55.5           â”† 61.75          â”† 2      â”† 4        â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ KS    â”† 54.2           â”† 41.0           â”† 5      â”† 1        â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ IN    â”† 55.0           â”† 50.5           â”† 9      â”† 2        â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ IL    â”† 60.923077      â”† 58.428571      â”† 13     â”† 7        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nA menudo veo que se ordena un DataFrame con el Ãºnico propÃ³sito de ordenar durante la operaciÃ³n GROUPBY. Digamos que queremos obtener los nombres de los polÃ­ticos mÃ¡s antiguos y mÃ¡s jÃ³venes (no es que todavÃ­a estÃ©n vivos) por estado, podrÃ­amos ORDENAR y AGRUPAR.\n\ndef get_person() -&gt; pl.Expr:\n    return pl.col(\"first_name\") + pl.lit(\" \") + pl.col(\"last_name\")\n\n\nq = (\n    dataset.lazy()\n    .sort(\"birthday\")\n    .groupby([\"state\"])\n    .agg(\n        [\n            get_person().first().alias(\"youngest\"),\n            get_person().last().alias(\"oldest\"),\n        ]\n    )\n    .limit(5)\n)\n\ndf = q.collect()\n\nprint(df)\n\nshape: (5, 3)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ state â”† youngest                 â”† oldest                   â”‚\nâ”‚ ---   â”† ---                      â”† ---                      â”‚\nâ”‚ str   â”† str                      â”† str                      â”‚\nâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ PR    â”† Jenniffer GonzÃ¡lez-ColÃ³n â”† Jenniffer GonzÃ¡lez-ColÃ³n â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ ND    â”† John Hoeven              â”† Kelly Armstrong          â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ KY    â”† Harold Rogers            â”† Garland Barr             â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ NM    â”† Teresa Leger Fernandez   â”† Melanie Stansbury        â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ OR    â”† Peter DeFazio            â”† Jeff Merkley             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\n\n\nPolars - User Guide\nPolars - Github"
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#introducciÃ³n",
    "href": "posts/2022/2022-03-16-polars.html#introducciÃ³n",
    "title": "Polars",
    "section": "",
    "text": "Polars es una librerÃ­a de DataFrames increÃ­blemente rÃ¡pida implementada en Rust utilizando Arrow Columnar Format de Apache como modelo de memoria.\n\nLazy | eager execution\nMulti-threaded\nSIMD (Single Instruction, Multiple Data)\nQuery optimization\nPowerful expression API\nRust | Python\n\nEsta secciÃ³n tiene como objetivos presentarle Polars a travÃ©s de ejemplos y comparÃ¡ndolo con otras soluciones.\n\nNota: Si usted no esta familiarizado con la manipulaciÃ³n de datos en Python, se recomienda partir leyendo sobre la librerÃ­a de Pandas. TambiÃ©n, se deja como referencia mi curso de ManipulaciÃ³n de Datos."
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#primeros-pasos",
    "href": "posts/2022/2022-03-16-polars.html#primeros-pasos",
    "title": "Polars",
    "section": "",
    "text": "Para instalar Polars, necesitarÃ¡ usar la lÃ­nea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge polars\nDe lo contrario, puede instalar con pip:\npip install polars\n\nNota: Todos los binarios estÃ¡n preconstruidos para Python v3.6+."
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#rendimiento",
    "href": "posts/2022/2022-03-16-polars.html#rendimiento",
    "title": "Polars",
    "section": "",
    "text": "Polars es muy rÃ¡pido y, de hecho, es una de las mejores soluciones disponibles. Tomemos como referencia db-benchmark de h2oai. Esta pÃ¡gina tiene como objetivo comparar varias herramientas similares a bases de datos populares en la ciencia de datos de cÃ³digo abierto. Se ejecuta regularmente con las Ãºltimas versiones de estos paquetes y se actualiza automÃ¡ticamente.\nTambiÃ©n se incluye la sintaxis que se cronometra junto con el tiempo. De esta manera, puede ver de inmediato si estÃ¡ realizando estas tareas o no, y si las diferencias de tiempo le importan o no. Una diferencia de 10x puede ser irrelevante si eso es solo 1s frente a 0,1s en el tamaÃ±o de sus datos.\nA modo de ejemplo, veamos algunos ejemplos de performances de distintas librerÃ­as para ejecutar distintos tipos de tareas sobre datasets con distintos tamaÃ±os. Para el caso de tareas bÃ¡sicas sobre un dataset de 50 GB, Polars supera a librerÃ­as espacializadas en distribuciÃ³n de Dataframes como Spark (143 segundos vs 568 segundos). Por otro lado, librerÃ­as conocidas en Python como Pandas o Dask se tiene el problema de out of memory."
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#expresiones-en-polars",
    "href": "posts/2022/2022-03-16-polars.html#expresiones-en-polars",
    "title": "Polars",
    "section": "",
    "text": "Polars tiene un poderoso concepto llamado expresiones. Las expresiones polares se pueden usar en varios contextos y son un mapeo funcional de Fn(Series) -&gt; Series, lo que significa que tienen Series como entrada y Series como salida. Al observar esta definiciÃ³n funcional, podemos ver que la salida de un Expr tambiÃ©n puede servir como entrada de un Expr.\nEso puede sonar un poco extraÃ±o, asÃ­ que vamos a dar un ejemplo.\nLa siguiente es una expresiÃ³n:\npl.col(\"foo\").sort().head(2)\nEl fragmento anterior dice seleccionar la columna \"foo\", luego ordenar esta columna y luego tomar los primeros 2 valores de la salida ordenada. El poder de las expresiones es que cada expresiÃ³n produce una nueva expresiÃ³n y que se pueden canalizar juntas. Puede ejecutar una expresiÃ³n pasÃ¡ndola en uno de los contextos de ejecuciÃ³n polares. AquÃ­ ejecutamos dos expresiones ejecutando df.select:\ndf.select([\n     pl.col(\"foo\").sort().head(2),\n     pl.col(\"barra\").filter(pl.col(\"foo\") == 1).sum()\n])\nTodas las expresiones se ejecutan en paralelo. (Tenga en cuenta que dentro de una expresiÃ³n puede haber mÃ¡s paralelizaciÃ³n).\n\n\nEn esta secciÃ³n veremos algunos ejemplos, pero primero vamos a crear un conjunto de datos:\n\nimport polars as pl\nimport numpy as np\n\n\nnp.random.seed(12)\n\ndf = pl.DataFrame(\n    {\n        \"nrs\": [1, 2, 3, None, 5],\n        \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", None],\n        \"random\": np.random.rand(5),\n        \"groups\": [\"A\", \"A\", \"B\", \"C\", \"B\"],\n    }\n)\nprint(df)\n\nshape: (5, 4)\nâ”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ nrs  â”† names â”† random   â”† groups â”‚\nâ”‚ ---  â”† ---   â”† ---      â”† ---    â”‚\nâ”‚ i64  â”† str   â”† f64      â”† str    â”‚\nâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\nâ”‚ 1    â”† foo   â”† 0.154163 â”† A      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 2    â”† ham   â”† 0.74     â”† A      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 3    â”† spam  â”† 0.263315 â”† B      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ null â”† egg   â”† 0.533739 â”† C      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 5    â”† null  â”† 0.014575 â”† B      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\nPuedes hacer mucho con las expresiones, veamos algunos ejemplos:\n\n\nPodemos contar los valores Ãºnicos en una columna. Tenga en cuenta que estamos creando el mismo resultado de diferentes maneras. Para no tener nombres de columna duplicados en el DataFrame, usamos una expresiÃ³n de alias, que cambia el nombre de una expresiÃ³n.\n\nout = df.select(\n    [\n        pl.col(\"names\").n_unique().alias(\"unique_names_1\"),\n        pl.col(\"names\").unique().count().alias(\"unique_names_2\"),\n    ]\n)\nprint(out)\n\nshape: (1, 2)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ unique_names_1 â”† unique_names_2 â”‚\nâ”‚ ---            â”† ---            â”‚\nâ”‚ u32            â”† u32            â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ 5              â”† 5              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\n\nPodemos hacer varias agregaciones. A continuaciÃ³n mostramos algunas de ellas, pero hay mÃ¡s, como median, mean, first, etc.\n\nout = df.select(\n    [\n        pl.sum(\"random\").alias(\"sum\"),\n        pl.min(\"random\").alias(\"min\"),\n        pl.max(\"random\").alias(\"max\"),\n        pl.col(\"random\").max().alias(\"other_max\"),\n        pl.std(\"random\").alias(\"std dev\"),\n        pl.var(\"random\").alias(\"variance\"),\n    ]\n)\nprint(out)\n\nshape: (1, 6)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ sum      â”† min      â”† max  â”† other_max â”† std dev  â”† variance â”‚\nâ”‚ ---      â”† ---      â”† ---  â”† ---       â”† ---      â”† ---      â”‚\nâ”‚ f64      â”† f64      â”† f64  â”† f64       â”† f64      â”† f64      â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ 1.705842 â”† 0.014575 â”† 0.74 â”† 0.74      â”† 0.293209 â”† 0.085971 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nTambiÃ©n podemos hacer cosas bastante complejas. En el siguiente fragmento, contamos todos los nombres que terminan con la cadena \"am\".\n\nout = df.select(\n    [\n        pl.col(\"names\").filter(pl.col(\"names\").str.contains(r\"am$\")).count(),\n    ]\n)\nprint(out)\n\nshape: (1, 1)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ names â”‚\nâ”‚ ---   â”‚\nâ”‚ u32   â”‚\nâ•â•â•â•â•â•â•â•â•¡\nâ”‚ 2     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nEn el ejemplo a continuaciÃ³n, usamos un condicional para crear una nueva expresiÃ³n when -&gt; then -&gt; otherwise.\nLa funciÃ³n when() requiere una expresiÃ³n de predicado (y, por lo tanto, conduce a una serie booleana), luego espera una expresiÃ³n que se usarÃ¡ en caso de que el predicado se evalÃºe como verdadero y, de lo contrario, espera una expresiÃ³n que se usarÃ¡ en caso de que el predicado se evalÃºe.\nTenga en cuenta que puede pasar cualquier expresiÃ³n, o simplemente expresiones base como pl.col(\"foo\"), pl.lit(3), pl.lit(\"bar\"), etc.\nFinalmente, multiplicamos esto con el resultado de una expresiÃ³n de suma.\n\nout = df.select(\n    [\n        pl.when(pl.col(\"random\") &gt; 0.5).then(0).otherwise(pl.col(\"random\")) * pl.sum(\"nrs\"),\n    ]\n)\nprint(out)\n\nshape: (5, 1)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ literal  â”‚\nâ”‚ ---      â”‚\nâ”‚ f64      â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ 1.695791 â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 0.0      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 2.896465 â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 0.0      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 0.160325 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nUna expresiÃ³n polar tambiÃ©n puede hacer un GROUPBY, AGGREGATION y JOIN implÃ­citos en una sola expresiÃ³n.\nEn los ejemplos a continuaciÃ³n, hacemos un GROUPBY sobre \"groups\" y AGREGATE SUM de \"random\", y en la siguiente expresiÃ³n GROUPBY OVER \"names\" y AGREGATE una lista de \"random\". Estas funciones de ventana se pueden combinar con otras expresiones y son una forma eficaz de determinar estadÃ­sticas de grupo. Vea mÃ¡s expresiones en el siguiente link.\n\nout = df[\n    [\n        pl.col(\"*\"),  # select all\n        pl.col(\"random\").sum().over(\"groups\").alias(\"sum[random]/groups\"),\n        pl.col(\"random\").list().over(\"names\").alias(\"random/name\"),\n    ]\n]\nprint(out)\n\nshape: (5, 6)\nâ”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ nrs  â”† names â”† random   â”† groups â”† sum[random]/groups â”† random/name â”‚\nâ”‚ ---  â”† ---   â”† ---      â”† ---    â”† ---                â”† ---         â”‚\nâ”‚ i64  â”† str   â”† f64      â”† str    â”† f64                â”† list [f64]  â”‚\nâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ 1    â”† foo   â”† 0.154163 â”† A      â”† 0.894213           â”† [0.154163]  â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 2    â”† ham   â”† 0.74     â”† A      â”† 0.894213           â”† [0.74]      â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 3    â”† spam  â”† 0.263315 â”† B      â”† 0.2778             â”† [0.263315]  â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ null â”† egg   â”† 0.533739 â”† C      â”† 0.533739           â”† [0.533739]  â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ 5    â”† null  â”† 0.014575 â”† B      â”† 0.2778             â”† [0.014575]  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#groupby",
    "href": "posts/2022/2022-03-16-polars.html#groupby",
    "title": "Polars",
    "section": "",
    "text": "Una de las formas mÃ¡s eficientes de procesar datos tabulares es paralelizar su procesamiento a travÃ©s del enfoque â€œdividir-aplicar-combinarâ€. Esta operaciÃ³n es el nÃºcleo de la implementaciÃ³n del agrupamiento de Polars, lo que le permite lograr operaciones ultrarrÃ¡pidas. MÃ¡s especÃ­ficamente, las fases de â€œdivisiÃ³nâ€ y â€œaplicaciÃ³nâ€ se ejecutan de forma multiproceso.\nUna operaciÃ³n de agrupaciÃ³n simple se toma a continuaciÃ³n como ejemplo para ilustrar este enfoque:\n\nPara las operaciones hash realizadas durante la fase de â€œdivisiÃ³nâ€, Polars utiliza un enfoque sin bloqueo de subprocesos mÃºltiples que se ilustra en el siguiente esquema:\n\nÂ¡Esta paralelizaciÃ³n permite que las operaciones de agrupaciÃ³n y uniÃ³n (por ejemplo) sean increÃ­blemente rÃ¡pidas!\n\n\n\nTodos hemos escuchado que Python es lento y â€œno escalaâ€. AdemÃ¡s de la sobrecarga de ejecutar el cÃ³digo de bytes â€œlentoâ€, Python debe permanecer dentro de las restricciones del Global interpreter lock (GIL). Esto significa que si se usa la operaciÃ³n lambda o una funciÃ³n de Python personalizada para aplicar durante una fase de paralelizaciÃ³n, la velocidad de Polars se limita al ejecutar el cÃ³digo de Python, lo que evita que varios subprocesos ejecuten la funciÃ³n.\nTodo esto se siente terriblemente limitante, especialmente porque a menudo necesitamos esos lambda en un paso .groupby(), por ejemplo. Este enfoque aÃºn es compatible con Polars, pero teniendo en cuenta el cÃ³digo de bytes Y el precio GIL deben pagarse.\nPara mitigar esto, Polars implementa una poderosa sintaxis definida no solo en su lazy, sino tambiÃ©n en su uso eager.\n\n\n\nEn la introducciÃ³n de la pÃ¡gina anterior, discutimos que el uso de funciones personalizadas de Python eliminaba la paralelizaciÃ³n y que podemos usar las expresiones de la API diferida para mitigar esto. Echemos un vistazo a lo que eso significa.\nComencemos con el conjunto de datos simple del congreso de EE. UU.\n\nimport polars as pl\n\ndataset = pl.read_csv(\"legislators-current.csv\")\ndataset = dataset.with_column(pl.col(\"birthday\").str.strptime(pl.Date))\nprint(dataset.head())\n\nshape: (5, 34)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ last_name â”† first_name â”† middle_name â”† suffix â”† ... â”† ballotpedia_id â”† washington_post_id â”† icpsr_id â”† wikipedia_id   â”‚\nâ”‚ ---       â”† ---        â”† ---         â”† ---    â”†     â”† ---            â”† ---                â”† ---      â”† ---            â”‚\nâ”‚ str       â”† str        â”† str         â”† str    â”†     â”† str            â”† str                â”† i64      â”† str            â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ Brown     â”† Sherrod    â”† null        â”† null   â”† ... â”† Sherrod Brown  â”† null               â”† 29389    â”† Sherrod Brown  â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Cantwell  â”† Maria      â”† null        â”† null   â”† ... â”† Maria Cantwell â”† null               â”† 39310    â”† Maria Cantwell â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Cardin    â”† Benjamin   â”† L.          â”† null   â”† ... â”† Ben Cardin     â”† null               â”† 15408    â”† Ben Cardin     â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Carper    â”† Thomas     â”† Richard     â”† null   â”† ... â”† Tom Carper     â”† null               â”† 15015    â”† Tom Carper     â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Casey     â”† Robert     â”† P.          â”† Jr.    â”† ... â”† Bob Casey, Jr. â”† null               â”† 40703    â”† Bob Casey Jr.  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nPuede combinar fÃ¡cilmente diferentes agregaciones agregando varias expresiones en una lista. No hay un lÃ­mite superior en el nÃºmero de agregaciones que puede hacer y puede hacer cualquier combinaciÃ³n que desee. En el fragmento a continuaciÃ³n, hacemos las siguientes agregaciones:\nPor grupo \"first_name\":\n\ncuente el nÃºmero de filas en el grupo:\n\nforma abreviada: pl.count(\"party\")\nforma completa: pl.col(\"party\").count()\n\nagregue el grupo de valores de gÃ©nero a una lista:\n\nforma completa: pl.col(\"gender\").list()\n\nobtenga el primer valor de la columna \"last_name\" en el grupo:\n\nforma abreviada: pl.primero(\"last_name\")\nforma completa: pl.col(\"last_name\").first()\n\n\nAdemÃ¡s de la agregaciÃ³n, clasificamos inmediatamente el resultado y lo limitamos a los 5 principales para que tengamos un buen resumen general.\n\nq = (\n    dataset.lazy()\n    .groupby(\"first_name\")\n    .agg(\n        [\n            pl.count(),\n            pl.col(\"gender\").list(),\n            pl.first(\"last_name\"),\n        ]\n    )\n    .sort(\"count\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 4)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ first_name â”† count â”† gender              â”† last_name â”‚\nâ”‚ ---        â”† ---   â”† ---                 â”† ---       â”‚\nâ”‚ str        â”† u32   â”† list [str]          â”† str       â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ John       â”† 19    â”† [\"M\", \"M\", ... \"M\"] â”† Barrasso  â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Mike       â”† 13    â”† [\"M\", \"M\", ... \"M\"] â”† Kelly     â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ Michael    â”† 11    â”† [\"M\", \"M\", ... \"M\"] â”† Bennet    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ David      â”† 11    â”† [\"M\", \"M\", ... \"M\"] â”† Cicilline â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ James      â”† 9     â”† [\"M\", \"M\", ... \"M\"] â”† Inhofe    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nOk, eso fue bastante fÃ¡cil, Â¿verdad? Subamos un nivel. Digamos que queremos saber cuÃ¡ntos delegados de un â€œestadoâ€ (state) son administraciÃ³n â€œDemocratâ€ o â€œRepublicanâ€. PodrÃ­amos consultarlo directamente en la agregaciÃ³n sin la necesidad de lambda o arreglar el DataFrame.\n\nq = (\n    dataset.lazy()\n    .groupby(\"state\")\n    .agg(\n        [\n            (pl.col(\"party\") == \"Democrat\").sum().alias(\"demo\"),\n            (pl.col(\"party\") == \"Republican\").sum().alias(\"repu\"),\n        ]\n    )\n    .sort(\"demo\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 3)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”\nâ”‚ state â”† demo â”† repu â”‚\nâ”‚ ---   â”† ---  â”† ---  â”‚\nâ”‚ str   â”† u32  â”† u32  â”‚\nâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•¡\nâ”‚ CA    â”† 44   â”† 10   â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ NY    â”† 21   â”† 8    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ IL    â”† 15   â”† 5    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ TX    â”† 13   â”† 25   â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ NJ    â”† 12   â”† 2    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜\n\n\nPor supuesto, tambiÃ©n se podrÃ­a hacer algo similar con un GROUPBY anidado, pero eso no me permitirÃ­a mostrar estas caracterÃ­sticas agradables. ğŸ˜‰\n\nq = (\n    dataset.lazy()\n    .groupby([\"state\", \"party\"])\n    .agg([pl.count(\"party\").alias(\"count\")])\n    .filter((pl.col(\"party\") == \"Democrat\") | (pl.col(\"party\") == \"Republican\"))\n    .sort(\"count\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 3)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ state â”† party      â”† count â”‚\nâ”‚ ---   â”† ---        â”† ---   â”‚\nâ”‚ str   â”† str        â”† u32   â”‚\nâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\nâ”‚ CA    â”† Democrat   â”† 44    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ TX    â”† Republican â”† 25    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ NY    â”† Democrat   â”† 21    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ FL    â”† Republican â”† 18    â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ IL    â”† Democrat   â”† 15    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nTambiÃ©n podemos filtrar los grupos. Digamos que queremos calcular una media por grupo, pero no queremos incluir todos los valores de ese grupo y tampoco queremos filtrar las filas del DataFrame (porque necesitamos esas filas para otra agregaciÃ³n).\nEn el siguiente ejemplo, mostramos cÃ³mo se puede hacer eso. Tenga en cuenta que podemos hacer funciones de Python para mayor claridad. Estas funciones no nos cuestan nada. Esto se debe a que solo creamos Polars expression, no aplicamos una funciÃ³n personalizada sobre Series durante el tiempo de ejecuciÃ³n de la consulta.\n\nfrom datetime import date\n\ndef compute_age() -&gt; pl.Expr:\n    return date(2021, 1, 1).year - pl.col(\"birthday\").dt.year()\n\n\ndef avg_birthday(gender: str) -&gt; pl.Expr:\n    return compute_age().filter(pl.col(\"gender\") == gender).mean().alias(f\"avg {gender} birthday\")\n\n\nq = (\n    dataset.lazy()\n    .groupby([\"state\"])\n    .agg(\n        [\n            avg_birthday(\"M\"),\n            avg_birthday(\"F\"),\n            (pl.col(\"gender\") == \"M\").sum().alias(\"# male\"),\n            (pl.col(\"gender\") == \"F\").sum().alias(\"# female\"),\n        ]\n    )\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 5)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ state â”† avg M birthday â”† avg F birthday â”† # male â”† # female â”‚\nâ”‚ ---   â”† ---            â”† ---            â”† ---    â”† ---      â”‚\nâ”‚ str   â”† f64            â”† f64            â”† u32    â”† u32      â”‚\nâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ MS    â”† 60.0           â”† 62.0           â”† 5      â”† 1        â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ NV    â”† 55.5           â”† 61.75          â”† 2      â”† 4        â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ KS    â”† 54.2           â”† 41.0           â”† 5      â”† 1        â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ IN    â”† 55.0           â”† 50.5           â”† 9      â”† 2        â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ IL    â”† 60.923077      â”† 58.428571      â”† 13     â”† 7        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n\n\nA menudo veo que se ordena un DataFrame con el Ãºnico propÃ³sito de ordenar durante la operaciÃ³n GROUPBY. Digamos que queremos obtener los nombres de los polÃ­ticos mÃ¡s antiguos y mÃ¡s jÃ³venes (no es que todavÃ­a estÃ©n vivos) por estado, podrÃ­amos ORDENAR y AGRUPAR.\n\ndef get_person() -&gt; pl.Expr:\n    return pl.col(\"first_name\") + pl.lit(\" \") + pl.col(\"last_name\")\n\n\nq = (\n    dataset.lazy()\n    .sort(\"birthday\")\n    .groupby([\"state\"])\n    .agg(\n        [\n            get_person().first().alias(\"youngest\"),\n            get_person().last().alias(\"oldest\"),\n        ]\n    )\n    .limit(5)\n)\n\ndf = q.collect()\n\nprint(df)\n\nshape: (5, 3)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ state â”† youngest                 â”† oldest                   â”‚\nâ”‚ ---   â”† ---                      â”† ---                      â”‚\nâ”‚ str   â”† str                      â”† str                      â”‚\nâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ PR    â”† Jenniffer GonzÃ¡lez-ColÃ³n â”† Jenniffer GonzÃ¡lez-ColÃ³n â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ ND    â”† John Hoeven              â”† Kelly Armstrong          â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ KY    â”† Harold Rogers            â”† Garland Barr             â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ NM    â”† Teresa Leger Fernandez   â”† Melanie Stansbury        â”‚\nâ”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤\nâ”‚ OR    â”† Peter DeFazio            â”† Jeff Merkley             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#referencias",
    "href": "posts/2022/2022-03-16-polars.html#referencias",
    "title": "Polars",
    "section": "",
    "text": "Polars - User Guide\nPolars - Github"
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html",
    "href": "posts/2021/2021-08-31-buenas_practicas.html",
    "title": "Buenas PrÃ¡cticas - Python",
    "section": "",
    "text": "Una pregunta que surgue a menudo cuando uno se encuentra programando es saber cuÃ¡l es la forma correcta de programar. La respuesta es que no existe la forma correcta de programar (ya sea en Python o cualquier otro lenguaje), sin embargo, existen estandares dentro del mundo de la programaciÃ³n, con el fin de hacer el cÃ³digo mÃ¡s legible, sencillo de entender y ayudar a encontrar posibles errores.\nEn esta secciÃ³n se mostrarÃ¡ algunos conceptos sencillos que te ayudarÃ¡n a mejorar tus skills en el desarrollo de software (con Python).\n\n\n\nEl PEP8 es un estilo de codificaciÃ³n que proporciona convenciones de codificaciÃ³n para el cÃ³digo Python que comprende la biblioteca estÃ¡ndar en la distribuciÃ³n principal de Python.\nAlgunos aspectos importantes:\n\nEl PEP8 y el PEP 257 (Docstring Conventions) fueron adaptados del ensayo original de la GuÃ­a de estilo Python de Guido, con algunas adiciones de la guÃ­a de estilo de Barry.\nEsta guÃ­a de estilo evoluciona con el tiempo a medida que se identifican convenciones adicionales y las convenciones pasadas se vuelven obsoletas debido a cambios en el propio lenguaje.\nMuchos proyectos tienen sus propias pautas de estilo de codificaciÃ³n. En caso de conflicto, dichas guÃ­as especÃ­ficas del proyecto tienen prioridad para ese proyecto.\n\nBasados en el PEP8 y algunas buenas prÃ¡cticas del diseÃ±o de software, veamos ejemplo para poder escribir de mejor forma nuestros cÃ³digos.\n\n\nCuando sea posible, define variables con nombres que tengan algÃºn sentido o que puedas identificar fÃ¡cilmente, no importa que sean mÃ¡s largas. Por ejemplo, en un programa podrÃ­amos escribir:\n\na = 10.  \nb = 3.5 \nprint(f\"El area es {a*b}\" )\n\nEl area es 35.0\n\n\npero, Â¿quÃ© significan a y b? lo sabemos por el comentario (bien hecho), pero si mÃ¡s adelante nos encontramos con esas variables, tendremos que recordar cual es cual. Es mejor usar nombres con significado:\n\naltura = 10.  \nbase = 3.5 \nprint(f\"El area es {a*b}\" )\n\nEl area es 35.0\n\n\n\n\n\nLas lÃ­neas de codigo no deben ser muy largas, como mucho 72 caracteres. Si se tiene una lÃ­nea larga, se puede cortar con una barra invertida (\\) y continuar en la siguiente lÃ­nea:\n\nprint(\"Esta es una frase muy larga, se puede cortar con un \\\n       y seguir en la lÃ­nea inferior.\")\n\nEsta es una frase muy larga, se puede cortar con un        y seguir en la lÃ­nea inferior.\n\n\n\n\n\nLos comentarios son muy importantes al escribir un programa. Describen lo que estÃ¡ sucediendo dentro de un programa, para que una persona que mira el cÃ³digo fuente no tenga dificultades para descifrarlo.\n\n#\n# esto es un comentario\nprint('Hola')\n\nHola\n\n\nTambiÃ©n podemos tener comentarios multilÃ­neas:\n\n#\n# Este es un comentario largo\n# y se extiende\n# a varias lÃ­neas\n\n\n\n\nLas importaciones generalmente deben estar en lÃ­neas separadas:\n\n#\n# no:\nimport sys, os\n\n\n#\n# si:\nimport os\nimport sys\n\n\n\n\nExisten varias formas de hacer comparaciones de objetos (principalmente en el uso del bucle if), acÃ¡ se dejan alguna recomendaciones:\n# no\nif greeting == True:\n\n# no\nif greeting is True:\n# si\nif greeting:\n\n\n\nDentro de parÃ©ntesis, corchetes o llaves, no dejar espacios inmediatamente dentro de ellos:\n\n#\n# no\nlista_01 = [1, 2, 3,4, 5, 6,7, 8, 9,]\n\n\n#\n# si \nlista_01 = [\n    1, 2, 3,\n    4, 5, 6,\n    7, 8, 9, \n]\n\nAunque en Python se pueden hacer varias declaraciones en una lÃ­nea, se recomienda hacer sÃ³lo una en cada lÃ­nea:\n\n#\n# no\na = 10; b = 20\n\n\n#\n# si\na = 10\nb = 20  \n\nCuando se trabaja con lista, conjuntos y/o tuplas se recomienda poner en cada lÃ­nea sus argumentos.\n\n#\n# no\nlista = [(1, 'hola'),(2, 'mundo'),]  \n\n\n#\n# si\nlista = [\n    (1, 'hola'),\n    (2, 'mundo'),\n]\n\nLo anterior se puede extender para funciones con muchos argumentos\n\n#\n# no\ndef funcion_01(x1,x2,x3,x4):\n    print(x1,x2,x3,x4)\n    \ndef funcion_02(\n    x1,x2,x3,x4):\n    print(x1,x2,x3,x4)\n\n\n#\n# si\ndef funcion_01(x1,x2,\n               x3,x4):\n    \n    print(x1,x2,x3,x4)\n    \ndef funcion_02(\n        x1,x2,\n        x3,x4):\n    \n    print(x1,x2,x3,x4)\n\n\n\n\nUn tema interesante es corresponde a la identaciÃ³n respecto a los operadores binarios, acÃ¡ se muestra la forma correcta de hacerlo:\n# no\nincome = (gross_wages +\n          taxable_interest +\n          (dividends - qualified_dividends) -\n          ira_deduction -\n          student_loan_interest)\n# si\nincome = (gross_wages\n          + taxable_interest\n          + (dividends - qualified_dividends)\n          - ira_deduction\n          - student_loan_interest)\n\n\n\nAunque combinar iterables con elementos de control de flujo para manipular listas es muy sencillo con Python, hay mÃ©todos especÃ­ficos mÃ¡s eficientes para hacer lo mismo. Pensemos el fitrado de datos de una lista:\n\n#\n# Seleccionar los nÃºmeros positivos\nnumeros = [-3, 2, 1, -8, -2, 7]\npositivos = []\nfor i in numeros:\n    if i &gt; 0:\n        positivos.append(i)\n        \nprint(f\"positivos: {positivos}\")\n\npositivos: [2, 1, 7]\n\n\nAunque tÃ©cnicamente es correcto, es mÃ¡s eficiente hacer List Comprehension:\n\n#\n# comprension de lista\nnumeros = [-3, 2, 1, -8, -2, 7]\npositivos = [i for i in numeros if i &gt; 0] # List Comprehension\nprint(f\"positivos: {positivos}\")\n\npositivos: [2, 1, 7]\n\n\n\n\n\nCuando se ocupa try/except, es necesario especificar el tipo de error que se estÃ¡ cometiendo.\n\n#\n# importar librerias\nimport sys\n\n\n#\n# no\ntry:\n    r = 1/0\nexcept:\n    print(\"Oops! ocurrio un\",sys.exc_info()[0])\n\nOops! ocurrio un &lt;class 'ZeroDivisionError'&gt;\n\n\n\n#\n# si\ntry:\n    r = 1/0\nexcept ZeroDivisionError:\n    print(\"Oops! ocurrio un\",sys.exc_info()[0])\n\nOops! ocurrio un &lt;class 'ZeroDivisionError'&gt;\n\n\n\n\n\nSiempre es mejor definir las variables dentro de una funciÃ³n y no dejar variables globales.\n\n#\n# no\nvalor = 5\n\ndef funcion_01(variable):\n    return 2*variable + valor\n\n\nfuncion_01(2)\n\n9\n\n\n\n#\n# si\ndef funcion_01(variable,valor):\n    return 2*variable + valor\n\n\nfuncion_01(2,5)\n\n9\n\n\n\n\n\nCon Python 3 se puede especificar el tipo de parÃ¡metro y el tipo de retorno de una funciÃ³n (usando la notaciÃ³n PEP484 y PEP526. Se definen dos conceptos claves:\n\nEscritura dinÃ¡mica: no se especifican los atributos de los inputs ni de los ouputs\nEscritura estÃ¡tica: se especifican los atributos de los inputs y los ouputs\n\n\n#\n# escritura dinÃ¡mica\ndef suma(x,y):\n    return x+y\n\n\nprint(suma(1,2))\n\n3\n\n\n\n#\n# escritura estatica\ndef suma(x:float,\n         y:float)-&gt;float:\n    return x+y\n\n\nprint(suma(1,2))\n\n3\n\n\nPara la escritura estÃ¡tica, si bien se especifica el tipo de atributo (tanto de los inputs o outputs), la funciÃ³n puede recibir otros tipos de atributos.\n\nprint(suma(\"hola\",\" mundo\"))\n\nhola mundo\n\n\nPara validar los tipos de datos son los correctos, se deben ocupar librerÃ­as especializadas en la validaciÃ³n de datos (por ejemplo: pydantic).\n\n\n\nExisten librerÃ­as que pueden ayudar a corregir errores de escrituras en tÃº cÃ³digo (tambiÃ©n conocido como AnÃ¡lisis EstÃ¡tico), por ejemplo:\n\nblack: El formateador de cÃ³digo inflexible.\nflake8: La herramienta para aplicar la guÃ­a de estilo PEP8.\nmypy: Mypy es un verificador de tipo estÃ¡tico para Python 3.\n\n\n\n\n\nCasi tan importante como la escritura de cÃ³digo, es su correcta documentaciÃ³n, una parte fundamental de cualquier programa que a menudo se infravalora o simplemente se ignora. Aparte de los comentarios entre el cÃ³digo explicando cÃ³mo funciona, el elemento bÃ¡sico de documentaciÃ³n de Python es el Docstring o cadena de documentaciÃ³n, que ya hemos visto. Simplemente es una cadena de texto con triple comillas que se coloca justo despuÃ©s de la definiciÃ³n de funciÃ³n o clase que sirve de documentaciÃ³n a ese elemento.\n\ndef potencia(x, y):\n    \"\"\"\n    Calcula la potencia arbitraria de un numero\n    \"\"\"\n    return x**y\n\n\n# Acceso a la documentaciÃ³n\npotencia.__doc__\n\n'\\n    Calcula la potencia arbitraria de un numero\\n    '\n\n\n\n# Acceso a la documentaciÃ³n\nhelp(potencia)\n\nHelp on function potencia in module __main__:\n\npotencia(x, y)\n    Calcula la potencia arbitraria de un numero\n\n\n\nLo correcto es detallar lo mejor posible en el Docstring quÃ© hace y cÃ³mo se usa la funciÃ³n o clase y los parÃ¡metros que necesita. Se recomienda usar el estilo de documentaciÃ³n del software de documentaciÃ³n sphinx, que emplea reStructuredText como lenguaje de marcado.\nVeamos un ejemplo de una funciÃ³n bien documentada:\n\ndef potencia(x, y):\n    \"\"\"\n    Calcula la potencia arbitraria de un numero\n\n    :param x: base\n    :param y: exponente\n    :return:  potencia de un numero\n    :ejemplos:\n    \n    &gt;&gt;&gt; potencia(2, 1)\n    2\n    &gt;&gt;&gt; potencia(3, 2)\n    9\n    \"\"\"\n\n    return x**y\n\n\n# Acceso a la documentaciÃ³n\npotencia.__doc__\n\n'\\n    Calcula la potencia arbitraria de un numero\\n\\n    :param x: base\\n    :param y: exponente\\n    :return:  potencia de un numero\\n    :ejemplos:\\n    \\n    &gt;&gt;&gt; potencia(2, 1)\\n    2\\n    &gt;&gt;&gt; potencia(3, 2)\\n    9\\n    '\n\n\n\n# Acceso a la documentaciÃ³n\nhelp(potencia)\n\nHelp on function potencia in module __main__:\n\npotencia(x, y)\n    Calcula la potencia arbitraria de un numero\n    \n    :param x: base\n    :param y: exponente\n    :return:  potencia de un numero\n    :ejemplos:\n    \n    &gt;&gt;&gt; potencia(2, 1)\n    2\n    &gt;&gt;&gt; potencia(3, 2)\n    9\n\n\n\nExisten varias formas de documentar tus funciones, las principales encontradas en la literatura son: * Google docstrings: forma de documentaciÃ³n recomendada por Google.. * reStructured Text: estÃ¡ndar oficial de documentaciÃ³n de Python; No es apto para principiantes, pero tiene muchas funciones. * NumPy/SciPy docstrings: combinaciÃ³n de NumPy de reStructured y Google Docstrings.\n\n\n\nEl Zen de Python te darÃ¡ la guÃ­a para decidir sobre que hacer con tu cÃ³digo, no te dice como lo debes escribir, sino como debes pensar si estas programando en Python.\nPrincipios importantes:\n\nExplÃ­cito es mejor que implÃ­cito: Que no se asuma nada, asegÃºrate que las cosas sean.\nSimple es mejor que complejo: Evita cÃ³digo complejo, cÃ³digo espagueti o que hace mas cosas para poder hacer una simple tarea.\nPlano es mejor que anidado: Si tu cÃ³digo tiene mas de 3 niveles de identaciÃ³n, deberÃ­as mover parte de ese cÃ³digo a una funciÃ³n.\nLos errores nunca deberÃ­an pasar silenciosamente: No uses un Try/Except sin definir que tipo de error vas a cachar, viene de la mano con Explicito es mejor que implÃ­cito.\nSi la implementaciÃ³n es difÃ­cil de explicar, es mala idea.\n\nTambiÃ©n, podemos ver el mensaje original del zen de python, ejecutando la siguiente linea de comando.\n\nimport this\n\nThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!\n\n\n\n\n\nLos consejos que se presentan son de mucha utilidad si usted quiere llevar sus conociminetos de programaciÃ³n al siguiente nivel, sin embargo, el contenido de cada uno amerita un curso por si solo. Se deja recomienda al lector seguir profundizando en estos temas.\n\n\nPython al ser multiparadigma, nos da una amplia gama de posibilidades de diseÃ±ar nuestros cÃ³digos. Dentro de estos se destacan:\n\nProgramaciÃ³n orientada a objetos (OOP)\nProgramaciÃ³n funcional\n\nCuÃ¡ndo ocupar uno o la otra, va a depender de cÃ³mo queremos abordar una determinada problemÃ¡tica, puesto que en la mayorÃ­a de los casos, se puede pasar de un paradigma a o otro (incluso mezclarlos de ser necesario).\n\n\n\nEn ingenierÃ­a de software, SOLID (Single responsibility, Open-closed, Liskov substitution, Interface segregation and Dependency inversion) es un acrÃ³nimo mnemÃ³nico introducido por Robert C. Martin a comienzos de la dÃ©cada del 2000 que representa cinco principios bÃ¡sicos de la programaciÃ³n orientada a objetos y el diseÃ±o. Cuando estos principios se aplican en conjunto es mÃ¡s probable que un desarrollador cree un sistema que sea fÃ¡cil de mantener y ampliar con el tiempo.\nEn el siguiente link se deja una guÃ­a para poder entender estos conceptos en python.\n\n\n\nLos patrones de diseÃ±o son la base para la bÃºsqueda de soluciones a problemas comunes en el desarrollo de software y otros Ã¡mbitos referentes al diseÃ±o de interacciÃ³n o interfaces.\n\nUn patrÃ³n de diseÃ±o es una soluciÃ³n a un problema de diseÃ±o.\n\nSe destacan tres tipos de patrones de diseÃ±os:\n\nComportamiento\nCreacionales\nEstructurales\n\nEn el siguiente link se deja una guÃ­a para poder entender estos conceptos en python.\n\n\n\n\nEsta secciÃ³n ofrece una selecciÃ³n de libros fundamentales para programadores, abarcando temas como codificaciÃ³n limpia, manejo de cÃ³digo heredado, refactorizaciÃ³n y desarrollo profesional. Escritos por expertos como Robert C. Martin, Michael C. Feathers, Martin Fowler y Thomas Hunt, estos libros proporcionan consejos prÃ¡cticos y estrategias probadas para mejorar la calidad del cÃ³digo y avanzar en la carrera de programaciÃ³n.\n\nThe Clean Coder: A Code Of Conduct For Professional Programmers Robert C. Martin (2011)\nClean Code: A Handbook of Agile Software - Robert C. Martin (2009).\nWorking effectively with legacy code Michael C. Feathers (2004)\nRefactoring Martin Fowler (1999)\nThe Pragmatic Programmer Thomas Hunt (1999)\n\n\n\n\n\nCode Style\nWrite More Pythonic Code"
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#introducciÃ³n",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#introducciÃ³n",
    "title": "Buenas PrÃ¡cticas - Python",
    "section": "",
    "text": "Una pregunta que surgue a menudo cuando uno se encuentra programando es saber cuÃ¡l es la forma correcta de programar. La respuesta es que no existe la forma correcta de programar (ya sea en Python o cualquier otro lenguaje), sin embargo, existen estandares dentro del mundo de la programaciÃ³n, con el fin de hacer el cÃ³digo mÃ¡s legible, sencillo de entender y ayudar a encontrar posibles errores.\nEn esta secciÃ³n se mostrarÃ¡ algunos conceptos sencillos que te ayudarÃ¡n a mejorar tus skills en el desarrollo de software (con Python)."
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#estilo-de-codificaciÃ³n-pep8",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#estilo-de-codificaciÃ³n-pep8",
    "title": "Buenas PrÃ¡cticas - Python",
    "section": "",
    "text": "El PEP8 es un estilo de codificaciÃ³n que proporciona convenciones de codificaciÃ³n para el cÃ³digo Python que comprende la biblioteca estÃ¡ndar en la distribuciÃ³n principal de Python.\nAlgunos aspectos importantes:\n\nEl PEP8 y el PEP 257 (Docstring Conventions) fueron adaptados del ensayo original de la GuÃ­a de estilo Python de Guido, con algunas adiciones de la guÃ­a de estilo de Barry.\nEsta guÃ­a de estilo evoluciona con el tiempo a medida que se identifican convenciones adicionales y las convenciones pasadas se vuelven obsoletas debido a cambios en el propio lenguaje.\nMuchos proyectos tienen sus propias pautas de estilo de codificaciÃ³n. En caso de conflicto, dichas guÃ­as especÃ­ficas del proyecto tienen prioridad para ese proyecto.\n\nBasados en el PEP8 y algunas buenas prÃ¡cticas del diseÃ±o de software, veamos ejemplo para poder escribir de mejor forma nuestros cÃ³digos.\n\n\nCuando sea posible, define variables con nombres que tengan algÃºn sentido o que puedas identificar fÃ¡cilmente, no importa que sean mÃ¡s largas. Por ejemplo, en un programa podrÃ­amos escribir:\n\na = 10.  \nb = 3.5 \nprint(f\"El area es {a*b}\" )\n\nEl area es 35.0\n\n\npero, Â¿quÃ© significan a y b? lo sabemos por el comentario (bien hecho), pero si mÃ¡s adelante nos encontramos con esas variables, tendremos que recordar cual es cual. Es mejor usar nombres con significado:\n\naltura = 10.  \nbase = 3.5 \nprint(f\"El area es {a*b}\" )\n\nEl area es 35.0\n\n\n\n\n\nLas lÃ­neas de codigo no deben ser muy largas, como mucho 72 caracteres. Si se tiene una lÃ­nea larga, se puede cortar con una barra invertida (\\) y continuar en la siguiente lÃ­nea:\n\nprint(\"Esta es una frase muy larga, se puede cortar con un \\\n       y seguir en la lÃ­nea inferior.\")\n\nEsta es una frase muy larga, se puede cortar con un        y seguir en la lÃ­nea inferior.\n\n\n\n\n\nLos comentarios son muy importantes al escribir un programa. Describen lo que estÃ¡ sucediendo dentro de un programa, para que una persona que mira el cÃ³digo fuente no tenga dificultades para descifrarlo.\n\n#\n# esto es un comentario\nprint('Hola')\n\nHola\n\n\nTambiÃ©n podemos tener comentarios multilÃ­neas:\n\n#\n# Este es un comentario largo\n# y se extiende\n# a varias lÃ­neas\n\n\n\n\nLas importaciones generalmente deben estar en lÃ­neas separadas:\n\n#\n# no:\nimport sys, os\n\n\n#\n# si:\nimport os\nimport sys\n\n\n\n\nExisten varias formas de hacer comparaciones de objetos (principalmente en el uso del bucle if), acÃ¡ se dejan alguna recomendaciones:\n# no\nif greeting == True:\n\n# no\nif greeting is True:\n# si\nif greeting:\n\n\n\nDentro de parÃ©ntesis, corchetes o llaves, no dejar espacios inmediatamente dentro de ellos:\n\n#\n# no\nlista_01 = [1, 2, 3,4, 5, 6,7, 8, 9,]\n\n\n#\n# si \nlista_01 = [\n    1, 2, 3,\n    4, 5, 6,\n    7, 8, 9, \n]\n\nAunque en Python se pueden hacer varias declaraciones en una lÃ­nea, se recomienda hacer sÃ³lo una en cada lÃ­nea:\n\n#\n# no\na = 10; b = 20\n\n\n#\n# si\na = 10\nb = 20  \n\nCuando se trabaja con lista, conjuntos y/o tuplas se recomienda poner en cada lÃ­nea sus argumentos.\n\n#\n# no\nlista = [(1, 'hola'),(2, 'mundo'),]  \n\n\n#\n# si\nlista = [\n    (1, 'hola'),\n    (2, 'mundo'),\n]\n\nLo anterior se puede extender para funciones con muchos argumentos\n\n#\n# no\ndef funcion_01(x1,x2,x3,x4):\n    print(x1,x2,x3,x4)\n    \ndef funcion_02(\n    x1,x2,x3,x4):\n    print(x1,x2,x3,x4)\n\n\n#\n# si\ndef funcion_01(x1,x2,\n               x3,x4):\n    \n    print(x1,x2,x3,x4)\n    \ndef funcion_02(\n        x1,x2,\n        x3,x4):\n    \n    print(x1,x2,x3,x4)\n\n\n\n\nUn tema interesante es corresponde a la identaciÃ³n respecto a los operadores binarios, acÃ¡ se muestra la forma correcta de hacerlo:\n# no\nincome = (gross_wages +\n          taxable_interest +\n          (dividends - qualified_dividends) -\n          ira_deduction -\n          student_loan_interest)\n# si\nincome = (gross_wages\n          + taxable_interest\n          + (dividends - qualified_dividends)\n          - ira_deduction\n          - student_loan_interest)\n\n\n\nAunque combinar iterables con elementos de control de flujo para manipular listas es muy sencillo con Python, hay mÃ©todos especÃ­ficos mÃ¡s eficientes para hacer lo mismo. Pensemos el fitrado de datos de una lista:\n\n#\n# Seleccionar los nÃºmeros positivos\nnumeros = [-3, 2, 1, -8, -2, 7]\npositivos = []\nfor i in numeros:\n    if i &gt; 0:\n        positivos.append(i)\n        \nprint(f\"positivos: {positivos}\")\n\npositivos: [2, 1, 7]\n\n\nAunque tÃ©cnicamente es correcto, es mÃ¡s eficiente hacer List Comprehension:\n\n#\n# comprension de lista\nnumeros = [-3, 2, 1, -8, -2, 7]\npositivos = [i for i in numeros if i &gt; 0] # List Comprehension\nprint(f\"positivos: {positivos}\")\n\npositivos: [2, 1, 7]\n\n\n\n\n\nCuando se ocupa try/except, es necesario especificar el tipo de error que se estÃ¡ cometiendo.\n\n#\n# importar librerias\nimport sys\n\n\n#\n# no\ntry:\n    r = 1/0\nexcept:\n    print(\"Oops! ocurrio un\",sys.exc_info()[0])\n\nOops! ocurrio un &lt;class 'ZeroDivisionError'&gt;\n\n\n\n#\n# si\ntry:\n    r = 1/0\nexcept ZeroDivisionError:\n    print(\"Oops! ocurrio un\",sys.exc_info()[0])\n\nOops! ocurrio un &lt;class 'ZeroDivisionError'&gt;\n\n\n\n\n\nSiempre es mejor definir las variables dentro de una funciÃ³n y no dejar variables globales.\n\n#\n# no\nvalor = 5\n\ndef funcion_01(variable):\n    return 2*variable + valor\n\n\nfuncion_01(2)\n\n9\n\n\n\n#\n# si\ndef funcion_01(variable,valor):\n    return 2*variable + valor\n\n\nfuncion_01(2,5)\n\n9\n\n\n\n\n\nCon Python 3 se puede especificar el tipo de parÃ¡metro y el tipo de retorno de una funciÃ³n (usando la notaciÃ³n PEP484 y PEP526. Se definen dos conceptos claves:\n\nEscritura dinÃ¡mica: no se especifican los atributos de los inputs ni de los ouputs\nEscritura estÃ¡tica: se especifican los atributos de los inputs y los ouputs\n\n\n#\n# escritura dinÃ¡mica\ndef suma(x,y):\n    return x+y\n\n\nprint(suma(1,2))\n\n3\n\n\n\n#\n# escritura estatica\ndef suma(x:float,\n         y:float)-&gt;float:\n    return x+y\n\n\nprint(suma(1,2))\n\n3\n\n\nPara la escritura estÃ¡tica, si bien se especifica el tipo de atributo (tanto de los inputs o outputs), la funciÃ³n puede recibir otros tipos de atributos.\n\nprint(suma(\"hola\",\" mundo\"))\n\nhola mundo\n\n\nPara validar los tipos de datos son los correctos, se deben ocupar librerÃ­as especializadas en la validaciÃ³n de datos (por ejemplo: pydantic).\n\n\n\nExisten librerÃ­as que pueden ayudar a corregir errores de escrituras en tÃº cÃ³digo (tambiÃ©n conocido como AnÃ¡lisis EstÃ¡tico), por ejemplo:\n\nblack: El formateador de cÃ³digo inflexible.\nflake8: La herramienta para aplicar la guÃ­a de estilo PEP8.\nmypy: Mypy es un verificador de tipo estÃ¡tico para Python 3."
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#documentaciÃ³n",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#documentaciÃ³n",
    "title": "Buenas PrÃ¡cticas - Python",
    "section": "",
    "text": "Casi tan importante como la escritura de cÃ³digo, es su correcta documentaciÃ³n, una parte fundamental de cualquier programa que a menudo se infravalora o simplemente se ignora. Aparte de los comentarios entre el cÃ³digo explicando cÃ³mo funciona, el elemento bÃ¡sico de documentaciÃ³n de Python es el Docstring o cadena de documentaciÃ³n, que ya hemos visto. Simplemente es una cadena de texto con triple comillas que se coloca justo despuÃ©s de la definiciÃ³n de funciÃ³n o clase que sirve de documentaciÃ³n a ese elemento.\n\ndef potencia(x, y):\n    \"\"\"\n    Calcula la potencia arbitraria de un numero\n    \"\"\"\n    return x**y\n\n\n# Acceso a la documentaciÃ³n\npotencia.__doc__\n\n'\\n    Calcula la potencia arbitraria de un numero\\n    '\n\n\n\n# Acceso a la documentaciÃ³n\nhelp(potencia)\n\nHelp on function potencia in module __main__:\n\npotencia(x, y)\n    Calcula la potencia arbitraria de un numero\n\n\n\nLo correcto es detallar lo mejor posible en el Docstring quÃ© hace y cÃ³mo se usa la funciÃ³n o clase y los parÃ¡metros que necesita. Se recomienda usar el estilo de documentaciÃ³n del software de documentaciÃ³n sphinx, que emplea reStructuredText como lenguaje de marcado.\nVeamos un ejemplo de una funciÃ³n bien documentada:\n\ndef potencia(x, y):\n    \"\"\"\n    Calcula la potencia arbitraria de un numero\n\n    :param x: base\n    :param y: exponente\n    :return:  potencia de un numero\n    :ejemplos:\n    \n    &gt;&gt;&gt; potencia(2, 1)\n    2\n    &gt;&gt;&gt; potencia(3, 2)\n    9\n    \"\"\"\n\n    return x**y\n\n\n# Acceso a la documentaciÃ³n\npotencia.__doc__\n\n'\\n    Calcula la potencia arbitraria de un numero\\n\\n    :param x: base\\n    :param y: exponente\\n    :return:  potencia de un numero\\n    :ejemplos:\\n    \\n    &gt;&gt;&gt; potencia(2, 1)\\n    2\\n    &gt;&gt;&gt; potencia(3, 2)\\n    9\\n    '\n\n\n\n# Acceso a la documentaciÃ³n\nhelp(potencia)\n\nHelp on function potencia in module __main__:\n\npotencia(x, y)\n    Calcula la potencia arbitraria de un numero\n    \n    :param x: base\n    :param y: exponente\n    :return:  potencia de un numero\n    :ejemplos:\n    \n    &gt;&gt;&gt; potencia(2, 1)\n    2\n    &gt;&gt;&gt; potencia(3, 2)\n    9\n\n\n\nExisten varias formas de documentar tus funciones, las principales encontradas en la literatura son: * Google docstrings: forma de documentaciÃ³n recomendada por Google.. * reStructured Text: estÃ¡ndar oficial de documentaciÃ³n de Python; No es apto para principiantes, pero tiene muchas funciones. * NumPy/SciPy docstrings: combinaciÃ³n de NumPy de reStructured y Google Docstrings."
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#zen-de-python",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#zen-de-python",
    "title": "Buenas PrÃ¡cticas - Python",
    "section": "",
    "text": "El Zen de Python te darÃ¡ la guÃ­a para decidir sobre que hacer con tu cÃ³digo, no te dice como lo debes escribir, sino como debes pensar si estas programando en Python.\nPrincipios importantes:\n\nExplÃ­cito es mejor que implÃ­cito: Que no se asuma nada, asegÃºrate que las cosas sean.\nSimple es mejor que complejo: Evita cÃ³digo complejo, cÃ³digo espagueti o que hace mas cosas para poder hacer una simple tarea.\nPlano es mejor que anidado: Si tu cÃ³digo tiene mas de 3 niveles de identaciÃ³n, deberÃ­as mover parte de ese cÃ³digo a una funciÃ³n.\nLos errores nunca deberÃ­an pasar silenciosamente: No uses un Try/Except sin definir que tipo de error vas a cachar, viene de la mano con Explicito es mejor que implÃ­cito.\nSi la implementaciÃ³n es difÃ­cil de explicar, es mala idea.\n\nTambiÃ©n, podemos ver el mensaje original del zen de python, ejecutando la siguiente linea de comando.\n\nimport this\n\nThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!"
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#mÃ¡s-consejos",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#mÃ¡s-consejos",
    "title": "Buenas PrÃ¡cticas - Python",
    "section": "",
    "text": "Los consejos que se presentan son de mucha utilidad si usted quiere llevar sus conociminetos de programaciÃ³n al siguiente nivel, sin embargo, el contenido de cada uno amerita un curso por si solo. Se deja recomienda al lector seguir profundizando en estos temas.\n\n\nPython al ser multiparadigma, nos da una amplia gama de posibilidades de diseÃ±ar nuestros cÃ³digos. Dentro de estos se destacan:\n\nProgramaciÃ³n orientada a objetos (OOP)\nProgramaciÃ³n funcional\n\nCuÃ¡ndo ocupar uno o la otra, va a depender de cÃ³mo queremos abordar una determinada problemÃ¡tica, puesto que en la mayorÃ­a de los casos, se puede pasar de un paradigma a o otro (incluso mezclarlos de ser necesario).\n\n\n\nEn ingenierÃ­a de software, SOLID (Single responsibility, Open-closed, Liskov substitution, Interface segregation and Dependency inversion) es un acrÃ³nimo mnemÃ³nico introducido por Robert C. Martin a comienzos de la dÃ©cada del 2000 que representa cinco principios bÃ¡sicos de la programaciÃ³n orientada a objetos y el diseÃ±o. Cuando estos principios se aplican en conjunto es mÃ¡s probable que un desarrollador cree un sistema que sea fÃ¡cil de mantener y ampliar con el tiempo.\nEn el siguiente link se deja una guÃ­a para poder entender estos conceptos en python.\n\n\n\nLos patrones de diseÃ±o son la base para la bÃºsqueda de soluciones a problemas comunes en el desarrollo de software y otros Ã¡mbitos referentes al diseÃ±o de interacciÃ³n o interfaces.\n\nUn patrÃ³n de diseÃ±o es una soluciÃ³n a un problema de diseÃ±o.\n\nSe destacan tres tipos de patrones de diseÃ±os:\n\nComportamiento\nCreacionales\nEstructurales\n\nEn el siguiente link se deja una guÃ­a para poder entender estos conceptos en python."
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#libros",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#libros",
    "title": "Buenas PrÃ¡cticas - Python",
    "section": "",
    "text": "Esta secciÃ³n ofrece una selecciÃ³n de libros fundamentales para programadores, abarcando temas como codificaciÃ³n limpia, manejo de cÃ³digo heredado, refactorizaciÃ³n y desarrollo profesional. Escritos por expertos como Robert C. Martin, Michael C. Feathers, Martin Fowler y Thomas Hunt, estos libros proporcionan consejos prÃ¡cticos y estrategias probadas para mejorar la calidad del cÃ³digo y avanzar en la carrera de programaciÃ³n.\n\nThe Clean Coder: A Code Of Conduct For Professional Programmers Robert C. Martin (2011)\nClean Code: A Handbook of Agile Software - Robert C. Martin (2009).\nWorking effectively with legacy code Michael C. Feathers (2004)\nRefactoring Martin Fowler (1999)\nThe Pragmatic Programmer Thomas Hunt (1999)"
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#referencias",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#referencias",
    "title": "Buenas PrÃ¡cticas - Python",
    "section": "",
    "text": "Code Style\nWrite More Pythonic Code"
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html",
    "href": "posts/2021/2021-07-31-jupyter.html",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Jupyter Notebook, es un entorno de trabajo interactivo que permite desarrollar cÃ³digo en Python (por defecto, aunque permite otros lenguajes) de manera dinÃ¡mica, a la vez que integrar en un mismo documento tanto bloques de cÃ³digo como texto, grÃ¡ficas o imÃ¡genes. Es un SaaS utilizado ampliamente en anÃ¡lisis numÃ©rico, estadÃ­stica y machine learning, entre otros campos de la informÃ¡tica y las matemÃ¡ticas.\nPor otro lado, JupyterLab es similar a Jupyter Notebook en cuanto a sus funcionalidade, pero tiene un interfaz mÃ¡s interesante para los usuarios. Eventualmente Jupyter Lab reemplazarÃ¡ a Jupyter Notebok.\nNos centraremos en comprender aspectos bÃ¡sicos de cÃ³mo trabajar un archivo en jupyter notebook (extensiÃ³n .ipynb).\n\n\n\n\n\nPara instalar RISE, necesitarÃ¡ usar la lÃ­nea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge notebook\nDe lo contrario, puede instalar con pip:\npip install notebook\n\nNota: SI desea instalar JupyterLab, simplemente reemplaza notebook por jupyterlab.\n\n\n\n\n\n\n\nUna vez que haya instalado Jupyter Notebook en su computadora, estarÃ¡ listo para ejecutar el servidor de la computadora portÃ¡til. Puede iniciar el servidor del portÃ¡til desde la lÃ­nea de comandos (usando Terminal en Mac/Linux, SÃ­mbolo del sistema en Windows) ejecutando:\njupyter notebook\n\nEsto imprimirÃ¡ cierta informaciÃ³n sobre el servidor en su terminal, incluida la URL de la aplicaciÃ³n web (de forma predeterminada, http://localhost:8888):\n$ jupyter notebook\n[I 08:58:24.417 NotebookApp] Serving notebooks from local directory: /Users/catherine\n[I 08:58:24.417 NotebookApp] 0 active kernels\n[I 08:58:24.417 NotebookApp] The Jupyter Notebook is running at: http://localhost:8888/\n[I 08:58:24.417 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\nA continuaciÃ³n, abrirÃ¡ su navegador web predeterminado a esta URL. Cuando el notebook se abra en su navegador, verÃ¡ el Panel, que mostrarÃ¡ una lista de notebooks, archivos y subdirectorios en el directorio donde se iniciÃ³ el servidor.\n\nLa parte superior de la lista de notebooks se muestran rutas de navegaciÃ³n en las que se puede hacer clic del directorio actual.\nPara crear un nuevo notebook, haga clic en el botÃ³n New en la parte superior de la lista y seleccione el kernel del menÃº desplegable (como se ve a continuaciÃ³n). Los kernels que se enumeran dependen de lo que estÃ© instalado en el servidor.\n\nNota: Es posible que algunos de los kernels de la siguiente captura de pantalla no existan como una opciÃ³n para usted.\n\n\nUna vez seleccionado el kernel, se abrira nuestro primer notebook!.\n\n\n\n\nJupyter notebook nos ofrece el siguiente toolbox:\n\n\nFile: En Ã©l, puede crear un nuevo cuaderno o abrir uno preexistente. AquÃ­ es tambiÃ©n a donde irÃ­a para cambiar el nombre de un Cuaderno. Creo que el elemento de menÃº mÃ¡s interesante es la opciÃ³n Guardar y Checkpoint. Esto le permite crear puntos de control a los que puede retroceder si lo necesita.\nEdit: AquÃ­ puede cortar, copiar y pegar celdas. AquÃ­ tambiÃ©n es donde irÃ­as si quisieras eliminar, dividir o fusionar una celda. Puede reordenar celdas aquÃ­ tambiÃ©n.\nView: es Ãºtil para alternar la visibilidad del encabezado y la barra de herramientas. TambiÃ©n puede activar o desactivar los nÃºmeros de lÃ­nea dentro de las celdas. AquÃ­ tambiÃ©n es donde irÃ­as si quieres meterte con la barra de herramientas de la celda.\nInsert: es solo para insertar celdas encima o debajo de la celda seleccionada actualmente.\nCell: le permite ejecutar una celda, un grupo de celdas o todas las celdas. TambiÃ©n puede ir aquÃ­ para cambiar el tipo de celda, aunque personalmente considero que la barra de herramientas es mÃ¡s intuitiva para eso.\nKernel: es para trabajar con el kernel que se ejecuta en segundo plano. AquÃ­ puede reiniciar el kernel, volver a conectarlo, apagarlo o incluso cambiar el kernel que estÃ¡ utilizando su computadora portÃ¡til.\nWidgets: es para guardar y borrar el estado del widget. Los widgets son bÃ¡sicamente widgets de JavaScript que puede agregar a sus celdas para crear contenido dinÃ¡mico utilizando Python (u otro Kernel).\nHelp: es donde debe aprender sobre los atajos de teclado del Notebook, un recorrido por la interfaz de usuario y mucho material de referencia.\n\n\n\n\n\n\nJupyter Notebook permite que escribamos texto formateado, es decir, texto con cursiva, negritas, tÃ­tulos de distintos tamaÃ±os, etc., de forma simple. Para ello Jupyter nos permite usar Markdown, que es un lenguaje de marcado (markup) muy popular.\nLos lenguajes de markup son lenguajes ideados para procesar texto, algunos de los mÃ¡s conocidos son HTML y \\(\\LaTeX\\). Markdown tiene como objetivo ser un lenguaje de sintaxis minimalista, simple de aprender y usar; de esa forma uno puede dar formato al texto pero sin perder demasiado tiempo en los detalles.\nLa cantidad de tutoriales en la red sobre Markdown es inmenso, por lo que nos centraremos en indicar las opciones que mÃ¡s se utilizan.\n\nTexto en negrita/cursiva: El texto en negrita se indica entre dos pares de asteriscos. De este modo **palabra** aparecerÃ¡ como palabra. Por otro lado, el texto en cursiva se indica entre dos asteriscos simples; es decir *palabra* aparecerÃ¡ como palabra.\nListas: Las listas en Markdown se realizan indicando un asterisco o un nÃºmero seguido de un punto si se desean listas numeradas. Markdown organiza automÃ¡ticamente los items asignÃ¡ndoles el nÃºmero correcto.\nInclusiÃ³n de imÃ¡genes: La sintaxis para incluir imÃ¡genes en Markdown es ![nombre alternativo](direcciÃ³n de la imagen) en donde el nombre alternativo aparecerÃ¡ en caso de que no se pueda cargar la imÃ¡gen y la direcciÃ³n puede referirse a una imagen local o un enlace en Internet.\nInclusiÃ³n de cÃ³digo HTML: El lenguaje Markdown es un subconjunto del lenguaje HTML y en donde se necesite un mayor control del formato, se puede incluir directamente el cÃ³digo HTML.\nEnlaces: Las celdas de texto pueden contener enlaces, tanto a otras partes del documento, como a pÃ¡ginas en internet u otros archivos locales. Su sintaxis es [texto](direcciÃ³n del enlace).\nFÃ³rmulas matemÃ¡ticas: Gracias al uso de MathJax, se puede incluir cÃ³digo en \\(\\LaTeX\\) para mostrar todo tipo de fÃ³rmulas y expresiones matemÃ¡ticas. Las fÃ³rmulas dentro de una lÃ­nea de texto se escriben entre sÃ­mbolos de dÃ³lar $...$, mientras que las expresiones separadas del texto utilizan sÃ­mbolos de dÃ³lar dobles $$...$$. Los siguientes son ejemplos de fÃ³rmulas matemÃ¡ticas escritas en \\(\\LaTeX\\):\n\n\\[p(x) = 3x^2 + 5y^2 + x^2y^2\\]\n\\[e^{\\pi i} - 1 = 0\\]\n\\[\\lim_{x \\rightarrow \\infty} 3x+1\\]\n\\[\\sum_{n=1}^\\infty\\frac{1}{n^2}\\]\n\\[\\int_0^\\infty\\frac{\\sin x}{x}\\,\\mathrm{d}x=\\frac{\\pi}{2}\\]\n\n\n\n\nJupyter Notebook permite que escribamos cÃ³digo dependiendo del kernel a trabajar. Por defecto, se trabaja con el kernel de Python.\nVeamos unos ejemplos sencillos de cÃ³digo:\n\nimport math\nn = 16\nprint(f\"La raiz cuadra de {n} es {math.sqrt(n)}\")\n\nLa raiz cuadra de 16 es 4.0\n\n\nTambiÃ©n es posible visualizar tablas de datos con la librerÃ­a pandas:\n\n#collapse-hide\nimport pandas as pd\nimport altair as alt\n\n# datasets\nmovies = 'https://vega.github.io/vega-datasets/data/movies.json'\nstocks = 'https://vega.github.io/vega-datasets/data/stocks.csv'\n\n\ndf = pd.read_json(movies) # load movies data\ndf.columns = [x.replace(' ', '_') for x in df.columns.values]\n\ndf.head()\n\n\n\n\n\n\n\n\n\nTitle\nUS_Gross\nWorldwide_Gross\nUS_DVD_Sales\nProduction_Budget\nRelease_Date\nMPAA_Rating\nRunning_Time_min\nDistributor\nSource\nMajor_Genre\nCreative_Type\nDirector\nRotten_Tomatoes_Rating\nIMDB_Rating\nIMDB_Votes\n\n\n\n\n0\nThe Land Girls\n146083.0\n146083.0\nNaN\n8000000.0\nJun 12 1998\nR\nNaN\nGramercy\nNone\nNone\nNone\nNone\nNaN\n6.1\n1071.0\n\n\n1\nFirst Love, Last Rites\n10876.0\n10876.0\nNaN\n300000.0\nAug 07 1998\nR\nNaN\nStrand\nNone\nDrama\nNone\nNone\nNaN\n6.9\n207.0\n\n\n2\nI Married a Strange Person\n203134.0\n203134.0\nNaN\n250000.0\nAug 28 1998\nNone\nNaN\nLionsgate\nNone\nComedy\nNone\nNone\nNaN\n6.8\n865.0\n\n\n3\nLet's Talk About Sex\n373615.0\n373615.0\nNaN\n300000.0\nSep 11 1998\nNone\nNaN\nFine Line\nNone\nComedy\nNone\nNone\n13.0\nNaN\nNaN\n\n\n4\nSlam\n1009819.0\n1087521.0\nNaN\n1000000.0\nOct 09 1998\nR\nNaN\nTrimark\nOriginal Screenplay\nDrama\nContemporary Fiction\nNone\n62.0\n3.4\n165.0\n\n\n\n\n\n\n\n\nUnas de las cosas mÃ¡s significativas de Jupyter notebook es poder trabajar con distintos tipos de grÃ¡ficos (imagen estÃ¡tica o interactiva). Estos son de bastante utilidad para poder comprender nuestros procedimientos.\n\n#collapse-hide\n\n# select a point for which to provide details-on-demand\nlabel = alt.selection_single(\n    encodings=['x'], # limit selection to x-axis value\n    on='mouseover',  # select on mouseover events\n    nearest=True,    # select data point nearest the cursor\n    empty='none'     # empty selection includes no data points\n)\n\n# define our base line chart of stock prices\nbase = alt.Chart().mark_line().encode(\n    alt.X('date:T'),\n    alt.Y('price:Q', scale=alt.Scale(type='log')),\n    alt.Color('symbol:N')\n)\n\nalt.layer(\n    base, # base line chart\n    \n    # add a rule mark to serve as a guide line\n    alt.Chart().mark_rule(color='#aaa').encode(\n        x='date:T'\n    ).transform_filter(label),\n    \n    # add circle marks for selected time points, hide unselected points\n    base.mark_circle().encode(\n        opacity=alt.condition(label, alt.value(1), alt.value(0))\n    ).add_selection(label),\n\n    # add white stroked text to provide a legible background for labels\n    base.mark_text(align='left', dx=5, dy=-5, stroke='white', strokeWidth=2).encode(\n        text='price:Q'\n    ).transform_filter(label),\n\n    # add text labels for stock prices\n    base.mark_text(align='left', dx=5, dy=-5).encode(\n        text='price:Q'\n    ).transform_filter(label),\n    \n    data=stocks\n).properties(\n    width=500,\n    height=400\n)\n\n\n\n\n\n\n\n\nLa completaciÃ³n mediante tabs, especialmente para los atributos, es una forma conveniente de explorar la estructura de cualquier objeto con el que estÃ© tratando.\nSimplemente escriba object_name.&lt;TAB&gt; para ver los atributos del objeto. AdemÃ¡s de los objetos y palabras clave de Python, la finalizaciÃ³n de pestaÃ±as tambiÃ©n funciona en nombres de archivos y directorios.\nimport collections\ncollections. # aprete la tecla &lt;ğ‘‡ğ´ğµ&gt;\n\n\n\nEn caso de necesitar ayuda sobre cualquier comando de Python, Jupyter nos ofrece una funciÃ³n llamada help.\nEn resumen, Â¡suele ser mÃ¡s importante saber como buscar informaciÃ³n que memorizarla! Por todo esto, Jupyter nos ofrece ayuda sobre cualquier comando agregando un signo de interrogaciÃ³n ? luego del nombre del comando (y luego ejecutar la celda con la combinaciÃ³n de teclas SHIFT + ENTER).\nimport numpy as np\nnp.sum?\n\n\n\nJupyter posee varias funciones mÃ¡gicas predefinidas que sirven para simplificar tareas comunes.\nHay dos tipos de magias:\n\nMagias por linea (line magics): son comandos que empiezan con el caracter % y que toman como argumentos valores escritos en la misma lÃ­nea.\nMagias por celda (cell magics): son comandos que empiezan con los caracteres %%, y que reciben argumentos en la misma lÃ­nea y en toda la celda.\n\nEn general solo se puede usar una sola mÃ¡gias por celda en cada celda y debe ser escrita en la primer linea de la celda.\nUn buen ejemplo de mÃ¡gia es %lsmagic que lista todas las magias disponibles:\n\n%lsmagic\n\nAvailable line magics:\n%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n\nAvailable cell magics:\n%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n\nAutomagic is ON, % prefix IS NOT needed for line magics.\n\n\nEn varias situaciones resulta necesario medir el tiempo de ejecuciÃ³n de una porciÃ³n de cÃ³digo. Para ello podemos usar la magia %timeit. Esta magia estÃ¡ disponible tanto para lÃ­nea como para celda:\n\n%%timeit \n1+1 # timeit repite (adaptativamente) la mediciÃ³n a fin de reducir el error.\n\n8.68 ns Â± 0.387 ns per loop (mean Â± std. dev. of 7 runs, 100000000 loops each)\n\n\nJupyter notebook permite tambiÃ©n mezclar varios lenguajes de programaciÃ³n en una misma notebook. Por ejemplo, podrÃ­amos escribir en bash lo siguiente:\n\n%%bash\nfor i in {3..1}; do\n    echo $i\ndone\necho \"Hola desde $BASH\"\n\n3\n2\n1\nHola desde /usr/bin/bash\n\n\nTambiÃ©n, puede acceder a la lÃ­nea de comandos, anteponiendo el sÃ­mbolo de !. Esto es de bastante utilidad cuando se quiere mostrar las dependencias que se necesitan instalar. (ejemplo: !pip install pandas).\nVeamos un ejemplo:\n\n!pwd\n\n/home/fralfaro/PycharmProjects/ds_blog/_notebooks\n\n\n\n\n\n\n\nNotebook Basics\nRunning the Notebook"
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#introducciÃ³n",
    "href": "posts/2021/2021-07-31-jupyter.html#introducciÃ³n",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Jupyter Notebook, es un entorno de trabajo interactivo que permite desarrollar cÃ³digo en Python (por defecto, aunque permite otros lenguajes) de manera dinÃ¡mica, a la vez que integrar en un mismo documento tanto bloques de cÃ³digo como texto, grÃ¡ficas o imÃ¡genes. Es un SaaS utilizado ampliamente en anÃ¡lisis numÃ©rico, estadÃ­stica y machine learning, entre otros campos de la informÃ¡tica y las matemÃ¡ticas.\nPor otro lado, JupyterLab es similar a Jupyter Notebook en cuanto a sus funcionalidade, pero tiene un interfaz mÃ¡s interesante para los usuarios. Eventualmente Jupyter Lab reemplazarÃ¡ a Jupyter Notebok.\nNos centraremos en comprender aspectos bÃ¡sicos de cÃ³mo trabajar un archivo en jupyter notebook (extensiÃ³n .ipynb)."
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#primeros-pasos",
    "href": "posts/2021/2021-07-31-jupyter.html#primeros-pasos",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Para instalar RISE, necesitarÃ¡ usar la lÃ­nea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge notebook\nDe lo contrario, puede instalar con pip:\npip install notebook\n\nNota: SI desea instalar JupyterLab, simplemente reemplaza notebook por jupyterlab."
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#primeros-pasos-1",
    "href": "posts/2021/2021-07-31-jupyter.html#primeros-pasos-1",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Una vez que haya instalado Jupyter Notebook en su computadora, estarÃ¡ listo para ejecutar el servidor de la computadora portÃ¡til. Puede iniciar el servidor del portÃ¡til desde la lÃ­nea de comandos (usando Terminal en Mac/Linux, SÃ­mbolo del sistema en Windows) ejecutando:\njupyter notebook\n\nEsto imprimirÃ¡ cierta informaciÃ³n sobre el servidor en su terminal, incluida la URL de la aplicaciÃ³n web (de forma predeterminada, http://localhost:8888):\n$ jupyter notebook\n[I 08:58:24.417 NotebookApp] Serving notebooks from local directory: /Users/catherine\n[I 08:58:24.417 NotebookApp] 0 active kernels\n[I 08:58:24.417 NotebookApp] The Jupyter Notebook is running at: http://localhost:8888/\n[I 08:58:24.417 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\nA continuaciÃ³n, abrirÃ¡ su navegador web predeterminado a esta URL. Cuando el notebook se abra en su navegador, verÃ¡ el Panel, que mostrarÃ¡ una lista de notebooks, archivos y subdirectorios en el directorio donde se iniciÃ³ el servidor.\n\nLa parte superior de la lista de notebooks se muestran rutas de navegaciÃ³n en las que se puede hacer clic del directorio actual.\nPara crear un nuevo notebook, haga clic en el botÃ³n New en la parte superior de la lista y seleccione el kernel del menÃº desplegable (como se ve a continuaciÃ³n). Los kernels que se enumeran dependen de lo que estÃ© instalado en el servidor.\n\nNota: Es posible que algunos de los kernels de la siguiente captura de pantalla no existan como una opciÃ³n para usted.\n\n\nUna vez seleccionado el kernel, se abrira nuestro primer notebook!.\n\n\n\n\nJupyter notebook nos ofrece el siguiente toolbox:\n\n\nFile: En Ã©l, puede crear un nuevo cuaderno o abrir uno preexistente. AquÃ­ es tambiÃ©n a donde irÃ­a para cambiar el nombre de un Cuaderno. Creo que el elemento de menÃº mÃ¡s interesante es la opciÃ³n Guardar y Checkpoint. Esto le permite crear puntos de control a los que puede retroceder si lo necesita.\nEdit: AquÃ­ puede cortar, copiar y pegar celdas. AquÃ­ tambiÃ©n es donde irÃ­as si quisieras eliminar, dividir o fusionar una celda. Puede reordenar celdas aquÃ­ tambiÃ©n.\nView: es Ãºtil para alternar la visibilidad del encabezado y la barra de herramientas. TambiÃ©n puede activar o desactivar los nÃºmeros de lÃ­nea dentro de las celdas. AquÃ­ tambiÃ©n es donde irÃ­as si quieres meterte con la barra de herramientas de la celda.\nInsert: es solo para insertar celdas encima o debajo de la celda seleccionada actualmente.\nCell: le permite ejecutar una celda, un grupo de celdas o todas las celdas. TambiÃ©n puede ir aquÃ­ para cambiar el tipo de celda, aunque personalmente considero que la barra de herramientas es mÃ¡s intuitiva para eso.\nKernel: es para trabajar con el kernel que se ejecuta en segundo plano. AquÃ­ puede reiniciar el kernel, volver a conectarlo, apagarlo o incluso cambiar el kernel que estÃ¡ utilizando su computadora portÃ¡til.\nWidgets: es para guardar y borrar el estado del widget. Los widgets son bÃ¡sicamente widgets de JavaScript que puede agregar a sus celdas para crear contenido dinÃ¡mico utilizando Python (u otro Kernel).\nHelp: es donde debe aprender sobre los atajos de teclado del Notebook, un recorrido por la interfaz de usuario y mucho material de referencia."
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#markdown",
    "href": "posts/2021/2021-07-31-jupyter.html#markdown",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Jupyter Notebook permite que escribamos texto formateado, es decir, texto con cursiva, negritas, tÃ­tulos de distintos tamaÃ±os, etc., de forma simple. Para ello Jupyter nos permite usar Markdown, que es un lenguaje de marcado (markup) muy popular.\nLos lenguajes de markup son lenguajes ideados para procesar texto, algunos de los mÃ¡s conocidos son HTML y \\(\\LaTeX\\). Markdown tiene como objetivo ser un lenguaje de sintaxis minimalista, simple de aprender y usar; de esa forma uno puede dar formato al texto pero sin perder demasiado tiempo en los detalles.\nLa cantidad de tutoriales en la red sobre Markdown es inmenso, por lo que nos centraremos en indicar las opciones que mÃ¡s se utilizan.\n\nTexto en negrita/cursiva: El texto en negrita se indica entre dos pares de asteriscos. De este modo **palabra** aparecerÃ¡ como palabra. Por otro lado, el texto en cursiva se indica entre dos asteriscos simples; es decir *palabra* aparecerÃ¡ como palabra.\nListas: Las listas en Markdown se realizan indicando un asterisco o un nÃºmero seguido de un punto si se desean listas numeradas. Markdown organiza automÃ¡ticamente los items asignÃ¡ndoles el nÃºmero correcto.\nInclusiÃ³n de imÃ¡genes: La sintaxis para incluir imÃ¡genes en Markdown es ![nombre alternativo](direcciÃ³n de la imagen) en donde el nombre alternativo aparecerÃ¡ en caso de que no se pueda cargar la imÃ¡gen y la direcciÃ³n puede referirse a una imagen local o un enlace en Internet.\nInclusiÃ³n de cÃ³digo HTML: El lenguaje Markdown es un subconjunto del lenguaje HTML y en donde se necesite un mayor control del formato, se puede incluir directamente el cÃ³digo HTML.\nEnlaces: Las celdas de texto pueden contener enlaces, tanto a otras partes del documento, como a pÃ¡ginas en internet u otros archivos locales. Su sintaxis es [texto](direcciÃ³n del enlace).\nFÃ³rmulas matemÃ¡ticas: Gracias al uso de MathJax, se puede incluir cÃ³digo en \\(\\LaTeX\\) para mostrar todo tipo de fÃ³rmulas y expresiones matemÃ¡ticas. Las fÃ³rmulas dentro de una lÃ­nea de texto se escriben entre sÃ­mbolos de dÃ³lar $...$, mientras que las expresiones separadas del texto utilizan sÃ­mbolos de dÃ³lar dobles $$...$$. Los siguientes son ejemplos de fÃ³rmulas matemÃ¡ticas escritas en \\(\\LaTeX\\):\n\n\\[p(x) = 3x^2 + 5y^2 + x^2y^2\\]\n\\[e^{\\pi i} - 1 = 0\\]\n\\[\\lim_{x \\rightarrow \\infty} 3x+1\\]\n\\[\\sum_{n=1}^\\infty\\frac{1}{n^2}\\]\n\\[\\int_0^\\infty\\frac{\\sin x}{x}\\,\\mathrm{d}x=\\frac{\\pi}{2}\\]"
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#cÃ³digo",
    "href": "posts/2021/2021-07-31-jupyter.html#cÃ³digo",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Jupyter Notebook permite que escribamos cÃ³digo dependiendo del kernel a trabajar. Por defecto, se trabaja con el kernel de Python.\nVeamos unos ejemplos sencillos de cÃ³digo:\n\nimport math\nn = 16\nprint(f\"La raiz cuadra de {n} es {math.sqrt(n)}\")\n\nLa raiz cuadra de 16 es 4.0\n\n\nTambiÃ©n es posible visualizar tablas de datos con la librerÃ­a pandas:\n\n#collapse-hide\nimport pandas as pd\nimport altair as alt\n\n# datasets\nmovies = 'https://vega.github.io/vega-datasets/data/movies.json'\nstocks = 'https://vega.github.io/vega-datasets/data/stocks.csv'\n\n\ndf = pd.read_json(movies) # load movies data\ndf.columns = [x.replace(' ', '_') for x in df.columns.values]\n\ndf.head()\n\n\n\n\n\n\n\n\n\nTitle\nUS_Gross\nWorldwide_Gross\nUS_DVD_Sales\nProduction_Budget\nRelease_Date\nMPAA_Rating\nRunning_Time_min\nDistributor\nSource\nMajor_Genre\nCreative_Type\nDirector\nRotten_Tomatoes_Rating\nIMDB_Rating\nIMDB_Votes\n\n\n\n\n0\nThe Land Girls\n146083.0\n146083.0\nNaN\n8000000.0\nJun 12 1998\nR\nNaN\nGramercy\nNone\nNone\nNone\nNone\nNaN\n6.1\n1071.0\n\n\n1\nFirst Love, Last Rites\n10876.0\n10876.0\nNaN\n300000.0\nAug 07 1998\nR\nNaN\nStrand\nNone\nDrama\nNone\nNone\nNaN\n6.9\n207.0\n\n\n2\nI Married a Strange Person\n203134.0\n203134.0\nNaN\n250000.0\nAug 28 1998\nNone\nNaN\nLionsgate\nNone\nComedy\nNone\nNone\nNaN\n6.8\n865.0\n\n\n3\nLet's Talk About Sex\n373615.0\n373615.0\nNaN\n300000.0\nSep 11 1998\nNone\nNaN\nFine Line\nNone\nComedy\nNone\nNone\n13.0\nNaN\nNaN\n\n\n4\nSlam\n1009819.0\n1087521.0\nNaN\n1000000.0\nOct 09 1998\nR\nNaN\nTrimark\nOriginal Screenplay\nDrama\nContemporary Fiction\nNone\n62.0\n3.4\n165.0\n\n\n\n\n\n\n\n\nUnas de las cosas mÃ¡s significativas de Jupyter notebook es poder trabajar con distintos tipos de grÃ¡ficos (imagen estÃ¡tica o interactiva). Estos son de bastante utilidad para poder comprender nuestros procedimientos.\n\n#collapse-hide\n\n# select a point for which to provide details-on-demand\nlabel = alt.selection_single(\n    encodings=['x'], # limit selection to x-axis value\n    on='mouseover',  # select on mouseover events\n    nearest=True,    # select data point nearest the cursor\n    empty='none'     # empty selection includes no data points\n)\n\n# define our base line chart of stock prices\nbase = alt.Chart().mark_line().encode(\n    alt.X('date:T'),\n    alt.Y('price:Q', scale=alt.Scale(type='log')),\n    alt.Color('symbol:N')\n)\n\nalt.layer(\n    base, # base line chart\n    \n    # add a rule mark to serve as a guide line\n    alt.Chart().mark_rule(color='#aaa').encode(\n        x='date:T'\n    ).transform_filter(label),\n    \n    # add circle marks for selected time points, hide unselected points\n    base.mark_circle().encode(\n        opacity=alt.condition(label, alt.value(1), alt.value(0))\n    ).add_selection(label),\n\n    # add white stroked text to provide a legible background for labels\n    base.mark_text(align='left', dx=5, dy=-5, stroke='white', strokeWidth=2).encode(\n        text='price:Q'\n    ).transform_filter(label),\n\n    # add text labels for stock prices\n    base.mark_text(align='left', dx=5, dy=-5).encode(\n        text='price:Q'\n    ).transform_filter(label),\n    \n    data=stocks\n).properties(\n    width=500,\n    height=400\n)\n\n\n\n\n\n\n\n\nLa completaciÃ³n mediante tabs, especialmente para los atributos, es una forma conveniente de explorar la estructura de cualquier objeto con el que estÃ© tratando.\nSimplemente escriba object_name.&lt;TAB&gt; para ver los atributos del objeto. AdemÃ¡s de los objetos y palabras clave de Python, la finalizaciÃ³n de pestaÃ±as tambiÃ©n funciona en nombres de archivos y directorios.\nimport collections\ncollections. # aprete la tecla &lt;ğ‘‡ğ´ğµ&gt;\n\n\n\nEn caso de necesitar ayuda sobre cualquier comando de Python, Jupyter nos ofrece una funciÃ³n llamada help.\nEn resumen, Â¡suele ser mÃ¡s importante saber como buscar informaciÃ³n que memorizarla! Por todo esto, Jupyter nos ofrece ayuda sobre cualquier comando agregando un signo de interrogaciÃ³n ? luego del nombre del comando (y luego ejecutar la celda con la combinaciÃ³n de teclas SHIFT + ENTER).\nimport numpy as np\nnp.sum?\n\n\n\nJupyter posee varias funciones mÃ¡gicas predefinidas que sirven para simplificar tareas comunes.\nHay dos tipos de magias:\n\nMagias por linea (line magics): son comandos que empiezan con el caracter % y que toman como argumentos valores escritos en la misma lÃ­nea.\nMagias por celda (cell magics): son comandos que empiezan con los caracteres %%, y que reciben argumentos en la misma lÃ­nea y en toda la celda.\n\nEn general solo se puede usar una sola mÃ¡gias por celda en cada celda y debe ser escrita en la primer linea de la celda.\nUn buen ejemplo de mÃ¡gia es %lsmagic que lista todas las magias disponibles:\n\n%lsmagic\n\nAvailable line magics:\n%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n\nAvailable cell magics:\n%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n\nAutomagic is ON, % prefix IS NOT needed for line magics.\n\n\nEn varias situaciones resulta necesario medir el tiempo de ejecuciÃ³n de una porciÃ³n de cÃ³digo. Para ello podemos usar la magia %timeit. Esta magia estÃ¡ disponible tanto para lÃ­nea como para celda:\n\n%%timeit \n1+1 # timeit repite (adaptativamente) la mediciÃ³n a fin de reducir el error.\n\n8.68 ns Â± 0.387 ns per loop (mean Â± std. dev. of 7 runs, 100000000 loops each)\n\n\nJupyter notebook permite tambiÃ©n mezclar varios lenguajes de programaciÃ³n en una misma notebook. Por ejemplo, podrÃ­amos escribir en bash lo siguiente:\n\n%%bash\nfor i in {3..1}; do\n    echo $i\ndone\necho \"Hola desde $BASH\"\n\n3\n2\n1\nHola desde /usr/bin/bash\n\n\nTambiÃ©n, puede acceder a la lÃ­nea de comandos, anteponiendo el sÃ­mbolo de !. Esto es de bastante utilidad cuando se quiere mostrar las dependencias que se necesitan instalar. (ejemplo: !pip install pandas).\nVeamos un ejemplo:\n\n!pwd\n\n/home/fralfaro/PycharmProjects/ds_blog/_notebooks"
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#referencias",
    "href": "posts/2021/2021-07-31-jupyter.html#referencias",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Notebook Basics\nRunning the Notebook"
  },
  {
    "objectID": "posts/2023/art_docs.html",
    "href": "posts/2023/art_docs.html",
    "title": "DocumentaciÃ³n",
    "section": "",
    "text": "Esperamos que, si estÃ¡s leyendo este tutorial, ya comprendas la importancia de documentar tu cÃ³digo. Pero, por si acaso, permÃ­teme citar algo que Guido mencionÃ³ en la reciente PyCon 2016:\n\n\n\n\n\n\nCita\n\n\n\nâ€œEl cÃ³digo se lee mÃ¡s a menudo de lo que se escribe.â€ â€” Guido van Rossum\n\n\nCuando escribes cÃ³digo, lo haces para dos audiencias principales: tus usuarios y tus desarrolladores (incluyÃ©ndote a ti mismo). Ambas audiencias son igualmente cruciales. Si eres como yo, es posible que hayas abierto antiguas bases de cÃ³digo y te hayas preguntado: â€œÂ¿En quÃ© estaba pensando?â€. Si tienes dificultades para entender tu propio cÃ³digo, imagina lo que tus usuarios u otros desarrolladores sienten cuando intentan utilizarlo o contribuir a tu cÃ³digo.\nPor otro lado, es probable que hayas pasado por situaciones en las que deseabas realizar algo en Python y encontraste lo que parecÃ­a ser una excelente biblioteca que podrÃ­a hacer el trabajo. Sin embargo, al comenzar a usar la biblioteca, buscaste ejemplos, descripciones o incluso documentaciÃ³n oficial sobre cÃ³mo realizar una tarea especÃ­fica y no pudiste encontrar una soluciÃ³n de inmediato.\nDespuÃ©s de buscar durante un tiempo, te das cuenta de que la documentaciÃ³n es insuficiente o, peor aÃºn, estÃ¡ completamente ausente. Esta es una experiencia frustrante que te impide utilizar la biblioteca, sin importar cuÃ¡n bueno o eficiente sea el cÃ³digo. Daniele Procida resumiÃ³ esta situaciÃ³n de manera acertada:\n!!! quote â€œNo importa cuÃ¡n bueno sea tu software, porque si la documentaciÃ³n no es lo suficientemente buena, la gente no lo usarÃ¡.â€ â€” Daniele Procida\nEn esta guÃ­a, aprenderÃ¡s desde cero cÃ³mo documentar adecuadamente tu cÃ³digo en Python, desde los scripts mÃ¡s pequeÃ±os hasta los proyectos mÃ¡s grandes de Python, para evitar que tus usuarios se sientan frustrados al usar o contribuir a tu proyecto.\n\n\n\n\nAntes de sumergirnos en el arte de documentar tu cÃ³digo en Python, es crucial establecer una distinciÃ³n fundamental: los comentarios y la documentaciÃ³n desempeÃ±an roles distintos y estÃ¡n dirigidos a audiencias diferentes.\nComentarios:\nEn tÃ©rminos generales, los comentarios estÃ¡n diseÃ±ados para proporcionar informaciÃ³n sobre tu cÃ³digo a los desarrolladores.\nLa audiencia principal a la que se dirigen son aquellos que mantienen y trabajan en el cÃ³digo Python. Cuando se combinan con un cÃ³digo bien escrito, los comentarios actÃºan como guÃ­as que ayudan a los lectores a comprender mejor el cÃ³digo, su propÃ³sito y su estructura. Esto se alinea perfectamente con la sabia observaciÃ³n de Jeff Atwood,\n!!! quote â€œEl cÃ³digo te dice cÃ³mo; los comentarios te dicen por quÃ©.â€ â€” Jeff Atwood\nDocumentaciÃ³n del CÃ³digo:\nPor otro lado, la documentaciÃ³n del cÃ³digo se enfoca en describir el uso y la funcionalidad del cÃ³digo a los usuarios. Aunque puede ser Ãºtil durante el proceso de desarrollo, su audiencia principal son los usuarios finales del software. La siguiente secciÃ³n de este artÃ­culo se adentrarÃ¡ en cuÃ¡ndo y cÃ³mo debes abordar la tarea de comentar tu cÃ³digo en Python.\n\n\n\n\nEn Python, los comentarios son esenciales para proporcionar informaciÃ³n adicional sobre tu cÃ³digo.\nSe crean utilizando el sÃ­mbolo de nÃºmero (#) y deben ser declaraciones breves, no mÃ¡s largas que unas pocas frases. AquÃ­ tienes un ejemplo simple:\ndef hello_world():    \n    # Un comentario simple antes de una simple declaraciÃ³n de impresiÃ³n\n    print(\"Hola Mundo\")\nDe acuerdo con las pautas de estilo de cÃ³digo de Python (PEP 8), los comentarios deben tener una longitud mÃ¡xima de 72 caracteres. Esto es vÃ¡lido incluso si tu proyecto cambia la longitud mÃ¡xima de lÃ­nea recomendada para que sea mayor que los 80 caracteres. Si un comentario va a superar el lÃ­mite de caracteres recomendado, es apropiado usar mÃºltiples lÃ­neas para el comentario:\ndef hello_long_world():     \n    # Una declaraciÃ³n muy larga que sigue y sigue y sigue y sigue y sigue \n    # sin terminar hasta que alcance el lÃ­mite de 80 caracteres\n    print(\"Â¡Hola Mundoooooooooooooooooooooooooooooooooooooooooooooooooooooo!\")\nComentar tu cÃ³digo sirve para varios propÃ³sitos, incluyendo:\n\nPlanificaciÃ³n y RevisiÃ³n: Durante el desarrollo de nuevas partes de tu cÃ³digo, los comentarios pueden servir como una forma de planificar o esquematizar esa secciÃ³n. Es importante recordar eliminar estos comentarios una vez que se haya implementado y revisado/testeado el cÃ³digo real:\n# Primer paso\n# Segundo paso\n# Tercer paso\nDescripciÃ³n del CÃ³digo: Los comentarios se utilizan para explicar la intenciÃ³n de secciones especÃ­ficas del cÃ³digo:\n# Intentar una conexiÃ³n basada en configuraciones anteriores. Si no tiene Ã©xito,\n# solicitar al usuario nuevas configuraciones.\nDescripciÃ³n AlgorÃ­tmica: Al usar algoritmos, especialmente los complicados, es Ãºtil explicar cÃ³mo funcionan o cÃ³mo se implementan en tu cÃ³digo. TambiÃ©n es apropiado describir por quÃ© seleccionaste un algoritmo especÃ­fico en lugar de otro:\n# Usar el ordenamiento rÃ¡pido para obtener ganancias de rendimiento.\nEtiquetado: Puedes utilizar etiquetas para seÃ±alar secciones especÃ­ficas de cÃ³digo donde se encuentran problemas conocidos o Ã¡reas de mejora. Algunos ejemplos son BUG, FIXME y TODO:\n# TODO: Agregar condiciÃ³n para cuando 'val' sea None\n\nLos comentarios en tu cÃ³digo deben ser breves y centrados. Evita comentarios largos cuando sea posible. AdemÃ¡s, sigue las siguientes cuatro reglas esenciales sugeridas por Jeff Atwood:\n\nMantÃ©n los Comentarios Cerca del CÃ³digo: Los comentarios deben estar lo mÃ¡s cerca posible del cÃ³digo que describen. Los comentarios distantes del cÃ³digo descriptivo son frustrantes y pueden pasarse por alto fÃ¡cilmente al realizar actualizaciones.\nEvita el Formato Complejo: No uses formatos complejos como tablas o figuras ASCII. Estos formatos pueden distraer y ser difÃ­ciles de mantener con el tiempo.\nEvita InformaciÃ³n Redundante: SupÃ³n que el lector del cÃ³digo tiene un entendimiento bÃ¡sico de los principios de programaciÃ³n y la sintaxis del lenguaje. No incluyas informaciÃ³n redundante.\nDiseÃ±a Tu CÃ³digo para que se Comente por SÃ­ Mismo: La forma mÃ¡s fÃ¡cil de entender el cÃ³digo es leyÃ©ndolo. Cuando diseÃ±es tu cÃ³digo utilizando conceptos claros y fÃ¡ciles de entender, ayudarÃ¡s al lector a comprender tu intenciÃ³n de manera rÃ¡pida y sencilla.\n\nRecuerda que los comentarios estÃ¡n diseÃ±ados para los lectores, incluyÃ©ndote a ti mismo, para ayudarlos a comprender el propÃ³sito y diseÃ±o del software.\n\n\n\nEl Type Hinting es una caracterÃ­stica que te permite indicar explÃ­citamente los tipos de datos que esperas en las funciones y mÃ©todos. Aunque Python es un lenguaje de programaciÃ³n de tipado dinÃ¡mico, el Type Hinting no cambia esa naturaleza, pero proporciona informaciÃ³n adicional a los desarrolladores y a las herramientas de anÃ¡lisis estÃ¡tico sobre cÃ³mo deberÃ­a funcionar el cÃ³digo.\nEl Type Hinting no afecta el comportamiento en tiempo de ejecuciÃ³n, por lo que no impide que el cÃ³digo funcione si los tipos no coinciden.\nEn cambio, es una herramienta para ayudar a los desarrolladores a comprender y depurar el cÃ³digo de manera mÃ¡s eficiente y prevenir posibles errores.\nConsidera la siguiente funciÃ³n hello_name:\ndef hello_name(name: str) -&gt; str:\n    return f\"Hello {name}\"\nEn este ejemplo, hemos utilizado Type Hinting para especificar que el parÃ¡metro name debe ser una cadena (str) y que la funciÃ³n hello_name debe devolver una cadena (str). Esta informaciÃ³n es Ãºtil para otros desarrolladores que utilicen esta funciÃ³n porque ahora saben quÃ© tipo de dato esperar como entrada y quÃ© tipo de dato obtendrÃ¡n como resultado.\n\n\n\n\n\nUna parte fundamental de la documentaciÃ³n en Python son las docstrings, que son cadenas de texto utilizadas para describir funciones, clases, mÃ³dulos y mÃ¡s.\n\n\nLas docstrings son cadenas de documentaciÃ³n que se encuentran dentro del cÃ³digo fuente Python. Estas cadenas proporcionan informaciÃ³n sobre el propÃ³sito y el funcionamiento de funciones, clases y otros elementos del cÃ³digo.\nLas docstrings son especialmente valiosas para ayudar a los usuarios y desarrolladores a comprender cÃ³mo utilizar y trabajar con tu cÃ³digo.\nÂ¿CÃ³mo Funcionan las Docstrings?\nCuando definimos una funciÃ³n, clase o mÃ³dulo en Python, podemos incluir una docstring justo debajo de la definiciÃ³n. Por ejemplo:\ndef saludar(nombre):\n    \"\"\"Esta funciÃ³n imprime un saludo personalizado.\"\"\"\n    print(f\"Hola, {nombre}!\")\nLas docstrings se pueden acceder a travÃ©s del atributo __doc__ del objeto. Por ejemplo:\nprint(saludar.__doc__)\nLa salida serÃ­a: â€œEsta funciÃ³n imprime un saludo personalizado.â€ Las docstrings tambiÃ©n se utilizan en entornos de desarrollo interactivo y se muestran al utilizar la funciÃ³n help().\nManipulaciÃ³n de Docstrings\nEs importante destacar que puedes manipular directamente las docstrings. Sin embargo, existen restricciones para los objetos incorporados en Python. Por ejemplo, no puedes cambiar la docstring de un objeto str incorporado:\nstr.__doc__ = \"Â¡Esto no funcionarÃ¡ para objetos incorporados!\"\nPero para funciones y objetos personalizados, puedes establecer o modificar sus docstrings de la siguiente manera:\ndef decir_hola(nombre):\n    \"\"\"Una funciÃ³n simple que saluda a la manera de Richie.\"\"\"\n    print(f\"Hola {nombre}, Â¿soy yo a quien estÃ¡s buscando?\")\n\ndecir_hola.__doc__ = \"Una funciÃ³n que saluda estilo Richie Rich.\"\nUbicaciÃ³n EstratÃ©gica de las Docstrings\nUna forma mÃ¡s sencilla de definir docstrings es colocar una cadena literal justo debajo de la definiciÃ³n de la funciÃ³n o clase. Python automÃ¡ticamente interpreta esta cadena como la docstring. Por ejemplo:\ndef decir_hola(nombre):\n    \"\"\"Una funciÃ³n simple que saluda a la manera de Richie.\"\"\"\n    print(f\"Hola {nombre}, Â¿soy yo a quien estÃ¡s buscando?\")\n\n\n\nLas docstrings son elementos esenciales para documentar tu cÃ³digo Python de manera clara y coherente. Siguen convenciones y pautas que se describen en PEP 257.\nEl propÃ³sito de las docstrings es proporcionar a los usuarios de tu cÃ³digo un resumen conciso y Ãºtil del objeto, como una funciÃ³n, clase, mÃ³dulo o script. Deben ser lo suficientemente concisas como para ser fÃ¡ciles de mantener, pero lo suficientemente detalladas como para que los nuevos usuarios comprendan su propÃ³sito y cÃ³mo utilizar el objeto documentado.\n\n\nTodas las docstrings deben utilizar el formato de triple comilla doble (\"\"\") y deben colocarse justo debajo de la definiciÃ³n del objeto, ya sea en una sola lÃ­nea o en varias lÃ­neas:\nUna lÃ­nea:\n\"\"\"Esta es una lÃ­nea de resumen rÃ¡pida utilizada como descripciÃ³n del objeto.\"\"\"\nVarias lÃ­neas:\n\"\"\"\nEsta es la lÃ­nea de resumen\nEsta es la elaboraciÃ³n adicional de la docstring. Dentro de esta secciÃ³n, puedes proporcionar mÃ¡s detalles segÃºn sea apropiado para la situaciÃ³n. Observa que el resumen y la elaboraciÃ³n estÃ¡n separados por una nueva lÃ­nea en blanco.\n\"\"\"\nEs importante destacar que todas las docstrings de varias lÃ­neas deben seguir un patrÃ³n especÃ­fico:\n\nUna lÃ­nea de resumen de una sola lÃ­nea.\nUna lÃ­nea en blanco despuÃ©s del resumen.\nCualquier elaboraciÃ³n adicional de la docstring.\nOtra lÃ­nea en blanco.\n\nAdemÃ¡s, todas las docstrings deben tener una longitud mÃ¡xima de caracteres que sigue las mismas pautas que los comentarios, que es de 72 caracteres.\n\n\n\nLas docstrings de clase se crean para la clase en sÃ­, asÃ­ como para cualquier mÃ©todo de clase. Las docstrings se colocan inmediatamente despuÃ©s de la clase o el mÃ©todo de clase, con un nivel de sangrÃ­a:\nclass ClaseSimple:\n    \"\"\"AquÃ­ van las docstrings de clase.\"\"\"\n    def decir_hola(self, nombre: str):\n        \"\"\"AquÃ­ van las docstrings de mÃ©todo de clase.\"\"\"\n        print(f'Hola {nombre}')\nLas docstrings de clase deben contener la siguiente informaciÃ³n:\n\nUn breve resumen de su propÃ³sito y comportamiento.\nCualquier mÃ©todo pÃºblico, junto con una breve descripciÃ³n.\nCualquier propiedad de clase (atributos).\nCualquier cosa relacionada con la interfaz para los subclases, si la clase estÃ¡ destinada a ser subclaseada.\n\nLos parÃ¡metros del constructor de clase deben documentarse dentro de la docstring del mÃ©todo __init__ de la clase. Los mÃ©todos individuales deben documentarse utilizando sus propias docstrings individuales. Las docstrings de mÃ©todo de clase deben contener lo siguiente:\n\nUna breve descripciÃ³n de lo que hace el mÃ©todo y para quÃ© se utiliza.\nCualquier argumento (tanto requerido como opcional) que se pase, incluidos los argumentos de palabras clave.\nEtiqueta para cualquier argumento que se considere opcional o tenga un valor predeterminado.\nCualquier efecto secundario que ocurra al ejecutar el mÃ©todo.\nCualquier excepciÃ³n que se genere.\nCualquier restricciÃ³n sobre cuÃ¡ndo se puede llamar al mÃ©todo.\n\nEchemos un vistazo a un ejemplo simple de una clase de datos que representa un Animal. Esta clase contendrÃ¡ algunas propiedades de clase, propiedades de instancia, un __init__ y un Ãºnico mÃ©todo de instancia:\nclass Animal:\n    \"\"\"Una clase utilizada para representar un Animal\n    \n    Attributes:\n        dice_str (str): una cadena formateada para imprimir lo que dice el animal\n        nombre (str): el nombre del animal\n        sonido (str): el sonido que hace el animal\n        num_patas (int): el nÃºmero de patas del animal (predeterminado 4)\n    \"\"\"\n    \n    dice_str = \"Un {nombre} dice {sonido}\"\n    \n    def __init__(self, nombre, sonido, num_patas=4):\n        \"\"\"Inicializa una nueva instancia de Animal\n        \n        Parameters:\n            nombre (str): El nombre del animal\n            sonido (str): El sonido que hace el animal\n            num_patas (int, opcional): El nÃºmero de patas del animal (predeterminado es 4)\n        \"\"\"\n        self.nombre = nombre\n        self.sonido = sonido\n        self.num_patas = num_patas\n        \n    def dice(self, sonido=None):\n        \"\"\"Imprime el nombre del animal y el sonido que hace.\n        \n        Si no se pasa el argumento `sonido`, se utiliza el sonido predeterminado del Animal.\n        \n        Parameters:\n            sonido (str, opcional): El sonido que hace el animal (predeterminado es None)\n        \n        Raises:\n            NotImplementedError: Si no se establece ningÃºn sonido para el animal o se pasa como parÃ¡metro.\n        \"\"\"\n        if self.sonido is None and sonido is None:\n            raise NotImplementedError(\"Â¡No se admiten animales silenciosos!\")\n        sonido_salida = self.sonido if sonido is None else sonido\n        print(self.dice_str.format(nombre=self.nombre, sonido=sonido_salida))\n\n\n\n\n\nExisten formatos especÃ­ficos de docstrings que pueden ser utilizados para ayudar a los analizadores de docstrings y a los usuarios a tener un formato familiar y reconocido.\nAlgunos de los formatos mÃ¡s comunes son los siguientes:\n\n\n\nTipo de Formato\nDescripciÃ³n\nCompatible con Sphinx\nEspecificaciÃ³n Formal\n\n\n\n\nGoogle docstrings\nForma de documentaciÃ³n recomendada por Google\nSÃ­\nNo\n\n\nreStructuredText\nEstÃ¡ndar oficial de documentaciÃ³n de Python; no es amigable para principiantes pero rico en caracterÃ­sticas\nSÃ­\nSÃ­\n\n\nNumPy/SciPy docstrings\nCombinaciÃ³n de reStructuredText y Docstrings de Google utilizada por NumPy\nSÃ­\nSÃ­\n\n\nEpytext\nUna adaptaciÃ³n de Epydoc para Python; ideal para desarrolladores de Java\nNo oficialmente\nSÃ­\n\n\n\nLa elecciÃ³n del formato de docstring depende de ti, pero debes mantener el mismo formato en todo tu documento o proyecto. A continuaciÃ³n, se presentan ejemplos de cada tipo para darte una idea de cÃ³mo se ve cada formato de documentaciÃ³n.\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cÃ¡lculo\n\nArgs:\n    file_loc (str): La ubicaciÃ³n del archivo de la hoja de cÃ¡lculo.\n    print_cols (bool): Una bandera utilizada para imprimir las columnas en la consola\n        (el valor predeterminado es Falso)\n\nReturns:\n    list: una lista de cadenas que representan las columnas de encabezado\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cÃ¡lculo\n\n:param file_loc: La ubicaciÃ³n del archivo de la hoja de cÃ¡lculo\n:type file_loc: str\n:param print_cols: Una bandera utilizada para imprimir las columnas en la consola\n    (el valor predeterminado es Falso)\n:type print_cols: bool\n\n:returns: una lista de cadenas que representan las columnas de encabezado\n:rtype: list\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cÃ¡lculo\n\nParameters\n----------\nfile_loc : str\n    La ubicaciÃ³n del archivo de la hoja de cÃ¡lculo\nprint_cols : bool, opcional\n    Una bandera utilizada para imprimir las columnas en la consola (el valor predeterminado es Falso)\n\nReturns\n-------\nlist\n    una lista de cadenas que representan las columnas de encabezado\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cÃ¡lculo\n\n@type file_loc: str\n@param file_loc: La ubicaciÃ³n del archivo de la hoja de cÃ¡lculo\n@type print_cols: bool\n@param print_cols: Una bandera utilizada para imprimir las columnas en la consola\n    (el valor predeterminado es Falso)\n@rtype: list\n@returns: una lista de cadenas que representan las columnas de encabezado\n\"\"\"\nEstos ejemplos te proporcionan una idea de cÃ³mo se estructuran y formatean las docstrings en diferentes estilos de documentaciÃ³n.\nPuedes elegir el que mejor se adapte a tus preferencias y necesidades de documentaciÃ³n, pero asegÃºrate de mantener la coherencia en todo tu proyecto.\n\n\n\n\n\nLos proyectos de Python vienen en todo tipo de formas, tamaÃ±os y propÃ³sitos. La forma en que documentas tu proyecto debe adaptarse a tu situaciÃ³n especÃ­fica. Ten en cuenta quiÃ©nes serÃ¡n los usuarios de tu proyecto y adÃ¡ptate a sus necesidades. Dependiendo del tipo de proyecto, se recomiendan ciertos aspectos de la documentaciÃ³n. La estructura general del proyecto y su documentaciÃ³n debe ser la siguiente:\nproject_root/\nâ”‚\nâ”œâ”€â”€ project/  # Project source code\nâ”œâ”€â”€ docs/\nâ”œâ”€â”€ README\nâ”œâ”€â”€ HOW_TO_CONTRIBUTE\nâ”œâ”€â”€ CODE_OF_CONDUCT\nâ”œâ”€â”€ examples.py\nEsta estructura de directorios es un diseÃ±o comÃºn para organizar un proyecto de software en Python. A continuaciÃ³n, se explica en detalle cada elemento de esta estructura:\n\nproject_root (Directorio RaÃ­z del Proyecto): Este es el directorio principal que contiene todos los archivos y carpetas relacionados con tu proyecto. Es el punto de partida para tu proyecto.\nproject/ (Carpeta â€œprojectâ€): Esta carpeta suele contener el cÃ³digo fuente principal de tu proyecto. AquÃ­ se almacenan todos los archivos de Python que forman parte de tu proyecto. Puedes organizar estos archivos en subdirectorios segÃºn la estructura de tu proyecto. Por ejemplo, puedes tener subdirectorios para mÃ³dulos especÃ­ficos o componentes del proyecto.\ndocs/ (Carpeta â€œdocsâ€): La carpeta â€œdocsâ€ se utiliza para almacenar la documentaciÃ³n de tu proyecto. AquÃ­ puedes incluir documentos explicativos, manuales de usuario, instrucciones de instalaciÃ³n y cualquier otra documentaciÃ³n relevante. Mantener una documentaciÃ³n clara y organizada es esencial para que los usuarios comprendan y utilicen tu proyecto de manera efectiva.\nREADME: El archivo â€œREADMEâ€ es un documento importante que proporciona una breve descripciÃ³n de tu proyecto y su propÃ³sito. Suele incluir informaciÃ³n sobre cÃ³mo instalar y utilizar el proyecto, asÃ­ como otros detalles importantes. Los usuarios suelen consultar este archivo primero cuando exploran un proyecto.\nHOW_TO_CONTRIBUTE: Este archivo contiene instrucciones para las personas que deseen contribuir al desarrollo de tu proyecto. Incluye detalles sobre cÃ³mo pueden colaborar, enviar correcciones, agregar nuevas funciones y seguir las pautas de contribuciÃ³n.\nCODE_OF_CONDUCT: El archivo â€œCODE_OF_CONDUCTâ€ establece las reglas y pautas de comportamiento que deben seguir los colaboradores y usuarios del proyecto. Define cÃ³mo deben interactuar entre sÃ­ de manera respetuosa y profesional. TambiÃ©n puede indicar las consecuencias en caso de violaciÃ³n del cÃ³digo de conducta.\nexamples.py: Este archivo es un script de Python que contiene ejemplos simples de cÃ³mo utilizar las funcionalidades de tu proyecto. Estos ejemplos pueden ayudar a los usuarios a comprender cÃ³mo utilizar tu cÃ³digo en situaciones reales y proporcionar ejemplos de uso prÃ¡ctico.\n\n\n\n\nLa documentaciÃ³n es una parte fundamental de cualquier proyecto de desarrollo de software. Proporciona informaciÃ³n crucial sobre cÃ³mo utilizar, mantener y contribuir al cÃ³digo. En el ecosistema de Python, existen varias bibliotecas y herramientas que facilitan la tarea de documentar el cÃ³digo de manera efectiva. En este artÃ­culo, exploraremos algunas de las principales bibliotecas de Python utilizadas para documentar cÃ³digo.\n\n\n\nSphinx es una de las herramientas de documentaciÃ³n mÃ¡s populares en el mundo de Python. Fue originalmente desarrollada para documentar la propia documentaciÃ³n de Python y se ha convertido en una elecciÃ³n comÃºn para proyectos de cÃ³digo abierto y proyectos internos. Algunas de sus caracterÃ­sticas clave incluyen:\n\nGeneraciÃ³n de documentaciÃ³n en varios formatos, incluyendo HTML, PDF, ePub y mÃ¡s.\nUtiliza reStructuredText como su formato de marcado predeterminado, que es altamente estructurado y permite documentar de manera eficiente los aspectos tÃ©cnicos.\nAmplia gama de extensiones y complementos que permiten personalizar y mejorar la documentaciÃ³n.\nAdmite la generaciÃ³n automÃ¡tica de documentaciÃ³n a partir de docstrings en el cÃ³digo Python.\nEs especialmente adecuado para documentar bibliotecas, API y proyectos tÃ©cnicos.\n\nSphinx es altamente configurable y puede generar documentaciÃ³n de alta calidad y profesional. Sin embargo, puede requerir un tiempo de configuraciÃ³n inicial y tiene una curva de aprendizaje empinada para los principiantes.\n\n\n\n\nMkDocs es una herramienta de generaciÃ³n de documentaciÃ³n que se centra en la simplicidad y la facilidad de uso. EstÃ¡ diseÃ±ada para crear documentaciÃ³n de proyectos de una manera simple y rÃ¡pida, principalmente enfocada en la generaciÃ³n de sitios web de documentaciÃ³n. Algunas de sus caracterÃ­sticas clave incluyen:\n\nUtiliza Markdown como formato de marcado predeterminado, que es fÃ¡cil de aprender y escribir.\nOfrece una interfaz de lÃ­nea de comandos simple para iniciar y generar sitios de documentaciÃ³n.\nProporciona temas y extensiones para personalizar el aspecto y la funcionalidad de la documentaciÃ³n generada.\nIdeal para proyectos de cÃ³digo abierto y documentaciÃ³n de proyectos pequeÃ±os a medianos.\n\nMkDocs es especialmente adecuado para proyectos con necesidades de documentaciÃ³n simples. Es fÃ¡cil de aprender y usar, lo que lo convierte en una excelente opciÃ³n para principiantes. Sin embargo, puede ser limitado en funcionalidad en comparaciÃ³n con Sphinx para proyectos tÃ©cnicos y complejos.\n\n\n\nMkDocs-Material es un tema personalizado para MkDocs, una popular herramienta de generaciÃ³n de sitios web estÃ¡ticos diseÃ±ada para crear documentaciÃ³n de proyectos de manera sencilla y efectiva. Este tema, conocido como â€œMaterial for MkDocsâ€, se inspira en el elegante diseÃ±o de Material Design de Google y estÃ¡ diseÃ±ado para ofrecer una experiencia de documentaciÃ³n moderna y atractiva.\nUna de las principales caracterÃ­sticas de MkDocs-Material es su enfoque en la legibilidad y la facilidad de navegaciÃ³n. Esto se logra mediante un diseÃ±o limpio y organizado que hace que la documentaciÃ³n sea mÃ¡s accesible para los usuarios. AdemÃ¡s, el tema proporciona herramientas Ãºtiles para mejorar la experiencia de los lectores, como una funciÃ³n de bÃºsqueda integrada que permite a los usuarios encontrar rÃ¡pidamente la informaciÃ³n que necesitan.\nOtra ventaja de MkDocs-Material es su navegaciÃ³n intuitiva, que facilita a los usuarios la exploraciÃ³n de la documentaciÃ³n y la navegaciÃ³n entre secciones y pÃ¡ginas. Esto es fundamental para garantizar que los usuarios puedan acceder fÃ¡cilmente a la informaciÃ³n que estÃ¡n buscando sin esfuerzo.\n\n\n\n\n\nLa documentaciÃ³n de proyectos sigue una progresiÃ³n simple:\n\nSin DocumentaciÃ³n\nAlguna DocumentaciÃ³n\nDocumentaciÃ³n Completa\nBuena DocumentaciÃ³n\nExcelente DocumentaciÃ³n\n\nSi te sientes perdido acerca de por dÃ³nde continuar con tu documentaciÃ³n, observa en quÃ© punto se encuentra tu proyecto en relaciÃ³n con la progresiÃ³n mencionada anteriormente. Â¿Tienes alguna documentaciÃ³n? Si no la tienes, comienza por ahÃ­. Si ya tienes algo de documentaciÃ³n pero te faltan algunos de los archivos clave del proyecto, comienza agregÃ¡ndolos.\nAl final, no te desanimes ni te sientas abrumado por la cantidad de trabajo necesario para documentar el cÃ³digo.\nUna vez que comiences a documentar tu cÃ³digo, te resultarÃ¡ mÃ¡s fÃ¡cil seguir adelante.\n\n\n\n\nDocumenting Python Code: A Complete Guide\nDocument Your Python Code and Projects With ChatGPT"
  },
  {
    "objectID": "posts/2023/art_docs.html#introducciÃ³n",
    "href": "posts/2023/art_docs.html#introducciÃ³n",
    "title": "DocumentaciÃ³n",
    "section": "",
    "text": "Esperamos que, si estÃ¡s leyendo este tutorial, ya comprendas la importancia de documentar tu cÃ³digo. Pero, por si acaso, permÃ­teme citar algo que Guido mencionÃ³ en la reciente PyCon 2016:\n\n\n\n\n\n\nCita\n\n\n\nâ€œEl cÃ³digo se lee mÃ¡s a menudo de lo que se escribe.â€ â€” Guido van Rossum\n\n\nCuando escribes cÃ³digo, lo haces para dos audiencias principales: tus usuarios y tus desarrolladores (incluyÃ©ndote a ti mismo). Ambas audiencias son igualmente cruciales. Si eres como yo, es posible que hayas abierto antiguas bases de cÃ³digo y te hayas preguntado: â€œÂ¿En quÃ© estaba pensando?â€. Si tienes dificultades para entender tu propio cÃ³digo, imagina lo que tus usuarios u otros desarrolladores sienten cuando intentan utilizarlo o contribuir a tu cÃ³digo.\nPor otro lado, es probable que hayas pasado por situaciones en las que deseabas realizar algo en Python y encontraste lo que parecÃ­a ser una excelente biblioteca que podrÃ­a hacer el trabajo. Sin embargo, al comenzar a usar la biblioteca, buscaste ejemplos, descripciones o incluso documentaciÃ³n oficial sobre cÃ³mo realizar una tarea especÃ­fica y no pudiste encontrar una soluciÃ³n de inmediato.\nDespuÃ©s de buscar durante un tiempo, te das cuenta de que la documentaciÃ³n es insuficiente o, peor aÃºn, estÃ¡ completamente ausente. Esta es una experiencia frustrante que te impide utilizar la biblioteca, sin importar cuÃ¡n bueno o eficiente sea el cÃ³digo. Daniele Procida resumiÃ³ esta situaciÃ³n de manera acertada:\n!!! quote â€œNo importa cuÃ¡n bueno sea tu software, porque si la documentaciÃ³n no es lo suficientemente buena, la gente no lo usarÃ¡.â€ â€” Daniele Procida\nEn esta guÃ­a, aprenderÃ¡s desde cero cÃ³mo documentar adecuadamente tu cÃ³digo en Python, desde los scripts mÃ¡s pequeÃ±os hasta los proyectos mÃ¡s grandes de Python, para evitar que tus usuarios se sientan frustrados al usar o contribuir a tu proyecto."
  },
  {
    "objectID": "posts/2023/art_docs.html#comentarios-vs-documentaciÃ³n",
    "href": "posts/2023/art_docs.html#comentarios-vs-documentaciÃ³n",
    "title": "DocumentaciÃ³n",
    "section": "",
    "text": "Antes de sumergirnos en el arte de documentar tu cÃ³digo en Python, es crucial establecer una distinciÃ³n fundamental: los comentarios y la documentaciÃ³n desempeÃ±an roles distintos y estÃ¡n dirigidos a audiencias diferentes.\nComentarios:\nEn tÃ©rminos generales, los comentarios estÃ¡n diseÃ±ados para proporcionar informaciÃ³n sobre tu cÃ³digo a los desarrolladores.\nLa audiencia principal a la que se dirigen son aquellos que mantienen y trabajan en el cÃ³digo Python. Cuando se combinan con un cÃ³digo bien escrito, los comentarios actÃºan como guÃ­as que ayudan a los lectores a comprender mejor el cÃ³digo, su propÃ³sito y su estructura. Esto se alinea perfectamente con la sabia observaciÃ³n de Jeff Atwood,\n!!! quote â€œEl cÃ³digo te dice cÃ³mo; los comentarios te dicen por quÃ©.â€ â€” Jeff Atwood\nDocumentaciÃ³n del CÃ³digo:\nPor otro lado, la documentaciÃ³n del cÃ³digo se enfoca en describir el uso y la funcionalidad del cÃ³digo a los usuarios. Aunque puede ser Ãºtil durante el proceso de desarrollo, su audiencia principal son los usuarios finales del software. La siguiente secciÃ³n de este artÃ­culo se adentrarÃ¡ en cuÃ¡ndo y cÃ³mo debes abordar la tarea de comentar tu cÃ³digo en Python."
  },
  {
    "objectID": "posts/2023/art_docs.html#comentarios",
    "href": "posts/2023/art_docs.html#comentarios",
    "title": "DocumentaciÃ³n",
    "section": "",
    "text": "En Python, los comentarios son esenciales para proporcionar informaciÃ³n adicional sobre tu cÃ³digo.\nSe crean utilizando el sÃ­mbolo de nÃºmero (#) y deben ser declaraciones breves, no mÃ¡s largas que unas pocas frases. AquÃ­ tienes un ejemplo simple:\ndef hello_world():    \n    # Un comentario simple antes de una simple declaraciÃ³n de impresiÃ³n\n    print(\"Hola Mundo\")\nDe acuerdo con las pautas de estilo de cÃ³digo de Python (PEP 8), los comentarios deben tener una longitud mÃ¡xima de 72 caracteres. Esto es vÃ¡lido incluso si tu proyecto cambia la longitud mÃ¡xima de lÃ­nea recomendada para que sea mayor que los 80 caracteres. Si un comentario va a superar el lÃ­mite de caracteres recomendado, es apropiado usar mÃºltiples lÃ­neas para el comentario:\ndef hello_long_world():     \n    # Una declaraciÃ³n muy larga que sigue y sigue y sigue y sigue y sigue \n    # sin terminar hasta que alcance el lÃ­mite de 80 caracteres\n    print(\"Â¡Hola Mundoooooooooooooooooooooooooooooooooooooooooooooooooooooo!\")\nComentar tu cÃ³digo sirve para varios propÃ³sitos, incluyendo:\n\nPlanificaciÃ³n y RevisiÃ³n: Durante el desarrollo de nuevas partes de tu cÃ³digo, los comentarios pueden servir como una forma de planificar o esquematizar esa secciÃ³n. Es importante recordar eliminar estos comentarios una vez que se haya implementado y revisado/testeado el cÃ³digo real:\n# Primer paso\n# Segundo paso\n# Tercer paso\nDescripciÃ³n del CÃ³digo: Los comentarios se utilizan para explicar la intenciÃ³n de secciones especÃ­ficas del cÃ³digo:\n# Intentar una conexiÃ³n basada en configuraciones anteriores. Si no tiene Ã©xito,\n# solicitar al usuario nuevas configuraciones.\nDescripciÃ³n AlgorÃ­tmica: Al usar algoritmos, especialmente los complicados, es Ãºtil explicar cÃ³mo funcionan o cÃ³mo se implementan en tu cÃ³digo. TambiÃ©n es apropiado describir por quÃ© seleccionaste un algoritmo especÃ­fico en lugar de otro:\n# Usar el ordenamiento rÃ¡pido para obtener ganancias de rendimiento.\nEtiquetado: Puedes utilizar etiquetas para seÃ±alar secciones especÃ­ficas de cÃ³digo donde se encuentran problemas conocidos o Ã¡reas de mejora. Algunos ejemplos son BUG, FIXME y TODO:\n# TODO: Agregar condiciÃ³n para cuando 'val' sea None\n\nLos comentarios en tu cÃ³digo deben ser breves y centrados. Evita comentarios largos cuando sea posible. AdemÃ¡s, sigue las siguientes cuatro reglas esenciales sugeridas por Jeff Atwood:\n\nMantÃ©n los Comentarios Cerca del CÃ³digo: Los comentarios deben estar lo mÃ¡s cerca posible del cÃ³digo que describen. Los comentarios distantes del cÃ³digo descriptivo son frustrantes y pueden pasarse por alto fÃ¡cilmente al realizar actualizaciones.\nEvita el Formato Complejo: No uses formatos complejos como tablas o figuras ASCII. Estos formatos pueden distraer y ser difÃ­ciles de mantener con el tiempo.\nEvita InformaciÃ³n Redundante: SupÃ³n que el lector del cÃ³digo tiene un entendimiento bÃ¡sico de los principios de programaciÃ³n y la sintaxis del lenguaje. No incluyas informaciÃ³n redundante.\nDiseÃ±a Tu CÃ³digo para que se Comente por SÃ­ Mismo: La forma mÃ¡s fÃ¡cil de entender el cÃ³digo es leyÃ©ndolo. Cuando diseÃ±es tu cÃ³digo utilizando conceptos claros y fÃ¡ciles de entender, ayudarÃ¡s al lector a comprender tu intenciÃ³n de manera rÃ¡pida y sencilla.\n\nRecuerda que los comentarios estÃ¡n diseÃ±ados para los lectores, incluyÃ©ndote a ti mismo, para ayudarlos a comprender el propÃ³sito y diseÃ±o del software.\n\n\n\nEl Type Hinting es una caracterÃ­stica que te permite indicar explÃ­citamente los tipos de datos que esperas en las funciones y mÃ©todos. Aunque Python es un lenguaje de programaciÃ³n de tipado dinÃ¡mico, el Type Hinting no cambia esa naturaleza, pero proporciona informaciÃ³n adicional a los desarrolladores y a las herramientas de anÃ¡lisis estÃ¡tico sobre cÃ³mo deberÃ­a funcionar el cÃ³digo.\nEl Type Hinting no afecta el comportamiento en tiempo de ejecuciÃ³n, por lo que no impide que el cÃ³digo funcione si los tipos no coinciden.\nEn cambio, es una herramienta para ayudar a los desarrolladores a comprender y depurar el cÃ³digo de manera mÃ¡s eficiente y prevenir posibles errores.\nConsidera la siguiente funciÃ³n hello_name:\ndef hello_name(name: str) -&gt; str:\n    return f\"Hello {name}\"\nEn este ejemplo, hemos utilizado Type Hinting para especificar que el parÃ¡metro name debe ser una cadena (str) y que la funciÃ³n hello_name debe devolver una cadena (str). Esta informaciÃ³n es Ãºtil para otros desarrolladores que utilicen esta funciÃ³n porque ahora saben quÃ© tipo de dato esperar como entrada y quÃ© tipo de dato obtendrÃ¡n como resultado."
  },
  {
    "objectID": "posts/2023/art_docs.html#docstrings",
    "href": "posts/2023/art_docs.html#docstrings",
    "title": "DocumentaciÃ³n",
    "section": "",
    "text": "Una parte fundamental de la documentaciÃ³n en Python son las docstrings, que son cadenas de texto utilizadas para describir funciones, clases, mÃ³dulos y mÃ¡s.\n\n\nLas docstrings son cadenas de documentaciÃ³n que se encuentran dentro del cÃ³digo fuente Python. Estas cadenas proporcionan informaciÃ³n sobre el propÃ³sito y el funcionamiento de funciones, clases y otros elementos del cÃ³digo.\nLas docstrings son especialmente valiosas para ayudar a los usuarios y desarrolladores a comprender cÃ³mo utilizar y trabajar con tu cÃ³digo.\nÂ¿CÃ³mo Funcionan las Docstrings?\nCuando definimos una funciÃ³n, clase o mÃ³dulo en Python, podemos incluir una docstring justo debajo de la definiciÃ³n. Por ejemplo:\ndef saludar(nombre):\n    \"\"\"Esta funciÃ³n imprime un saludo personalizado.\"\"\"\n    print(f\"Hola, {nombre}!\")\nLas docstrings se pueden acceder a travÃ©s del atributo __doc__ del objeto. Por ejemplo:\nprint(saludar.__doc__)\nLa salida serÃ­a: â€œEsta funciÃ³n imprime un saludo personalizado.â€ Las docstrings tambiÃ©n se utilizan en entornos de desarrollo interactivo y se muestran al utilizar la funciÃ³n help().\nManipulaciÃ³n de Docstrings\nEs importante destacar que puedes manipular directamente las docstrings. Sin embargo, existen restricciones para los objetos incorporados en Python. Por ejemplo, no puedes cambiar la docstring de un objeto str incorporado:\nstr.__doc__ = \"Â¡Esto no funcionarÃ¡ para objetos incorporados!\"\nPero para funciones y objetos personalizados, puedes establecer o modificar sus docstrings de la siguiente manera:\ndef decir_hola(nombre):\n    \"\"\"Una funciÃ³n simple que saluda a la manera de Richie.\"\"\"\n    print(f\"Hola {nombre}, Â¿soy yo a quien estÃ¡s buscando?\")\n\ndecir_hola.__doc__ = \"Una funciÃ³n que saluda estilo Richie Rich.\"\nUbicaciÃ³n EstratÃ©gica de las Docstrings\nUna forma mÃ¡s sencilla de definir docstrings es colocar una cadena literal justo debajo de la definiciÃ³n de la funciÃ³n o clase. Python automÃ¡ticamente interpreta esta cadena como la docstring. Por ejemplo:\ndef decir_hola(nombre):\n    \"\"\"Una funciÃ³n simple que saluda a la manera de Richie.\"\"\"\n    print(f\"Hola {nombre}, Â¿soy yo a quien estÃ¡s buscando?\")\n\n\n\nLas docstrings son elementos esenciales para documentar tu cÃ³digo Python de manera clara y coherente. Siguen convenciones y pautas que se describen en PEP 257.\nEl propÃ³sito de las docstrings es proporcionar a los usuarios de tu cÃ³digo un resumen conciso y Ãºtil del objeto, como una funciÃ³n, clase, mÃ³dulo o script. Deben ser lo suficientemente concisas como para ser fÃ¡ciles de mantener, pero lo suficientemente detalladas como para que los nuevos usuarios comprendan su propÃ³sito y cÃ³mo utilizar el objeto documentado.\n\n\nTodas las docstrings deben utilizar el formato de triple comilla doble (\"\"\") y deben colocarse justo debajo de la definiciÃ³n del objeto, ya sea en una sola lÃ­nea o en varias lÃ­neas:\nUna lÃ­nea:\n\"\"\"Esta es una lÃ­nea de resumen rÃ¡pida utilizada como descripciÃ³n del objeto.\"\"\"\nVarias lÃ­neas:\n\"\"\"\nEsta es la lÃ­nea de resumen\nEsta es la elaboraciÃ³n adicional de la docstring. Dentro de esta secciÃ³n, puedes proporcionar mÃ¡s detalles segÃºn sea apropiado para la situaciÃ³n. Observa que el resumen y la elaboraciÃ³n estÃ¡n separados por una nueva lÃ­nea en blanco.\n\"\"\"\nEs importante destacar que todas las docstrings de varias lÃ­neas deben seguir un patrÃ³n especÃ­fico:\n\nUna lÃ­nea de resumen de una sola lÃ­nea.\nUna lÃ­nea en blanco despuÃ©s del resumen.\nCualquier elaboraciÃ³n adicional de la docstring.\nOtra lÃ­nea en blanco.\n\nAdemÃ¡s, todas las docstrings deben tener una longitud mÃ¡xima de caracteres que sigue las mismas pautas que los comentarios, que es de 72 caracteres.\n\n\n\nLas docstrings de clase se crean para la clase en sÃ­, asÃ­ como para cualquier mÃ©todo de clase. Las docstrings se colocan inmediatamente despuÃ©s de la clase o el mÃ©todo de clase, con un nivel de sangrÃ­a:\nclass ClaseSimple:\n    \"\"\"AquÃ­ van las docstrings de clase.\"\"\"\n    def decir_hola(self, nombre: str):\n        \"\"\"AquÃ­ van las docstrings de mÃ©todo de clase.\"\"\"\n        print(f'Hola {nombre}')\nLas docstrings de clase deben contener la siguiente informaciÃ³n:\n\nUn breve resumen de su propÃ³sito y comportamiento.\nCualquier mÃ©todo pÃºblico, junto con una breve descripciÃ³n.\nCualquier propiedad de clase (atributos).\nCualquier cosa relacionada con la interfaz para los subclases, si la clase estÃ¡ destinada a ser subclaseada.\n\nLos parÃ¡metros del constructor de clase deben documentarse dentro de la docstring del mÃ©todo __init__ de la clase. Los mÃ©todos individuales deben documentarse utilizando sus propias docstrings individuales. Las docstrings de mÃ©todo de clase deben contener lo siguiente:\n\nUna breve descripciÃ³n de lo que hace el mÃ©todo y para quÃ© se utiliza.\nCualquier argumento (tanto requerido como opcional) que se pase, incluidos los argumentos de palabras clave.\nEtiqueta para cualquier argumento que se considere opcional o tenga un valor predeterminado.\nCualquier efecto secundario que ocurra al ejecutar el mÃ©todo.\nCualquier excepciÃ³n que se genere.\nCualquier restricciÃ³n sobre cuÃ¡ndo se puede llamar al mÃ©todo.\n\nEchemos un vistazo a un ejemplo simple de una clase de datos que representa un Animal. Esta clase contendrÃ¡ algunas propiedades de clase, propiedades de instancia, un __init__ y un Ãºnico mÃ©todo de instancia:\nclass Animal:\n    \"\"\"Una clase utilizada para representar un Animal\n    \n    Attributes:\n        dice_str (str): una cadena formateada para imprimir lo que dice el animal\n        nombre (str): el nombre del animal\n        sonido (str): el sonido que hace el animal\n        num_patas (int): el nÃºmero de patas del animal (predeterminado 4)\n    \"\"\"\n    \n    dice_str = \"Un {nombre} dice {sonido}\"\n    \n    def __init__(self, nombre, sonido, num_patas=4):\n        \"\"\"Inicializa una nueva instancia de Animal\n        \n        Parameters:\n            nombre (str): El nombre del animal\n            sonido (str): El sonido que hace el animal\n            num_patas (int, opcional): El nÃºmero de patas del animal (predeterminado es 4)\n        \"\"\"\n        self.nombre = nombre\n        self.sonido = sonido\n        self.num_patas = num_patas\n        \n    def dice(self, sonido=None):\n        \"\"\"Imprime el nombre del animal y el sonido que hace.\n        \n        Si no se pasa el argumento `sonido`, se utiliza el sonido predeterminado del Animal.\n        \n        Parameters:\n            sonido (str, opcional): El sonido que hace el animal (predeterminado es None)\n        \n        Raises:\n            NotImplementedError: Si no se establece ningÃºn sonido para el animal o se pasa como parÃ¡metro.\n        \"\"\"\n        if self.sonido is None and sonido is None:\n            raise NotImplementedError(\"Â¡No se admiten animales silenciosos!\")\n        sonido_salida = self.sonido if sonido is None else sonido\n        print(self.dice_str.format(nombre=self.nombre, sonido=sonido_salida))\n\n\n\n\n\nExisten formatos especÃ­ficos de docstrings que pueden ser utilizados para ayudar a los analizadores de docstrings y a los usuarios a tener un formato familiar y reconocido.\nAlgunos de los formatos mÃ¡s comunes son los siguientes:\n\n\n\nTipo de Formato\nDescripciÃ³n\nCompatible con Sphinx\nEspecificaciÃ³n Formal\n\n\n\n\nGoogle docstrings\nForma de documentaciÃ³n recomendada por Google\nSÃ­\nNo\n\n\nreStructuredText\nEstÃ¡ndar oficial de documentaciÃ³n de Python; no es amigable para principiantes pero rico en caracterÃ­sticas\nSÃ­\nSÃ­\n\n\nNumPy/SciPy docstrings\nCombinaciÃ³n de reStructuredText y Docstrings de Google utilizada por NumPy\nSÃ­\nSÃ­\n\n\nEpytext\nUna adaptaciÃ³n de Epydoc para Python; ideal para desarrolladores de Java\nNo oficialmente\nSÃ­\n\n\n\nLa elecciÃ³n del formato de docstring depende de ti, pero debes mantener el mismo formato en todo tu documento o proyecto. A continuaciÃ³n, se presentan ejemplos de cada tipo para darte una idea de cÃ³mo se ve cada formato de documentaciÃ³n.\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cÃ¡lculo\n\nArgs:\n    file_loc (str): La ubicaciÃ³n del archivo de la hoja de cÃ¡lculo.\n    print_cols (bool): Una bandera utilizada para imprimir las columnas en la consola\n        (el valor predeterminado es Falso)\n\nReturns:\n    list: una lista de cadenas que representan las columnas de encabezado\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cÃ¡lculo\n\n:param file_loc: La ubicaciÃ³n del archivo de la hoja de cÃ¡lculo\n:type file_loc: str\n:param print_cols: Una bandera utilizada para imprimir las columnas en la consola\n    (el valor predeterminado es Falso)\n:type print_cols: bool\n\n:returns: una lista de cadenas que representan las columnas de encabezado\n:rtype: list\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cÃ¡lculo\n\nParameters\n----------\nfile_loc : str\n    La ubicaciÃ³n del archivo de la hoja de cÃ¡lculo\nprint_cols : bool, opcional\n    Una bandera utilizada para imprimir las columnas en la consola (el valor predeterminado es Falso)\n\nReturns\n-------\nlist\n    una lista de cadenas que representan las columnas de encabezado\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cÃ¡lculo\n\n@type file_loc: str\n@param file_loc: La ubicaciÃ³n del archivo de la hoja de cÃ¡lculo\n@type print_cols: bool\n@param print_cols: Una bandera utilizada para imprimir las columnas en la consola\n    (el valor predeterminado es Falso)\n@rtype: list\n@returns: una lista de cadenas que representan las columnas de encabezado\n\"\"\"\nEstos ejemplos te proporcionan una idea de cÃ³mo se estructuran y formatean las docstrings en diferentes estilos de documentaciÃ³n.\nPuedes elegir el que mejor se adapte a tus preferencias y necesidades de documentaciÃ³n, pero asegÃºrate de mantener la coherencia en todo tu proyecto."
  },
  {
    "objectID": "posts/2023/art_docs.html#documentar-tus-proyectos-de-python",
    "href": "posts/2023/art_docs.html#documentar-tus-proyectos-de-python",
    "title": "DocumentaciÃ³n",
    "section": "",
    "text": "Los proyectos de Python vienen en todo tipo de formas, tamaÃ±os y propÃ³sitos. La forma en que documentas tu proyecto debe adaptarse a tu situaciÃ³n especÃ­fica. Ten en cuenta quiÃ©nes serÃ¡n los usuarios de tu proyecto y adÃ¡ptate a sus necesidades. Dependiendo del tipo de proyecto, se recomiendan ciertos aspectos de la documentaciÃ³n. La estructura general del proyecto y su documentaciÃ³n debe ser la siguiente:\nproject_root/\nâ”‚\nâ”œâ”€â”€ project/  # Project source code\nâ”œâ”€â”€ docs/\nâ”œâ”€â”€ README\nâ”œâ”€â”€ HOW_TO_CONTRIBUTE\nâ”œâ”€â”€ CODE_OF_CONDUCT\nâ”œâ”€â”€ examples.py\nEsta estructura de directorios es un diseÃ±o comÃºn para organizar un proyecto de software en Python. A continuaciÃ³n, se explica en detalle cada elemento de esta estructura:\n\nproject_root (Directorio RaÃ­z del Proyecto): Este es el directorio principal que contiene todos los archivos y carpetas relacionados con tu proyecto. Es el punto de partida para tu proyecto.\nproject/ (Carpeta â€œprojectâ€): Esta carpeta suele contener el cÃ³digo fuente principal de tu proyecto. AquÃ­ se almacenan todos los archivos de Python que forman parte de tu proyecto. Puedes organizar estos archivos en subdirectorios segÃºn la estructura de tu proyecto. Por ejemplo, puedes tener subdirectorios para mÃ³dulos especÃ­ficos o componentes del proyecto.\ndocs/ (Carpeta â€œdocsâ€): La carpeta â€œdocsâ€ se utiliza para almacenar la documentaciÃ³n de tu proyecto. AquÃ­ puedes incluir documentos explicativos, manuales de usuario, instrucciones de instalaciÃ³n y cualquier otra documentaciÃ³n relevante. Mantener una documentaciÃ³n clara y organizada es esencial para que los usuarios comprendan y utilicen tu proyecto de manera efectiva.\nREADME: El archivo â€œREADMEâ€ es un documento importante que proporciona una breve descripciÃ³n de tu proyecto y su propÃ³sito. Suele incluir informaciÃ³n sobre cÃ³mo instalar y utilizar el proyecto, asÃ­ como otros detalles importantes. Los usuarios suelen consultar este archivo primero cuando exploran un proyecto.\nHOW_TO_CONTRIBUTE: Este archivo contiene instrucciones para las personas que deseen contribuir al desarrollo de tu proyecto. Incluye detalles sobre cÃ³mo pueden colaborar, enviar correcciones, agregar nuevas funciones y seguir las pautas de contribuciÃ³n.\nCODE_OF_CONDUCT: El archivo â€œCODE_OF_CONDUCTâ€ establece las reglas y pautas de comportamiento que deben seguir los colaboradores y usuarios del proyecto. Define cÃ³mo deben interactuar entre sÃ­ de manera respetuosa y profesional. TambiÃ©n puede indicar las consecuencias en caso de violaciÃ³n del cÃ³digo de conducta.\nexamples.py: Este archivo es un script de Python que contiene ejemplos simples de cÃ³mo utilizar las funcionalidades de tu proyecto. Estos ejemplos pueden ayudar a los usuarios a comprender cÃ³mo utilizar tu cÃ³digo en situaciones reales y proporcionar ejemplos de uso prÃ¡ctico."
  },
  {
    "objectID": "posts/2023/art_docs.html#principales-librerÃ­as",
    "href": "posts/2023/art_docs.html#principales-librerÃ­as",
    "title": "DocumentaciÃ³n",
    "section": "",
    "text": "La documentaciÃ³n es una parte fundamental de cualquier proyecto de desarrollo de software. Proporciona informaciÃ³n crucial sobre cÃ³mo utilizar, mantener y contribuir al cÃ³digo. En el ecosistema de Python, existen varias bibliotecas y herramientas que facilitan la tarea de documentar el cÃ³digo de manera efectiva. En este artÃ­culo, exploraremos algunas de las principales bibliotecas de Python utilizadas para documentar cÃ³digo.\n\n\n\nSphinx es una de las herramientas de documentaciÃ³n mÃ¡s populares en el mundo de Python. Fue originalmente desarrollada para documentar la propia documentaciÃ³n de Python y se ha convertido en una elecciÃ³n comÃºn para proyectos de cÃ³digo abierto y proyectos internos. Algunas de sus caracterÃ­sticas clave incluyen:\n\nGeneraciÃ³n de documentaciÃ³n en varios formatos, incluyendo HTML, PDF, ePub y mÃ¡s.\nUtiliza reStructuredText como su formato de marcado predeterminado, que es altamente estructurado y permite documentar de manera eficiente los aspectos tÃ©cnicos.\nAmplia gama de extensiones y complementos que permiten personalizar y mejorar la documentaciÃ³n.\nAdmite la generaciÃ³n automÃ¡tica de documentaciÃ³n a partir de docstrings en el cÃ³digo Python.\nEs especialmente adecuado para documentar bibliotecas, API y proyectos tÃ©cnicos.\n\nSphinx es altamente configurable y puede generar documentaciÃ³n de alta calidad y profesional. Sin embargo, puede requerir un tiempo de configuraciÃ³n inicial y tiene una curva de aprendizaje empinada para los principiantes.\n\n\n\n\nMkDocs es una herramienta de generaciÃ³n de documentaciÃ³n que se centra en la simplicidad y la facilidad de uso. EstÃ¡ diseÃ±ada para crear documentaciÃ³n de proyectos de una manera simple y rÃ¡pida, principalmente enfocada en la generaciÃ³n de sitios web de documentaciÃ³n. Algunas de sus caracterÃ­sticas clave incluyen:\n\nUtiliza Markdown como formato de marcado predeterminado, que es fÃ¡cil de aprender y escribir.\nOfrece una interfaz de lÃ­nea de comandos simple para iniciar y generar sitios de documentaciÃ³n.\nProporciona temas y extensiones para personalizar el aspecto y la funcionalidad de la documentaciÃ³n generada.\nIdeal para proyectos de cÃ³digo abierto y documentaciÃ³n de proyectos pequeÃ±os a medianos.\n\nMkDocs es especialmente adecuado para proyectos con necesidades de documentaciÃ³n simples. Es fÃ¡cil de aprender y usar, lo que lo convierte en una excelente opciÃ³n para principiantes. Sin embargo, puede ser limitado en funcionalidad en comparaciÃ³n con Sphinx para proyectos tÃ©cnicos y complejos.\n\n\n\nMkDocs-Material es un tema personalizado para MkDocs, una popular herramienta de generaciÃ³n de sitios web estÃ¡ticos diseÃ±ada para crear documentaciÃ³n de proyectos de manera sencilla y efectiva. Este tema, conocido como â€œMaterial for MkDocsâ€, se inspira en el elegante diseÃ±o de Material Design de Google y estÃ¡ diseÃ±ado para ofrecer una experiencia de documentaciÃ³n moderna y atractiva.\nUna de las principales caracterÃ­sticas de MkDocs-Material es su enfoque en la legibilidad y la facilidad de navegaciÃ³n. Esto se logra mediante un diseÃ±o limpio y organizado que hace que la documentaciÃ³n sea mÃ¡s accesible para los usuarios. AdemÃ¡s, el tema proporciona herramientas Ãºtiles para mejorar la experiencia de los lectores, como una funciÃ³n de bÃºsqueda integrada que permite a los usuarios encontrar rÃ¡pidamente la informaciÃ³n que necesitan.\nOtra ventaja de MkDocs-Material es su navegaciÃ³n intuitiva, que facilita a los usuarios la exploraciÃ³n de la documentaciÃ³n y la navegaciÃ³n entre secciones y pÃ¡ginas. Esto es fundamental para garantizar que los usuarios puedan acceder fÃ¡cilmente a la informaciÃ³n que estÃ¡n buscando sin esfuerzo."
  },
  {
    "objectID": "posts/2023/art_docs.html#por-dÃ³nde-empiezo",
    "href": "posts/2023/art_docs.html#por-dÃ³nde-empiezo",
    "title": "DocumentaciÃ³n",
    "section": "",
    "text": "La documentaciÃ³n de proyectos sigue una progresiÃ³n simple:\n\nSin DocumentaciÃ³n\nAlguna DocumentaciÃ³n\nDocumentaciÃ³n Completa\nBuena DocumentaciÃ³n\nExcelente DocumentaciÃ³n\n\nSi te sientes perdido acerca de por dÃ³nde continuar con tu documentaciÃ³n, observa en quÃ© punto se encuentra tu proyecto en relaciÃ³n con la progresiÃ³n mencionada anteriormente. Â¿Tienes alguna documentaciÃ³n? Si no la tienes, comienza por ahÃ­. Si ya tienes algo de documentaciÃ³n pero te faltan algunos de los archivos clave del proyecto, comienza agregÃ¡ndolos.\nAl final, no te desanimes ni te sientas abrumado por la cantidad de trabajo necesario para documentar el cÃ³digo.\nUna vez que comiences a documentar tu cÃ³digo, te resultarÃ¡ mÃ¡s fÃ¡cil seguir adelante."
  },
  {
    "objectID": "posts/2023/art_docs.html#referencias",
    "href": "posts/2023/art_docs.html#referencias",
    "title": "DocumentaciÃ³n",
    "section": "",
    "text": "Documenting Python Code: A Complete Guide\nDocument Your Python Code and Projects With ChatGPT"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "DocumentaciÃ³n\n\n\nEnteneder los pasos para crear una buena documentaciÃ³n en Python (mÃ¡s algunas recomendaciones).\n\n\n\npython\n\n\ndocs\n\n\n\n\n\n\n\n\n\n7 oct 2023\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nGitlab PDF\n\n\nCÃ³mo aprovechar GitLab CI/CD para generar archivos PDF utilizando los artefactos de un Pipeline.\n\n\n\nci-cd\n\n\nsoftware-development\n\n\n\n\n\n\n\n\n\n1 oct 2023\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nTest Driven Development\n\n\nCÃ³mo abordar el desarrollo de software para Data Science usando Test Driven Development.\n\n\n\npython\n\n\nsoftware-development\n\n\n\n\n\n\n\n\n\n25 may 2022\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nPolars\n\n\nPolars es una librerÃ­a de DataFrames increÃ­blemente rÃ¡pida y eficiente implementada en Rust.\n\n\n\npython\n\n\ndata-analysis\n\n\n\n\n\n\n\n\n\n25 may 2022\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nImpact on Digital Learning\n\n\nCompetition Solution: LearnPlatform COVID-19 Impact on Digital Learning proposed by Kaggle.\n\n\n\nkaggle\n\n\ndata-analysis\n\n\n\n\n\n\n\n\n\n31 ago 2021\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nBuenas PrÃ¡cticas - Python\n\n\nConsejos que te ayudarÃ¡n a mejorar tus skills en el desarrollo de software (con Python).\n\n\n\npython\n\n\nsoftware-development\n\n\n\n\n\n\n\n\n\n15 ago 2021\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nRISE\n\n\nRISE es una extensiÃ³n a los Jupyter Notebooks que permite transformar tus notebooks en presentaciones interactivas.\n\n\n\npython\n\n\njupyter-notebooks\n\n\n\n\n\n\n\n\n\n5 ago 2021\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nJupyter Noteboook\n\n\nJupyter Notebook, es un entorno de trabajo interactivo que permite desarrollar cÃ³digo en Python.\n\n\n\npython\n\n\njupyter-notebooks\n\n\n\n\n\n\n\n\n\n31 jul 2021\n\n\nFrancisco Alfaro\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Francisco Alfaro M.",
    "section": "",
    "text": "English EspaÃ±ol\n\n\n\nHi ğŸ‘‹ My name is Francisco!\n\n\n\n\nProfession: ğŸ“Š Mathematical Engineer\nCurrent Work:\n\nğŸ’» Head of Advanced Analytics (Grupo Security)\nğŸ“– Associate Lecturer (UTFSM)\n\n\n\nInterests\nğŸ®ğŸ¦ŠSSBM-Dark | ğŸ€ğŸ‘‘Basketball-LBJ\nâœ… Software Development  âœ… Statistical Modelling, Time Series  âœ… Machine/Deep Learning  âœ… Cloud computing, Big Data"
  },
  {
    "objectID": "about-es.html",
    "href": "about-es.html",
    "title": "Francisco Alfaro M.",
    "section": "",
    "text": "English EspaÃ±ol\n\n\n\nHolağŸ‘‹ Mi nombre es Francisco!\n\n\n\n\nProfesiÃ³n: ğŸ“Š Ingeniero MatemÃ¡tico\nTrabajo Actual:\n\nğŸ’» Jefe de AnalÃ­tica Avanzada (Grupo Security)\nğŸ“– Profesor Asociado (UTFSM)\n\n\n\nIntereses\nğŸ®ğŸ¦ŠSSBM-Dark | ğŸ€ğŸ‘‘Basketball-LBJ\nâœ… Desarrollo de Software  âœ… Modelado EstadÃ­stico, Series Temporales  âœ… Aprendizaje AutomÃ¡tico/Profundo  âœ… ComputaciÃ³n en la Nube, Big Data"
  },
  {
    "objectID": "posts/2023/gitlab_pdf.html",
    "href": "posts/2023/gitlab_pdf.html",
    "title": "Gitlab PDF",
    "section": "",
    "text": "GitLab CI/CD es una potente herramienta que permite automatizar y gestionar el ciclo de vida de las aplicaciones de software.\nCI (IntegraciÃ³n Continua) y CD (Entrega Continua) son prÃ¡cticas esenciales en el desarrollo de software moderno que buscan mejorar la calidad del cÃ³digo, aumentar la eficiencia y reducir los errores. GitLab CI/CD se integra de manera nativa en el flujo de trabajo de GitLab, lo que lo convierte en una opciÃ³n atractiva para equipos de desarrollo.\n\nCI (IntegraciÃ³n Continua): Es el proceso de integrar cambios de cÃ³digo frecuentes en un repositorio compartido. Esto implica la ejecuciÃ³n automÃ¡tica de pruebas y anÃ¡lisis de calidad cada vez que se envÃ­a cÃ³digo. El objetivo es identificar y corregir problemas de manera temprana en el ciclo de desarrollo.\nCD (Entrega Continua): Una vez que las pruebas de CI se han superado con Ã©xito, el cÃ³digo se considera apto para su implementaciÃ³n en entornos de producciÃ³n o de pruebas. El objetivo es entregar de manera eficiente y confiable el software a los usuarios finales.\n\n\n\n\n\nAntes de profundizar en la generaciÃ³n de archivos PDF, es importante comprender el concepto de â€œartefactosâ€ en GitLab CI/CD. Los artefactos son archivos o conjuntos de archivos generados como resultado de una ejecuciÃ³n exitosa de un pipeline.\nEstos artefactos se almacenan en GitLab y se pueden utilizar posteriormente en otros trabajos o pipelines.\nEn el contexto de la generaciÃ³n de archivos PDF, los artefactos son esenciales porque permiten que los archivos PDF generados en un trabajo se conserven y utilicen en otros trabajos o etapas del pipeline.\n\n\n\n\nLa generaciÃ³n de archivos PDF como parte de su proceso de CI/CD puede ser Ãºtil en varios escenarios, como la creaciÃ³n de informes automatizados, la generaciÃ³n de documentaciÃ³n tÃ©cnica o la producciÃ³n de facturas en lÃ­nea.\nA continuaciÃ³n, detallaremos cÃ³mo lograrlo utilizando GitLab CI/CD:\n\nNota: Tomaremos como referencia el siguiente repositorio.\n\n\n\nAntes de comenzar, asegÃºrese de que su proyecto de GitLab estÃ© configurado correctamente y tenga acceso a GitLab CI/CD. TambiÃ©n debe tener un archivo de cÃ³digo fuente que desee convertir en un archivo PDF.\nAsegÃºrese de que cualquier dependencia necesaria estÃ© especificada en su archivo de configuraciÃ³n de CI/CD.\n\n\n\n\nCree un script que sea capaz de generar el archivo PDF a partir de sus datos de entrada.\nEste script deberÃ­a tomar los datos relevantes y formatearlos en un archivo PDF.\n\n\n\n\nEn su repositorio de GitLab, cree un archivo llamado .gitlab-ci.yml si aÃºn no lo ha hecho.\nEste archivo contiene la configuraciÃ³n de su pipeline.\nAquÃ­ hay un ejemplo de cÃ³mo podrÃ­a verse:\nstages:\n  - pdf\n\ngenerate_pdf:\n  stage: pdf\n  image: aergus/latex\n  script:\n    - latexmk -pdf **/*.tex\n\n  artifacts:\n    paths:\n      - ./*.pdf\nEn este ejemplo:\nstages:\n  - pdf\n\nstages: Esta secciÃ³n define las etapas (stages). En este caso, solo se define una etapa llamada â€œpdfâ€. Las etapas son divisiones lÃ³gicas en el pipeline que agrupan trabajos relacionados. En este caso, el pipeline tiene una sola etapa llamada â€œpdfâ€.\n\ngenerate_pdf:\n  stage: pdf\n  image: aergus/latex\n  script:\n    - latexmk -pdf **/*.tex\n\ngenerate_pdf: Esta secciÃ³n define un trabajo (job) llamado â€œgenerate_pdfâ€. Un trabajo es una unidad de ejecuciÃ³n en el pipeline. AquÃ­ estÃ¡ el desglose de esta secciÃ³n:\n\nstage: pdf: Esta lÃ­nea especifica que este trabajo pertenece a la etapa â€œpdfâ€ definida previamente. En otras palabras, este trabajo se ejecutarÃ¡ en la etapa â€œpdfâ€ del pipeline.\nimage: aergus/latex: Esta lÃ­nea especifica la imagen Docker que se utilizarÃ¡ para ejecutar este trabajo. En este caso, se utiliza la imagen â€œaergus/latexâ€, que contiene un entorno LaTeX para compilar documentos PDF. Esta imagen es esencial para compilar archivos LaTeX en archivos PDF.\nscript: AquÃ­ se definen los comandos que se ejecutarÃ¡n en el trabajo. En este caso, se utiliza el comando â€œlatexmk -pdf **/*.texâ€. Este comando utiliza â€œlatexmkâ€ para compilar todos los archivos â€œ.texâ€ en el proyecto en archivos PDF. El uso de **/*.tex significa que buscarÃ¡ archivos â€œ.texâ€ en todos los subdirectorios del proyecto.\n\n\nartifacts:\n  paths:\n    - ./*.pdf\n\nartifacts: Esta secciÃ³n especifica quÃ© archivos deben considerarse artefactos y, por lo tanto, se conservarÃ¡n despuÃ©s de una ejecuciÃ³n exitosa del trabajo. AquÃ­ estÃ¡ el desglose de esta secciÃ³n:\n\npaths: ./*.pdf: Esta lÃ­nea especifica que todos los archivos con extensiÃ³n â€œ.pdfâ€ en el directorio actual deben considerarse artefactos. Esto significa que los archivos PDF generados como resultado de la ejecuciÃ³n de este trabajo se conservarÃ¡n y estarÃ¡n disponibles para su descarga despuÃ©s de el pipeline se haya ejecutado con Ã©xito.\n\n\n\n\n\nCada vez que realice un envÃ­o de cÃ³digo (push) o active manualmente el pipeline, GitLab ejecutarÃ¡ el trabajo de generaciÃ³n de PDF. El script generarÃ¡ el archivo PDF y lo almacenarÃ¡ como un artefacto.\n\n\n\n\nUna vez que el pipeline se haya ejecutado con Ã©xito, puede acceder a los archivos PDF generados en GitLab.\nVaya a la pÃ¡gina de su proyecto en GitLab, seleccione â€œCI/CDâ€ y luego â€œArtefactosâ€.\nAquÃ­ encontrarÃ¡ el archivo PDF generado que puede descargar.\n\n\n\n\nGitLab CI/CD es una herramienta poderosa que puede ayudar en la automatizaciÃ³n de una amplia variedad de tareas, incluida la generaciÃ³n de archivos PDF.\nAl comprender cÃ³mo utilizar artefactos en GitLab CI/CD y seguir los pasos mencionados anteriormente, puede integrar fÃ¡cilmente la generaciÃ³n de PDF en su flujo de trabajo de desarrollo, lo que ahorra tiempo y esfuerzo, y garantiza la consistencia y la calidad en la creaciÃ³n de documentos PDF automatizados.\n\n\n\n\nGet started with GitLab CI/CD\nJob artifacts"
  },
  {
    "objectID": "posts/2023/gitlab_pdf.html#introducciÃ³n",
    "href": "posts/2023/gitlab_pdf.html#introducciÃ³n",
    "title": "Gitlab PDF",
    "section": "",
    "text": "GitLab CI/CD es una potente herramienta que permite automatizar y gestionar el ciclo de vida de las aplicaciones de software.\nCI (IntegraciÃ³n Continua) y CD (Entrega Continua) son prÃ¡cticas esenciales en el desarrollo de software moderno que buscan mejorar la calidad del cÃ³digo, aumentar la eficiencia y reducir los errores. GitLab CI/CD se integra de manera nativa en el flujo de trabajo de GitLab, lo que lo convierte en una opciÃ³n atractiva para equipos de desarrollo.\n\nCI (IntegraciÃ³n Continua): Es el proceso de integrar cambios de cÃ³digo frecuentes en un repositorio compartido. Esto implica la ejecuciÃ³n automÃ¡tica de pruebas y anÃ¡lisis de calidad cada vez que se envÃ­a cÃ³digo. El objetivo es identificar y corregir problemas de manera temprana en el ciclo de desarrollo.\nCD (Entrega Continua): Una vez que las pruebas de CI se han superado con Ã©xito, el cÃ³digo se considera apto para su implementaciÃ³n en entornos de producciÃ³n o de pruebas. El objetivo es entregar de manera eficiente y confiable el software a los usuarios finales."
  },
  {
    "objectID": "posts/2023/gitlab_pdf.html#artefactos-en-gitlab-cicd",
    "href": "posts/2023/gitlab_pdf.html#artefactos-en-gitlab-cicd",
    "title": "Gitlab PDF",
    "section": "",
    "text": "Antes de profundizar en la generaciÃ³n de archivos PDF, es importante comprender el concepto de â€œartefactosâ€ en GitLab CI/CD. Los artefactos son archivos o conjuntos de archivos generados como resultado de una ejecuciÃ³n exitosa de un pipeline.\nEstos artefactos se almacenan en GitLab y se pueden utilizar posteriormente en otros trabajos o pipelines.\nEn el contexto de la generaciÃ³n de archivos PDF, los artefactos son esenciales porque permiten que los archivos PDF generados en un trabajo se conserven y utilicen en otros trabajos o etapas del pipeline."
  },
  {
    "objectID": "posts/2023/gitlab_pdf.html#generaciÃ³n-de-archivos-pdf-con-gitlab-cicd",
    "href": "posts/2023/gitlab_pdf.html#generaciÃ³n-de-archivos-pdf-con-gitlab-cicd",
    "title": "Gitlab PDF",
    "section": "",
    "text": "La generaciÃ³n de archivos PDF como parte de su proceso de CI/CD puede ser Ãºtil en varios escenarios, como la creaciÃ³n de informes automatizados, la generaciÃ³n de documentaciÃ³n tÃ©cnica o la producciÃ³n de facturas en lÃ­nea.\nA continuaciÃ³n, detallaremos cÃ³mo lograrlo utilizando GitLab CI/CD:\n\nNota: Tomaremos como referencia el siguiente repositorio.\n\n\n\nAntes de comenzar, asegÃºrese de que su proyecto de GitLab estÃ© configurado correctamente y tenga acceso a GitLab CI/CD. TambiÃ©n debe tener un archivo de cÃ³digo fuente que desee convertir en un archivo PDF.\nAsegÃºrese de que cualquier dependencia necesaria estÃ© especificada en su archivo de configuraciÃ³n de CI/CD.\n\n\n\n\nCree un script que sea capaz de generar el archivo PDF a partir de sus datos de entrada.\nEste script deberÃ­a tomar los datos relevantes y formatearlos en un archivo PDF.\n\n\n\n\nEn su repositorio de GitLab, cree un archivo llamado .gitlab-ci.yml si aÃºn no lo ha hecho.\nEste archivo contiene la configuraciÃ³n de su pipeline.\nAquÃ­ hay un ejemplo de cÃ³mo podrÃ­a verse:\nstages:\n  - pdf\n\ngenerate_pdf:\n  stage: pdf\n  image: aergus/latex\n  script:\n    - latexmk -pdf **/*.tex\n\n  artifacts:\n    paths:\n      - ./*.pdf\nEn este ejemplo:\nstages:\n  - pdf\n\nstages: Esta secciÃ³n define las etapas (stages). En este caso, solo se define una etapa llamada â€œpdfâ€. Las etapas son divisiones lÃ³gicas en el pipeline que agrupan trabajos relacionados. En este caso, el pipeline tiene una sola etapa llamada â€œpdfâ€.\n\ngenerate_pdf:\n  stage: pdf\n  image: aergus/latex\n  script:\n    - latexmk -pdf **/*.tex\n\ngenerate_pdf: Esta secciÃ³n define un trabajo (job) llamado â€œgenerate_pdfâ€. Un trabajo es una unidad de ejecuciÃ³n en el pipeline. AquÃ­ estÃ¡ el desglose de esta secciÃ³n:\n\nstage: pdf: Esta lÃ­nea especifica que este trabajo pertenece a la etapa â€œpdfâ€ definida previamente. En otras palabras, este trabajo se ejecutarÃ¡ en la etapa â€œpdfâ€ del pipeline.\nimage: aergus/latex: Esta lÃ­nea especifica la imagen Docker que se utilizarÃ¡ para ejecutar este trabajo. En este caso, se utiliza la imagen â€œaergus/latexâ€, que contiene un entorno LaTeX para compilar documentos PDF. Esta imagen es esencial para compilar archivos LaTeX en archivos PDF.\nscript: AquÃ­ se definen los comandos que se ejecutarÃ¡n en el trabajo. En este caso, se utiliza el comando â€œlatexmk -pdf **/*.texâ€. Este comando utiliza â€œlatexmkâ€ para compilar todos los archivos â€œ.texâ€ en el proyecto en archivos PDF. El uso de **/*.tex significa que buscarÃ¡ archivos â€œ.texâ€ en todos los subdirectorios del proyecto.\n\n\nartifacts:\n  paths:\n    - ./*.pdf\n\nartifacts: Esta secciÃ³n especifica quÃ© archivos deben considerarse artefactos y, por lo tanto, se conservarÃ¡n despuÃ©s de una ejecuciÃ³n exitosa del trabajo. AquÃ­ estÃ¡ el desglose de esta secciÃ³n:\n\npaths: ./*.pdf: Esta lÃ­nea especifica que todos los archivos con extensiÃ³n â€œ.pdfâ€ en el directorio actual deben considerarse artefactos. Esto significa que los archivos PDF generados como resultado de la ejecuciÃ³n de este trabajo se conservarÃ¡n y estarÃ¡n disponibles para su descarga despuÃ©s de el pipeline se haya ejecutado con Ã©xito.\n\n\n\n\n\nCada vez que realice un envÃ­o de cÃ³digo (push) o active manualmente el pipeline, GitLab ejecutarÃ¡ el trabajo de generaciÃ³n de PDF. El script generarÃ¡ el archivo PDF y lo almacenarÃ¡ como un artefacto.\n\n\n\n\nUna vez que el pipeline se haya ejecutado con Ã©xito, puede acceder a los archivos PDF generados en GitLab.\nVaya a la pÃ¡gina de su proyecto en GitLab, seleccione â€œCI/CDâ€ y luego â€œArtefactosâ€.\nAquÃ­ encontrarÃ¡ el archivo PDF generado que puede descargar."
  },
  {
    "objectID": "posts/2023/gitlab_pdf.html#conclusiones",
    "href": "posts/2023/gitlab_pdf.html#conclusiones",
    "title": "Gitlab PDF",
    "section": "",
    "text": "GitLab CI/CD es una herramienta poderosa que puede ayudar en la automatizaciÃ³n de una amplia variedad de tareas, incluida la generaciÃ³n de archivos PDF.\nAl comprender cÃ³mo utilizar artefactos en GitLab CI/CD y seguir los pasos mencionados anteriormente, puede integrar fÃ¡cilmente la generaciÃ³n de PDF en su flujo de trabajo de desarrollo, lo que ahorra tiempo y esfuerzo, y garantiza la consistencia y la calidad en la creaciÃ³n de documentos PDF automatizados."
  },
  {
    "objectID": "posts/2023/gitlab_pdf.html#referencias",
    "href": "posts/2023/gitlab_pdf.html#referencias",
    "title": "Gitlab PDF",
    "section": "",
    "text": "Get started with GitLab CI/CD\nJob artifacts"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html",
    "href": "posts/2021/eda_learnplatform.html",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "Main objective is understand of the best way the challenge LearnPlatform COVID-19 Impact on Digital Learning proposed by Kaggle.\nThe steps to follow are:\n\nOverview of the Dataset: Understanding the datasets available.\nPreprocessing: Preprocessing of the datasets available.\nEDA: Exploratory data analysis using visualization tools in Python.\n\n\nNote: My analysis is inspired by several of the notebooks that different profiles have uploaded to the challenge, so some graphics or images belong to these authors. The most important ones will be found in the references. On the other hand, my project is available in Jupyter Book, click in the following link.\n\n\n\nThe objective of this section is to be able to read and give an interpretation to each one of the available datasets, analyzing column by column. For each dataset we will make a brief description:\n\nFile: File name (.csv).\nShape: Dimensionality of datasets.\nDescription: Basic description of the dataset.\nTop 5 rows: Show first 5 rows + explanation for some columns.\nSummary: Summary of datasets.\n\n\n# libraries\nimport glob\nimport re\n\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# read data\n\n## products dataset\npath = '../input/learnplatform-covid19-impact-on-digital-learning/'\nproducts_df = pd.read_csv(path + \"products_info.csv\")\nproducts_df.columns = [x.lower().replace(' ','_') for x in products_df.columns]\n\n## districts dataset\ndistricts_df = pd.read_csv(path +\"districts_info.csv\")\n#districts_df.state = districts_df.state.replace('District Of Columbia','District of Columbia')\n\n## engagement dataset\npath = '../input/learnplatform-covid19-impact-on-digital-learning/engagement_data/' \nall_files = glob.glob(path + \"/*.csv\")\n\nli = []\n\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"/\")[-1].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    li.append(df)\nengagement_df = pd.concat(li)\nengagement_df = engagement_df.reset_index(drop=True)\n\n# summary\n\ndf_list = [\n    districts_df,\n    products_df,\n    engagement_df\n]\n\ndf_name = [\n    'districts_df',\n    'products_df',\n    'engagement_df'\n]\n\ncols = [\n    'dataframe',\n    'column', \n    'dtype', \n    'Non-Null Count', \n    'Null Count',\n    'unique'\n    \n]\n\nframes=[]\n\n\nfor i in range(len(df_list)):\n    df = df_list[i].copy()\n    a = df.dtypes.reset_index().rename(columns = {'index':'column',0:'dtype'})\n    b = df.count().reset_index().rename(columns = {'index':'column',0:'Non-Null Count'})\n    c = df.isnull().sum().reset_index().rename(columns = {'index':'column',0:'Null Count'})\n    temp = a.merge(b,on = 'column').merge(c,on = 'column')\n    \n    dct = {col: len(df[col].unique()) for col in df.columns}\n    df_unique = pd.DataFrame({\n    'column':dct.keys(),\n    'unique':dct.values(),\n    })\n    temp = temp.merge(df_unique,on = 'column')\n    temp['dataframe'] = df_name[i]\n    frames.append(temp)\n\n\n\n\nFile: districts_info.csv.\nShape: \\(233\\) rows \\(\\times\\) \\(7\\) columns.\nDescription: file contains information about each school district.\nTop 5 rows::\n\n\n\nSummary:\n\n\n\n\n\n\nFile: products_info.csv\nShape: \\(372\\) rows \\(\\times\\) \\(6\\) columns.\nDescription: for each school district, there is an additional file that contains the engagement for each tool for everyday in 2020.\nTop 5 rows:: \nSummary:\n\n\n\n\n\n\nFile: engagement_data/*.csv.\nShape: \\(22324190\\) rows \\(\\times\\) \\(5\\) columns.\nDescription: file contains information about each school district. The files can be joined by the key columns district_id and lp_id.\nTop 5 rows:: \nSummary:\n\n\n\n\n\n\nPreprocessing is an important step in any analytics competition. It helps you to handle your data more efficiently. However, please note that the way I preprocess the data may not be suited for your analysis purposes. Therefore, before you begin preprocessing your data, think about which data you would like to keep and/or modify and which data is not relevant for your analysis.\n\none-hot encoding the product sectors\nsplitting up the primary essential function into main and sub category\n\n\nNote: Preprocessing varies if you see other notebooks of this challenge. The processing will depend on the understanding of each of the datasets and the extra information that you may have.\n\n\n\n# products_df\n\nproducts_df['primary_function_main'] = products_df['primary_essential_function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproducts_df['primary_function_sub'] = products_df['primary_essential_function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproducts_df['primary_function_sub'] = products_df['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\n#products_df.drop(\"Primary Essential Function\", axis=1, inplace=True)\n\ntemp_sectors = products_df['sector(s)'].str.get_dummies(sep=\"; \")\ntemp_sectors.columns = [f\"sector_{re.sub(' ', '', c)}\" for c in temp_sectors.columns]\nproducts_df = products_df.join(temp_sectors)\n#products_df.drop(\"Sector(s)\", axis=1, inplace=True)\n\n#del temp_sectors\n\n# engagement_df\n\nengagement_df['time'] = pd.to_datetime(engagement_df['time'])\n\ntemp = engagement_df[['time']].drop_duplicates('time')\ntemp['week'] = temp['time'].apply(lambda x: x.isocalendar()[1])\nengagement_df = engagement_df.merge(temp,on ='time')\n\nengagement_df['lp_id'] = engagement_df['lp_id'].fillna(-1).astype(int)\nengagement_df['district_id'] = engagement_df['district_id'].fillna(-1).astype(int)\n\nengagement_df_mix = engagement_df.merge(\n    districts_df[['district_id','state']],\n    on = 'district_id'\n)\nengagement_df_mix = engagement_df_mix.merge(\n    products_df[['lp_id','product_name','sector_Corporate', 'sector_HigherEd','sector_PreK-12']],\n    on = 'lp_id'\n)\n\n\n\n\nExploratory data analysis is the most important part of the challenge, since this will make the difference between the winner and the other participants. You should keep in mind that your visualizations must be able to simply and easily summarize the datasets. Also, it is hoped that the proposed visualizations can help to understand behaviors that are not easy to analyze with a simple table.\nVisualizations will be made in matplotlib, seaborn y plotly. Based on the article by Diverging Color Maps for Scientific Visualization (Expanded) - Kenneth Moreland, we will occupy Grays scale next to the technique: dark text on a light background.\n\nNote: Visualizations made on this notebook are static. You can use different tools to be able to make dynamic visualizations (Altair, plotly, etc.). You can also perform tools like Streamlit to make Dashboards. On the other hand, if you fully understand python visualization tools and have knowledge of HTML/CSS, you can make beautiful notebook presentations like this one.\n\n\n\nFirst of all, I am interested how diverse the available school districts are. As you can see in below plot, the available data does not cover all the states in the U.S. . The states with the most available school districts are CT (30) and UT (29) while there are also states with only one school district (FL, TN, NY, AZ).\n\n# map plot: districts\n\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ndistricts_df['state_abbrev'] = districts_df['state'].replace(us_state_abbrev)\ndistricts_info_by_state = districts_df['state_abbrev'].value_counts().to_frame().reset_index(drop=False)\ndistricts_info_by_state.columns = ['state_abbrev', 'num_districts']\n\ntemp = pd.DataFrame({\n    'state_abbrev':us_state_abbrev.values(),\n})\n\ntemp = temp.merge(districts_info_by_state,on='state_abbrev',how='left').fillna(0)\ntemp['num_districts'] = temp['num_districts'].astype(int)\n\nfig = go.Figure()\nlayout = dict(\n    title_text = \"Number of Available School Districts per State\",\n    title_font_color=\"black\",\n    geo_scope='usa',\n)    \n\n\nfig.add_trace(\n    go.Choropleth(\n        locations=temp.state_abbrev,\n        zmax=1,\n        z = temp.num_districts,\n        locationmode = 'USA-states', # set of locations match entries in `locations`\n        marker_line_color='black',\n        geo='geo',\n        colorscale=px.colors.sequential.Greys, \n        \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()\n\n                                                \n\n\n\n# bar plot: districts\n\nplt.style.use('default')\nplt.figure(figsize=(14,8))\n\nplotting = sns.countplot(\n    y=\"state\",\n    data=districts_df,\n    order=districts_df.state.value_counts().index,\n    palette=\"Greys_d\",\n    linewidth=3\n)\n\nfor container in plotting.containers:\n    plotting.bar_label(container,fontsize=16)\n\n#Text\nplotting.text(x = -5, y = -4.2, s = \"State Distribution\",fontsize = 24, weight = 'bold', alpha = .90);\nplotting.text(x = -5, y = -3, s = \"Distribution of United States\",fontsize = 16, alpha = .85)\nplotting.text(x = 31.2, y = 0.08, s = 'Highest', weight = 'bold',fontsize = 14)\nplotting.text(x = 1.7, y = 22.3, s = 'Lowest', weight = 'bold',fontsize = 14)\n\nplt.yticks(fontsize=14)\nplt.xticks(fontsize=14)\n\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nLocales are separated into 4 categories: Suburb,Rural, City and Town, where most of the locales are concentrated in the Suburb category (104).\nFor the pct_black/hispanic variable, Rural and Town categories concentrate their entire population close to the interval $ [0,0.2 [$, while for the others sectors this percentage is varied.\nFor pctfree/reduced and pp_total_raw indicators, the distribution for each location is different, although they tend to focus on a particular interval.\n\n# heatmap: districts -&gt; locale\n\ntemp = districts_df.groupby('locale').pp_total_raw.value_counts().to_frame()\ntemp.columns = ['amount']\n\ntemp = temp.reset_index(drop=False)\n\ntemp = temp.pivot(index='locale', columns='pp_total_raw')['amount']\ntemp = temp[['[4000, 6000[', '[6000, 8000[', '[8000, 10000[', '[10000, 12000[',\n       '[12000, 14000[', '[14000, 16000[', '[16000, 18000[', \n       '[18000, 20000[', '[20000, 22000[', '[22000, 24000[', ]]\n\n\ntemp1 = districts_df.groupby('locale')['pct_black/hispanic'].value_counts().to_frame()\ntemp1.columns = ['amount']\n\ntemp1 = temp1.reset_index(drop=False)\ntemp1 = temp1.pivot(index='locale', columns='pct_black/hispanic')['amount']\n\ntemp2 = districts_df.groupby('locale')['pct_free/reduced'].value_counts().to_frame()\ntemp2.columns = ['amount']\n\ntemp2 = temp2.reset_index(drop=False)\n\ntemp2 = temp2.pivot(index='locale', columns='pct_free/reduced')['amount']\n\nplt.style.use('default')\n\nfig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(24,18))\n\nsns.countplot(data=districts_df, x='locale', ax=ax1, palette='Greys_d')\nax1.text(x = -0.5, y = 120, s = \"Locale Distribution\",fontsize = 24, weight = 'bold', alpha = .90);\nax1.xaxis.set_tick_params(labelsize=16)\n\nfor container in ax1.containers:\n    ax1.bar_label(container,fontsize=16)\n\nsns.heatmap(temp1.fillna(0), annot=True,  cmap='Greys', ax=ax2,annot_kws={\"fontsize\":14})\nax2.set_title('Heatmap: locale and pct_black/hispanic',fontsize=16,loc='left')\nax2.xaxis.set_tick_params(labelsize=16)\nax2.yaxis.set_tick_params(labelsize=16)\n\nsns.heatmap(temp.fillna(0), annot=True,  cmap='Greys', ax=ax3,annot_kws={\"fontsize\":14})\nax3.set_title('Heatmap: locale and pp_total_raw',fontsize=16,loc='left')\nax3.xaxis.set_tick_params(labelsize=16)\nax3.yaxis.set_tick_params(labelsize=16)\n\nsns.heatmap(temp2.fillna(0), annot=True,  cmap='Greys', ax=ax4,annot_kws={\"fontsize\":14})\nax4.set_title('Heatmap: locale and pct_free/reduced',fontsize=16,loc='left')\nax4.xaxis.set_tick_params(labelsize=16)\nax4.yaxis.set_tick_params(labelsize=16)\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSectors are separated into 3 categories: sector_Corporate, sector_HigherEd and sector_PreK-12, donde la categorÃ­a mayoritaria corresponde a sector_PreK-12 (350). On the other hand, analyzing the primary_function_main variable, all sectors are focused on theLC category. It is worth mentioning that the distribution of the other categories remains almost the same between sectors.\n\nplt.style.use('default')\nnames = ['sector_Corporate', 'sector_HigherEd','sector_PreK-12']\ncounts = [products_df[x].sum() for x in names]\n\ntemp_bar = pd.DataFrame({\n    'sector':names,\n    'count':counts\n}).sort_values('count',ascending = False)\n\ntemp = products_df.groupby('primary_function_main')[names].sum()\n\n#fig, [ax1, ax2 ]= plt.subplots(nrows=1, ncols=2, figsize=(12,6))\nplt.figure(figsize=(18,18))\n\nplt.subplot(3,2,1)\nax = sns.barplot(x=\"sector\", y=\"count\", data=temp_bar,palette ='Greys_d')\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=12)\n\nplt.subplot(3,2,2)\n\nsns.heatmap(temp.T, annot=True,  cmap='Greys',annot_kws={\"fontsize\":10},fmt='g')\n\nplt.text(x = -6, y = -0.25, s = \"Sectors Distribution\",fontsize = 18, weight = 'bold', alpha = .90);\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nContinuing the analysis of the primary_function_main variable, it was observed that most of these are in theLC category (77%). Within this category, its subcategory is analyzed, where the predominant subcategory is Sites, Resources & Reference (101).\n\n# pieplot: products\n\ncolor = [\n    'darkgray',\n    'silver',\n    'lightgray',\n    'gainsboro',\n]\n\nproducts_df[\"primary_function_main\"].value_counts().plot(\n    kind = 'pie', \n    autopct='%1d%%', \n    figsize=(6,6), \n    colors=color,\n    wedgeprops={\"edgecolor\":\"k\",'linewidth': 0.8,},\n    textprops={'color':\"black\"},\n    startangle=0)\nplt.text(x = -1.4, y = 1.1, s = \"Categories\",fontsize = 18, weight = 'bold', alpha = .90);\nplt.show()\n\n\n\n\n\n\n\n\n\n# pieplot: products -&gt; subcategories\n\nplt.style.use('default')\nplt.figure(figsize=(18,8))\n\ntemp = products_df[products_df.primary_function_main == 'LC']\nax = sns.countplot(\n    data=temp, \n    y='primary_function_sub',\n    order=temp.primary_function_sub.value_counts().index,\n    palette ='Greys_d'\n)\n\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=16)\n\n\n#plt.title('Sub-Categories in Primary Function LC')\nplt.text(x = -50, y = -0.8, \n         s = \"Sub-Categories in Primary Function LC\",fontsize = 24, weight = 'bold', alpha = .90);\n\nplt.text(x = 105, y =0.08, s = 'Highest', weight = 'bold',fontsize=16)\nplt.text(x = 7, y = 6, s = 'Lowest', weight = 'bold',fontsize=16)\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nAfter understanding the functionality of each of the tools, it is necessary to understand the distribution of the tools. The first thing is to study the distribution of the providers of the products we have, where:\n\n258 providers have 1 occurrences.\n18 providers have 2 occurrences.\n9 providers have 3 occurrences.\n2 providers have 4 occurrences.\n2 providers have 6 occurrences.\n1 provider have 30 occurrences.\n\nBased on this, only the top 15 providers will be displayed.\n\ndct = {\n    'Savvas Learning Company | Formerly Pearson K12 Learning': 'Savvas Learning Company'\n}\n\ntemp = products_df['provider/company_name'].value_counts().reset_index()\ntemp.columns = ['provider/company_name','count']\ntemp = temp.replace( {\n    'Savvas Learning Company | Formerly Pearson K12 Learning': 'Savvas Learning Company'\n})\n\nn = 15\ntemp = temp.sort_values('count',ascending = False).head(n)\n\nplt.style.use('default')\nplt.figure(figsize=(18,8))\n\nax = sns.barplot(\n    data=temp, \n    y='provider/company_name',\n    x='count',\n    palette ='Greys_d'\n)\n\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=15)\n    \nplt.text(x = -7, y = -1, \n         s = f\"Top {n} provider/company name\",fontsize = 20, weight = 'bold', alpha = .90);\n   \nplt.text(x = 31, y =0.08, s = 'Highest', weight = 'bold',fontsize=16)\nplt.text(x = 3, y = 14.2, s = 'Lowest', weight = 'bold',fontsize=16)\nplt.yticks(fontsize=16)\n\n\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\nplt.show()\n\n\n\n\n\n\n\n\nWith regard to products, there are about 372 different products.\nWe can make a word cloud to be able to analyze in a different way, words by themselves that are repeated the most in the product_name variable.\n\ncloud = WordCloud(\n    width=1080,\n    height=270,\n    colormap='Greys',\n    background_color='white'\n    ).generate(\" \".join(products_df['product_name'].astype(str)))\n\nplt.figure(figsize=(22, 10))\nplt.imshow(cloud)\nplt.axis('off');\n\n\n\n\n\n\n\n\nTo understand more in detail the use of these products, we will analyze the use of these products with respect to the variable engagement_index. The first graph is related to the average engagement_index (per student) for the year 2020, where the first 15 products will be displayed.\nAn important fact is that 362 products have an average of less than 1!.\n\ngroup_01 = (engagement_df_mix.groupby('product_name')['engagement_index'].mean()/1000).reset_index().sort_values('engagement_index',ascending = False)\ngroup_01['engagement_index'] = group_01['engagement_index'].apply(lambda x: round(x,2))\nless_1 = len(group_01.loc[lambda x:x['engagement_index']&lt;1])\n\n\nplt.style.use('default')\nplt.figure(figsize=(14,8))\n\nplotting = sns.barplot(\n    y=\"product_name\",\n    x = \"engagement_index\",\n    data=group_01.head(20),\n    palette=\"Greys_d\",\n\n)\n\nfor container in plotting.containers:\n    plotting.bar_label(container,fontsize=14)\n\nplt.text(x = -3.5, y = -3, \n         s = \"Mean daily page-load events in top 20 tools\",fontsize = 20, weight = 'bold', alpha = .90);\n\nplt.text(x = -3.5, y = -2, \n         s = \"per 1 student\",fontsize = 14,  alpha = .90);\n\nplt.text(x = 11, y =0.1, s = 'Highest', weight = 'bold',fontsize=14)\nplt.text(x = 1, y = 19.2, s = 'Lowest', weight = 'bold',fontsize=14)\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\nplt.show()\n\n\n\n\n\n\n\n\nLetâ€™s study the temporal behavior (at the level of weeks) of these tools during the year 2020, where the most three used tools will be shown with different colors, while the other tools will be visualized but with the same color (in order to understand their distribution).\n\nNote: The proposed analysis can be carried out at the day level and analyzing through time series each of the tools during the year 2020.\n\n\ncol = 'week'\n\ngroup_04  = (engagement_df_mix.groupby(['product_name',col])['engagement_index'].mean()/1000).reset_index().sort_values('engagement_index',ascending = False)\n\ng_high = group_01.head(3)['product_name']\ngroup_04_top = group_04.loc[lambda x: x.product_name.isin(g_high)]\n\nstates = group_04['product_name'].unique()\ntimes= group_04[col].unique()\n\nindex = pd.MultiIndex.from_product([states,times], names = [\"product_name\", col])\n\ndf_complete = pd.DataFrame(index = index).reset_index().fillna(0)\n\ngroup_04 = df_complete.merge(group_04,on = ['product_name',col],how='left').fillna(0)\n\nn = 3\ng_high = group_04.groupby('product_name')['engagement_index'].sum().sort_values(ascending=False).head(n).index.to_list()\n\n\ncolors = [    \n    'lightgray', \n    'dimgray', \n    'black', \n    'firebrick', \n    'darkred']\npalette_01 = {x:'lavender' for x in group_04['product_name'].unique() if x not in g_high}\npalette_02 = {g_high[i]:colors[i] for i in range(n)}\n\nplt.style.use('default')\nplt.figure(figsize=(20,6))\n\n\nsns.lineplot(\n    data=group_04.loc[lambda x: ~x.product_name.isin(g_high)], \n    x=col, \n    y=\"engagement_index\", \n    hue='product_name',\n    legend = False,\n    palette=palette_01,\n    linewidth = 1.\n\n    )\n\nsns.lineplot(\n    data=group_04.loc[lambda x: x.product_name.isin(g_high)], \n    x=col, \n    y=\"engagement_index\", \n    hue='product_name',\n    palette=palette_02,\n    linewidth = 1.\n\n    )\n\n\nplt.text(x = -2, y =23.7, s = 'Mean daily page-load events in top 3 tools', weight = 'bold',fontsize=14)\nplt.text(x = -2, y =22.3, s = 'by products and time, per 1 student',fontsize=12)\n\n\nplt.text(x = 12, y =20.7, s = '1,000 cases of COVID', weight = 'bold',fontsize=8)\nplt.text(x = 37, y =20.7, s = '1st September', weight = 'bold',fontsize=8)\n\n\nplt.axvline(x = 11, color = 'black', linestyle='--',linewidth = 0.5)\nplt.axvline(x = 36, color = 'black', linestyle='--',linewidth = 0.5)\nplt.show()\n\n\n\n\n\n\n\n\nNow, we can understand the engagement index for the most important tools about districts, where the districts of * Wisconsin ,  Missouri * and * Virginia * have the highest engagement index among the three most used tools.\n\ngroup_02 = (engagement_df_mix.groupby(['state','product_name'])['engagement_index'].mean()/1000)\\\n            .reset_index().sort_values('engagement_index',ascending = False).fillna(0)\n\ngripo_02_top = group_02.loc[lambda x: x.product_name.isin(g_high)]\ngripo_02_top['engagement_index'] = gripo_02_top['engagement_index'].apply(lambda x: round(x,2))\n#gripo_02_top = gripo_02_top.loc[lambda x: x['engagement_index']&gt;0]\n\n\nplt.style.use('default')\n\ng = sns.FacetGrid(gripo_02_top,hue='product_name',col = 'product_name',height=4, col_wrap= 3  )\ng.map(sns.barplot, \"engagement_index\",\"state\", palette=\"Greys_d\",)\n\ng.fig.set_size_inches(15, 8)\ng.fig.subplots_adjust(top=0.81, right=0.86)\n\naxes = g.axes.flatten()\nfor ax in axes:\n    for container in ax.containers:\n        ax.bar_label(container,fontsize=8)\n\n\nplt.text(x = -50, y = -4, s = \"Mean daily page-load events in top 3 tools\",fontsize = 16, weight = 'bold', alpha = .90);\nplt.text(x = -50, y = -3, s = \"by state and products, per 1 student\",fontsize = 14,  alpha = .90);\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nDepending on what you want to achieve you might want to carefully preselect districts. Note that we approach in this notebook might not necessarily suit your individual purposes.\nWhen looking at digital learning, you might want to spend sometime in figuring out which districts actually applied digital learning\n\n\n\n\n\nDiverging Color Maps for Scientific Visualization (Expanded) - Kenneth Moreland\nKaggle Competitions:\n\nEnthusiast to Data Professional - What changes?\nHow To Approach Analytics Challenges\nMost popular tools in 2020 Digital Learning"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html#overview-of-the-dataset",
    "href": "posts/2021/eda_learnplatform.html#overview-of-the-dataset",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "The objective of this section is to be able to read and give an interpretation to each one of the available datasets, analyzing column by column. For each dataset we will make a brief description:\n\nFile: File name (.csv).\nShape: Dimensionality of datasets.\nDescription: Basic description of the dataset.\nTop 5 rows: Show first 5 rows + explanation for some columns.\nSummary: Summary of datasets.\n\n\n# libraries\nimport glob\nimport re\n\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# read data\n\n## products dataset\npath = '../input/learnplatform-covid19-impact-on-digital-learning/'\nproducts_df = pd.read_csv(path + \"products_info.csv\")\nproducts_df.columns = [x.lower().replace(' ','_') for x in products_df.columns]\n\n## districts dataset\ndistricts_df = pd.read_csv(path +\"districts_info.csv\")\n#districts_df.state = districts_df.state.replace('District Of Columbia','District of Columbia')\n\n## engagement dataset\npath = '../input/learnplatform-covid19-impact-on-digital-learning/engagement_data/' \nall_files = glob.glob(path + \"/*.csv\")\n\nli = []\n\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"/\")[-1].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    li.append(df)\nengagement_df = pd.concat(li)\nengagement_df = engagement_df.reset_index(drop=True)\n\n# summary\n\ndf_list = [\n    districts_df,\n    products_df,\n    engagement_df\n]\n\ndf_name = [\n    'districts_df',\n    'products_df',\n    'engagement_df'\n]\n\ncols = [\n    'dataframe',\n    'column', \n    'dtype', \n    'Non-Null Count', \n    'Null Count',\n    'unique'\n    \n]\n\nframes=[]\n\n\nfor i in range(len(df_list)):\n    df = df_list[i].copy()\n    a = df.dtypes.reset_index().rename(columns = {'index':'column',0:'dtype'})\n    b = df.count().reset_index().rename(columns = {'index':'column',0:'Non-Null Count'})\n    c = df.isnull().sum().reset_index().rename(columns = {'index':'column',0:'Null Count'})\n    temp = a.merge(b,on = 'column').merge(c,on = 'column')\n    \n    dct = {col: len(df[col].unique()) for col in df.columns}\n    df_unique = pd.DataFrame({\n    'column':dct.keys(),\n    'unique':dct.values(),\n    })\n    temp = temp.merge(df_unique,on = 'column')\n    temp['dataframe'] = df_name[i]\n    frames.append(temp)\n\n\n\n\nFile: districts_info.csv.\nShape: \\(233\\) rows \\(\\times\\) \\(7\\) columns.\nDescription: file contains information about each school district.\nTop 5 rows::\n\n\n\nSummary:\n\n\n\n\n\n\nFile: products_info.csv\nShape: \\(372\\) rows \\(\\times\\) \\(6\\) columns.\nDescription: for each school district, there is an additional file that contains the engagement for each tool for everyday in 2020.\nTop 5 rows:: \nSummary:\n\n\n\n\n\n\nFile: engagement_data/*.csv.\nShape: \\(22324190\\) rows \\(\\times\\) \\(5\\) columns.\nDescription: file contains information about each school district. The files can be joined by the key columns district_id and lp_id.\nTop 5 rows:: \nSummary:"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html#preprocessing",
    "href": "posts/2021/eda_learnplatform.html#preprocessing",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "Preprocessing is an important step in any analytics competition. It helps you to handle your data more efficiently. However, please note that the way I preprocess the data may not be suited for your analysis purposes. Therefore, before you begin preprocessing your data, think about which data you would like to keep and/or modify and which data is not relevant for your analysis.\n\none-hot encoding the product sectors\nsplitting up the primary essential function into main and sub category\n\n\nNote: Preprocessing varies if you see other notebooks of this challenge. The processing will depend on the understanding of each of the datasets and the extra information that you may have.\n\n\n\n# products_df\n\nproducts_df['primary_function_main'] = products_df['primary_essential_function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproducts_df['primary_function_sub'] = products_df['primary_essential_function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproducts_df['primary_function_sub'] = products_df['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\n#products_df.drop(\"Primary Essential Function\", axis=1, inplace=True)\n\ntemp_sectors = products_df['sector(s)'].str.get_dummies(sep=\"; \")\ntemp_sectors.columns = [f\"sector_{re.sub(' ', '', c)}\" for c in temp_sectors.columns]\nproducts_df = products_df.join(temp_sectors)\n#products_df.drop(\"Sector(s)\", axis=1, inplace=True)\n\n#del temp_sectors\n\n# engagement_df\n\nengagement_df['time'] = pd.to_datetime(engagement_df['time'])\n\ntemp = engagement_df[['time']].drop_duplicates('time')\ntemp['week'] = temp['time'].apply(lambda x: x.isocalendar()[1])\nengagement_df = engagement_df.merge(temp,on ='time')\n\nengagement_df['lp_id'] = engagement_df['lp_id'].fillna(-1).astype(int)\nengagement_df['district_id'] = engagement_df['district_id'].fillna(-1).astype(int)\n\nengagement_df_mix = engagement_df.merge(\n    districts_df[['district_id','state']],\n    on = 'district_id'\n)\nengagement_df_mix = engagement_df_mix.merge(\n    products_df[['lp_id','product_name','sector_Corporate', 'sector_HigherEd','sector_PreK-12']],\n    on = 'lp_id'\n)"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html#eda",
    "href": "posts/2021/eda_learnplatform.html#eda",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "Exploratory data analysis is the most important part of the challenge, since this will make the difference between the winner and the other participants. You should keep in mind that your visualizations must be able to simply and easily summarize the datasets. Also, it is hoped that the proposed visualizations can help to understand behaviors that are not easy to analyze with a simple table.\nVisualizations will be made in matplotlib, seaborn y plotly. Based on the article by Diverging Color Maps for Scientific Visualization (Expanded) - Kenneth Moreland, we will occupy Grays scale next to the technique: dark text on a light background.\n\nNote: Visualizations made on this notebook are static. You can use different tools to be able to make dynamic visualizations (Altair, plotly, etc.). You can also perform tools like Streamlit to make Dashboards. On the other hand, if you fully understand python visualization tools and have knowledge of HTML/CSS, you can make beautiful notebook presentations like this one.\n\n\n\nFirst of all, I am interested how diverse the available school districts are. As you can see in below plot, the available data does not cover all the states in the U.S. . The states with the most available school districts are CT (30) and UT (29) while there are also states with only one school district (FL, TN, NY, AZ).\n\n# map plot: districts\n\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ndistricts_df['state_abbrev'] = districts_df['state'].replace(us_state_abbrev)\ndistricts_info_by_state = districts_df['state_abbrev'].value_counts().to_frame().reset_index(drop=False)\ndistricts_info_by_state.columns = ['state_abbrev', 'num_districts']\n\ntemp = pd.DataFrame({\n    'state_abbrev':us_state_abbrev.values(),\n})\n\ntemp = temp.merge(districts_info_by_state,on='state_abbrev',how='left').fillna(0)\ntemp['num_districts'] = temp['num_districts'].astype(int)\n\nfig = go.Figure()\nlayout = dict(\n    title_text = \"Number of Available School Districts per State\",\n    title_font_color=\"black\",\n    geo_scope='usa',\n)    \n\n\nfig.add_trace(\n    go.Choropleth(\n        locations=temp.state_abbrev,\n        zmax=1,\n        z = temp.num_districts,\n        locationmode = 'USA-states', # set of locations match entries in `locations`\n        marker_line_color='black',\n        geo='geo',\n        colorscale=px.colors.sequential.Greys, \n        \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()\n\n                                                \n\n\n\n# bar plot: districts\n\nplt.style.use('default')\nplt.figure(figsize=(14,8))\n\nplotting = sns.countplot(\n    y=\"state\",\n    data=districts_df,\n    order=districts_df.state.value_counts().index,\n    palette=\"Greys_d\",\n    linewidth=3\n)\n\nfor container in plotting.containers:\n    plotting.bar_label(container,fontsize=16)\n\n#Text\nplotting.text(x = -5, y = -4.2, s = \"State Distribution\",fontsize = 24, weight = 'bold', alpha = .90);\nplotting.text(x = -5, y = -3, s = \"Distribution of United States\",fontsize = 16, alpha = .85)\nplotting.text(x = 31.2, y = 0.08, s = 'Highest', weight = 'bold',fontsize = 14)\nplotting.text(x = 1.7, y = 22.3, s = 'Lowest', weight = 'bold',fontsize = 14)\n\nplt.yticks(fontsize=14)\nplt.xticks(fontsize=14)\n\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nLocales are separated into 4 categories: Suburb,Rural, City and Town, where most of the locales are concentrated in the Suburb category (104).\nFor the pct_black/hispanic variable, Rural and Town categories concentrate their entire population close to the interval $ [0,0.2 [$, while for the others sectors this percentage is varied.\nFor pctfree/reduced and pp_total_raw indicators, the distribution for each location is different, although they tend to focus on a particular interval.\n\n# heatmap: districts -&gt; locale\n\ntemp = districts_df.groupby('locale').pp_total_raw.value_counts().to_frame()\ntemp.columns = ['amount']\n\ntemp = temp.reset_index(drop=False)\n\ntemp = temp.pivot(index='locale', columns='pp_total_raw')['amount']\ntemp = temp[['[4000, 6000[', '[6000, 8000[', '[8000, 10000[', '[10000, 12000[',\n       '[12000, 14000[', '[14000, 16000[', '[16000, 18000[', \n       '[18000, 20000[', '[20000, 22000[', '[22000, 24000[', ]]\n\n\ntemp1 = districts_df.groupby('locale')['pct_black/hispanic'].value_counts().to_frame()\ntemp1.columns = ['amount']\n\ntemp1 = temp1.reset_index(drop=False)\ntemp1 = temp1.pivot(index='locale', columns='pct_black/hispanic')['amount']\n\ntemp2 = districts_df.groupby('locale')['pct_free/reduced'].value_counts().to_frame()\ntemp2.columns = ['amount']\n\ntemp2 = temp2.reset_index(drop=False)\n\ntemp2 = temp2.pivot(index='locale', columns='pct_free/reduced')['amount']\n\nplt.style.use('default')\n\nfig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(24,18))\n\nsns.countplot(data=districts_df, x='locale', ax=ax1, palette='Greys_d')\nax1.text(x = -0.5, y = 120, s = \"Locale Distribution\",fontsize = 24, weight = 'bold', alpha = .90);\nax1.xaxis.set_tick_params(labelsize=16)\n\nfor container in ax1.containers:\n    ax1.bar_label(container,fontsize=16)\n\nsns.heatmap(temp1.fillna(0), annot=True,  cmap='Greys', ax=ax2,annot_kws={\"fontsize\":14})\nax2.set_title('Heatmap: locale and pct_black/hispanic',fontsize=16,loc='left')\nax2.xaxis.set_tick_params(labelsize=16)\nax2.yaxis.set_tick_params(labelsize=16)\n\nsns.heatmap(temp.fillna(0), annot=True,  cmap='Greys', ax=ax3,annot_kws={\"fontsize\":14})\nax3.set_title('Heatmap: locale and pp_total_raw',fontsize=16,loc='left')\nax3.xaxis.set_tick_params(labelsize=16)\nax3.yaxis.set_tick_params(labelsize=16)\n\nsns.heatmap(temp2.fillna(0), annot=True,  cmap='Greys', ax=ax4,annot_kws={\"fontsize\":14})\nax4.set_title('Heatmap: locale and pct_free/reduced',fontsize=16,loc='left')\nax4.xaxis.set_tick_params(labelsize=16)\nax4.yaxis.set_tick_params(labelsize=16)\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSectors are separated into 3 categories: sector_Corporate, sector_HigherEd and sector_PreK-12, donde la categorÃ­a mayoritaria corresponde a sector_PreK-12 (350). On the other hand, analyzing the primary_function_main variable, all sectors are focused on theLC category. It is worth mentioning that the distribution of the other categories remains almost the same between sectors.\n\nplt.style.use('default')\nnames = ['sector_Corporate', 'sector_HigherEd','sector_PreK-12']\ncounts = [products_df[x].sum() for x in names]\n\ntemp_bar = pd.DataFrame({\n    'sector':names,\n    'count':counts\n}).sort_values('count',ascending = False)\n\ntemp = products_df.groupby('primary_function_main')[names].sum()\n\n#fig, [ax1, ax2 ]= plt.subplots(nrows=1, ncols=2, figsize=(12,6))\nplt.figure(figsize=(18,18))\n\nplt.subplot(3,2,1)\nax = sns.barplot(x=\"sector\", y=\"count\", data=temp_bar,palette ='Greys_d')\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=12)\n\nplt.subplot(3,2,2)\n\nsns.heatmap(temp.T, annot=True,  cmap='Greys',annot_kws={\"fontsize\":10},fmt='g')\n\nplt.text(x = -6, y = -0.25, s = \"Sectors Distribution\",fontsize = 18, weight = 'bold', alpha = .90);\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nContinuing the analysis of the primary_function_main variable, it was observed that most of these are in theLC category (77%). Within this category, its subcategory is analyzed, where the predominant subcategory is Sites, Resources & Reference (101).\n\n# pieplot: products\n\ncolor = [\n    'darkgray',\n    'silver',\n    'lightgray',\n    'gainsboro',\n]\n\nproducts_df[\"primary_function_main\"].value_counts().plot(\n    kind = 'pie', \n    autopct='%1d%%', \n    figsize=(6,6), \n    colors=color,\n    wedgeprops={\"edgecolor\":\"k\",'linewidth': 0.8,},\n    textprops={'color':\"black\"},\n    startangle=0)\nplt.text(x = -1.4, y = 1.1, s = \"Categories\",fontsize = 18, weight = 'bold', alpha = .90);\nplt.show()\n\n\n\n\n\n\n\n\n\n# pieplot: products -&gt; subcategories\n\nplt.style.use('default')\nplt.figure(figsize=(18,8))\n\ntemp = products_df[products_df.primary_function_main == 'LC']\nax = sns.countplot(\n    data=temp, \n    y='primary_function_sub',\n    order=temp.primary_function_sub.value_counts().index,\n    palette ='Greys_d'\n)\n\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=16)\n\n\n#plt.title('Sub-Categories in Primary Function LC')\nplt.text(x = -50, y = -0.8, \n         s = \"Sub-Categories in Primary Function LC\",fontsize = 24, weight = 'bold', alpha = .90);\n\nplt.text(x = 105, y =0.08, s = 'Highest', weight = 'bold',fontsize=16)\nplt.text(x = 7, y = 6, s = 'Lowest', weight = 'bold',fontsize=16)\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nAfter understanding the functionality of each of the tools, it is necessary to understand the distribution of the tools. The first thing is to study the distribution of the providers of the products we have, where:\n\n258 providers have 1 occurrences.\n18 providers have 2 occurrences.\n9 providers have 3 occurrences.\n2 providers have 4 occurrences.\n2 providers have 6 occurrences.\n1 provider have 30 occurrences.\n\nBased on this, only the top 15 providers will be displayed.\n\ndct = {\n    'Savvas Learning Company | Formerly Pearson K12 Learning': 'Savvas Learning Company'\n}\n\ntemp = products_df['provider/company_name'].value_counts().reset_index()\ntemp.columns = ['provider/company_name','count']\ntemp = temp.replace( {\n    'Savvas Learning Company | Formerly Pearson K12 Learning': 'Savvas Learning Company'\n})\n\nn = 15\ntemp = temp.sort_values('count',ascending = False).head(n)\n\nplt.style.use('default')\nplt.figure(figsize=(18,8))\n\nax = sns.barplot(\n    data=temp, \n    y='provider/company_name',\n    x='count',\n    palette ='Greys_d'\n)\n\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=15)\n    \nplt.text(x = -7, y = -1, \n         s = f\"Top {n} provider/company name\",fontsize = 20, weight = 'bold', alpha = .90);\n   \nplt.text(x = 31, y =0.08, s = 'Highest', weight = 'bold',fontsize=16)\nplt.text(x = 3, y = 14.2, s = 'Lowest', weight = 'bold',fontsize=16)\nplt.yticks(fontsize=16)\n\n\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\nplt.show()\n\n\n\n\n\n\n\n\nWith regard to products, there are about 372 different products.\nWe can make a word cloud to be able to analyze in a different way, words by themselves that are repeated the most in the product_name variable.\n\ncloud = WordCloud(\n    width=1080,\n    height=270,\n    colormap='Greys',\n    background_color='white'\n    ).generate(\" \".join(products_df['product_name'].astype(str)))\n\nplt.figure(figsize=(22, 10))\nplt.imshow(cloud)\nplt.axis('off');\n\n\n\n\n\n\n\n\nTo understand more in detail the use of these products, we will analyze the use of these products with respect to the variable engagement_index. The first graph is related to the average engagement_index (per student) for the year 2020, where the first 15 products will be displayed.\nAn important fact is that 362 products have an average of less than 1!.\n\ngroup_01 = (engagement_df_mix.groupby('product_name')['engagement_index'].mean()/1000).reset_index().sort_values('engagement_index',ascending = False)\ngroup_01['engagement_index'] = group_01['engagement_index'].apply(lambda x: round(x,2))\nless_1 = len(group_01.loc[lambda x:x['engagement_index']&lt;1])\n\n\nplt.style.use('default')\nplt.figure(figsize=(14,8))\n\nplotting = sns.barplot(\n    y=\"product_name\",\n    x = \"engagement_index\",\n    data=group_01.head(20),\n    palette=\"Greys_d\",\n\n)\n\nfor container in plotting.containers:\n    plotting.bar_label(container,fontsize=14)\n\nplt.text(x = -3.5, y = -3, \n         s = \"Mean daily page-load events in top 20 tools\",fontsize = 20, weight = 'bold', alpha = .90);\n\nplt.text(x = -3.5, y = -2, \n         s = \"per 1 student\",fontsize = 14,  alpha = .90);\n\nplt.text(x = 11, y =0.1, s = 'Highest', weight = 'bold',fontsize=14)\nplt.text(x = 1, y = 19.2, s = 'Lowest', weight = 'bold',fontsize=14)\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\nplt.show()\n\n\n\n\n\n\n\n\nLetâ€™s study the temporal behavior (at the level of weeks) of these tools during the year 2020, where the most three used tools will be shown with different colors, while the other tools will be visualized but with the same color (in order to understand their distribution).\n\nNote: The proposed analysis can be carried out at the day level and analyzing through time series each of the tools during the year 2020.\n\n\ncol = 'week'\n\ngroup_04  = (engagement_df_mix.groupby(['product_name',col])['engagement_index'].mean()/1000).reset_index().sort_values('engagement_index',ascending = False)\n\ng_high = group_01.head(3)['product_name']\ngroup_04_top = group_04.loc[lambda x: x.product_name.isin(g_high)]\n\nstates = group_04['product_name'].unique()\ntimes= group_04[col].unique()\n\nindex = pd.MultiIndex.from_product([states,times], names = [\"product_name\", col])\n\ndf_complete = pd.DataFrame(index = index).reset_index().fillna(0)\n\ngroup_04 = df_complete.merge(group_04,on = ['product_name',col],how='left').fillna(0)\n\nn = 3\ng_high = group_04.groupby('product_name')['engagement_index'].sum().sort_values(ascending=False).head(n).index.to_list()\n\n\ncolors = [    \n    'lightgray', \n    'dimgray', \n    'black', \n    'firebrick', \n    'darkred']\npalette_01 = {x:'lavender' for x in group_04['product_name'].unique() if x not in g_high}\npalette_02 = {g_high[i]:colors[i] for i in range(n)}\n\nplt.style.use('default')\nplt.figure(figsize=(20,6))\n\n\nsns.lineplot(\n    data=group_04.loc[lambda x: ~x.product_name.isin(g_high)], \n    x=col, \n    y=\"engagement_index\", \n    hue='product_name',\n    legend = False,\n    palette=palette_01,\n    linewidth = 1.\n\n    )\n\nsns.lineplot(\n    data=group_04.loc[lambda x: x.product_name.isin(g_high)], \n    x=col, \n    y=\"engagement_index\", \n    hue='product_name',\n    palette=palette_02,\n    linewidth = 1.\n\n    )\n\n\nplt.text(x = -2, y =23.7, s = 'Mean daily page-load events in top 3 tools', weight = 'bold',fontsize=14)\nplt.text(x = -2, y =22.3, s = 'by products and time, per 1 student',fontsize=12)\n\n\nplt.text(x = 12, y =20.7, s = '1,000 cases of COVID', weight = 'bold',fontsize=8)\nplt.text(x = 37, y =20.7, s = '1st September', weight = 'bold',fontsize=8)\n\n\nplt.axvline(x = 11, color = 'black', linestyle='--',linewidth = 0.5)\nplt.axvline(x = 36, color = 'black', linestyle='--',linewidth = 0.5)\nplt.show()\n\n\n\n\n\n\n\n\nNow, we can understand the engagement index for the most important tools about districts, where the districts of * Wisconsin ,  Missouri * and * Virginia * have the highest engagement index among the three most used tools.\n\ngroup_02 = (engagement_df_mix.groupby(['state','product_name'])['engagement_index'].mean()/1000)\\\n            .reset_index().sort_values('engagement_index',ascending = False).fillna(0)\n\ngripo_02_top = group_02.loc[lambda x: x.product_name.isin(g_high)]\ngripo_02_top['engagement_index'] = gripo_02_top['engagement_index'].apply(lambda x: round(x,2))\n#gripo_02_top = gripo_02_top.loc[lambda x: x['engagement_index']&gt;0]\n\n\nplt.style.use('default')\n\ng = sns.FacetGrid(gripo_02_top,hue='product_name',col = 'product_name',height=4, col_wrap= 3  )\ng.map(sns.barplot, \"engagement_index\",\"state\", palette=\"Greys_d\",)\n\ng.fig.set_size_inches(15, 8)\ng.fig.subplots_adjust(top=0.81, right=0.86)\n\naxes = g.axes.flatten()\nfor ax in axes:\n    for container in ax.containers:\n        ax.bar_label(container,fontsize=8)\n\n\nplt.text(x = -50, y = -4, s = \"Mean daily page-load events in top 3 tools\",fontsize = 16, weight = 'bold', alpha = .90);\nplt.text(x = -50, y = -3, s = \"by state and products, per 1 student\",fontsize = 14,  alpha = .90);\nplt.show()"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html#summary",
    "href": "posts/2021/eda_learnplatform.html#summary",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "Depending on what you want to achieve you might want to carefully preselect districts. Note that we approach in this notebook might not necessarily suit your individual purposes.\nWhen looking at digital learning, you might want to spend sometime in figuring out which districts actually applied digital learning"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html#references",
    "href": "posts/2021/eda_learnplatform.html#references",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "Diverging Color Maps for Scientific Visualization (Expanded) - Kenneth Moreland\nKaggle Competitions:\n\nEnthusiast to Data Professional - What changes?\nHow To Approach Analytics Challenges\nMost popular tools in 2020 Digital Learning"
  },
  {
    "objectID": "posts/2021/2021-08-05-rise.html",
    "href": "posts/2021/2021-08-05-rise.html",
    "title": "RISE",
    "section": "",
    "text": "RISE es una extensiÃ³n a los jupyter notebooks que permite transformar tus notebooks en presentaciones interactivas.\nToda las celdas pueden editarse y ejecutarse directamente, durante la presentaciÃ³n. Esto es prÃ¡ctico si necesitas corregir un error en una celda de texto. MÃ¡s importante aÃºn, puedes ejecutar cÃ³digo directamente en el kernel. En una misma diapositiva puedes tener mÃºltiples celdas y elegir cuÃ¡l ejecutar, o corregir el texto y volver a ejecutar.\n\nAlgunas caracterÃ­sticas importantes del uso de RISE:\n\nSimplifica la generaciÃ³n de material.\nSe mantiene un archivo y no varios archivos para hablar de lo mismo.\nEs fÃ¡cil de corregir, no se necesita mucho esfuerzo (similar a una PPT).\n\nEn esta sesiÃ³n, se muestra un ejemplo de cÃ³mo crear una presentaciÃ³n con RISE.\n\nNota: Puede encontrar los cÃ³digos de este ejemplo en el siguiente repositorio. Por otro lado, puede revisar el siguente link para ver la compilaciÃ³n con GitLab CI/CD.\n\n\n\n\n\n\nPara instalar RISE, necesitarÃ¡ usar la lÃ­nea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge rise\nDe lo contrario, puede instalar con pip:\npip install RISE\n\nNota: No interactuarÃ¡s directamente con RISE. En su lugar, podrÃ¡ acceder a Ã©l a travÃ©s de Jupyter Notebooks.\n\n\n\n\n\nPara crear una presentaciÃ³n, deberÃ¡ iniciar Jupyter Notebooks y abrir un nuevo notebook (tenga en cuenta que debe hacer esto despuÃ©s de haber instalado RISE). Una vez que tenga un Jupyter Notebook nuevo, deberÃ¡ habilitar la presentaciÃ³n de diapositivas. Puede hacer esto haciendo lo siguiente:\n\nHaga clic en â€œVerâ€ en la barra de herramientas de Jupyter\nColoca el cursor sobre â€œBarra de herramientas de celdaâ€ en el menÃº â€œVerâ€\nHaga clic en â€œPresentaciÃ³n de diapositivasâ€ en el menÃº â€œBarra de herramientas de celdaâ€\n\n\n\n\nEn este punto, deberÃ­a tener una barra de herramientas de celda con un menÃº desplegable en el lado derecho: \nDeberÃ­a ver seis opciones aquÃ­. Este menÃº desplegable y sus opciones determinan cÃ³mo encaja cada celda en la presentaciÃ³n. Las opciones y sus descripciones se encuentran a continuaciÃ³n:\n\nslide: indica que la celda seleccionada debe ser el comienzo de una nueva diapositiva.\nsub-slide -: indica que la celda seleccionada debe ser el comienzo de una nueva sub-diapositiva, que aparece en un nuevo marco debajo de la diapositiva anterior.\nfragment: indica que la celda seleccionada debe aparecer como una compilaciÃ³n de la diapositiva anterior.\nskip: indica que la celda seleccionada debe omitirse y no ser parte de la presentaciÃ³n de diapositivas.\nnotes: indica que la celda seleccionada debe ser solo notas del presentador.\n- -: indica que la celda seleccionada debe seguir el comportamiento de la celda anterior, lo cual es Ãºtil cuando una celda de rebaja y una celda de cÃ³digo deben aparecer simultÃ¡neamente.\n\nCada una de estas opciones puede incluir cÃ³digo Python o cÃ³digo Markdown/HTML/LaTeX como un Jupyter Notebook tradicional.\n\n\n\nUna vez que se han utilizado las celdas para crear material para la presentaciÃ³n, la presentaciÃ³n se puede ver directamente desde el notebook.\nHay dos opciones para ver la presentaciÃ³n de diapositivas:\n\nUsar el acceso directo OPTION + R shortcut (ALT + R on Windows) para ingresar y salir del modo de presentaciÃ³n desde dentro de la computadora portÃ¡til\nAl hacer clic en el botÃ³n â€œModo de presentaciÃ³nâ€ de la computadora portÃ¡til, esto solo aparecerÃ¡ si ha instalado RISE.\n\n\nDespuÃ©s de ingresar al modo de presentaciÃ³n, deberÃ­a ver una pantalla similar a esta:\n\n\n\n\nSi bien puede ser tentador usar las teclas &lt;- y -&gt; para cambiar las diapositivas en la presentaciÃ³n, esto no funcionarÃ¡ por completo: omitirÃ¡ las celdas marcadas como sub-slides. En su lugar, se debe usar ESPACIO para mover la presentaciÃ³n de diapositivas hacia adelante y MAYÃšS + ESPACIO para mover la presentaciÃ³n de diapositivas hacia atrÃ¡s.\nHay muchos otros atajos de teclado a los que se puede acceder dentro de la presentaciÃ³n haciendo clic en el signo de interrogaciÃ³n (?) en la esquina inferior izquierda.\n\n\n\nUna de las mejores cosas de RISE es que funciona en una sesiÃ³n de Python en vivo, lo que significa que puede editar y ejecutar cÃ³digo mientras se ejecuta la presentaciÃ³n.\n\n\n\n\nPuedes exportar tu presentaciÃ³n desplegando la opciÃ³n: File -&gt; Download as.\n\nNota: Para poder descargar en formato .pdf, necesita tener instalado pandoc.\n\n\n\n\n\n\nRISE - Documentation\nCreating Interactive Slideshows in Jupyter Notebooks"
  },
  {
    "objectID": "posts/2021/2021-08-05-rise.html#introducciÃ³n",
    "href": "posts/2021/2021-08-05-rise.html#introducciÃ³n",
    "title": "RISE",
    "section": "",
    "text": "RISE es una extensiÃ³n a los jupyter notebooks que permite transformar tus notebooks en presentaciones interactivas.\nToda las celdas pueden editarse y ejecutarse directamente, durante la presentaciÃ³n. Esto es prÃ¡ctico si necesitas corregir un error en una celda de texto. MÃ¡s importante aÃºn, puedes ejecutar cÃ³digo directamente en el kernel. En una misma diapositiva puedes tener mÃºltiples celdas y elegir cuÃ¡l ejecutar, o corregir el texto y volver a ejecutar.\n\nAlgunas caracterÃ­sticas importantes del uso de RISE:\n\nSimplifica la generaciÃ³n de material.\nSe mantiene un archivo y no varios archivos para hablar de lo mismo.\nEs fÃ¡cil de corregir, no se necesita mucho esfuerzo (similar a una PPT).\n\nEn esta sesiÃ³n, se muestra un ejemplo de cÃ³mo crear una presentaciÃ³n con RISE.\n\nNota: Puede encontrar los cÃ³digos de este ejemplo en el siguiente repositorio. Por otro lado, puede revisar el siguente link para ver la compilaciÃ³n con GitLab CI/CD."
  },
  {
    "objectID": "posts/2021/2021-08-05-rise.html#primeros-pasos",
    "href": "posts/2021/2021-08-05-rise.html#primeros-pasos",
    "title": "RISE",
    "section": "",
    "text": "Para instalar RISE, necesitarÃ¡ usar la lÃ­nea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge rise\nDe lo contrario, puede instalar con pip:\npip install RISE\n\nNota: No interactuarÃ¡s directamente con RISE. En su lugar, podrÃ¡ acceder a Ã©l a travÃ©s de Jupyter Notebooks."
  },
  {
    "objectID": "posts/2021/2021-08-05-rise.html#habilitaciÃ³n-del-modo-de-presentaciÃ³n",
    "href": "posts/2021/2021-08-05-rise.html#habilitaciÃ³n-del-modo-de-presentaciÃ³n",
    "title": "RISE",
    "section": "",
    "text": "Para crear una presentaciÃ³n, deberÃ¡ iniciar Jupyter Notebooks y abrir un nuevo notebook (tenga en cuenta que debe hacer esto despuÃ©s de haber instalado RISE). Una vez que tenga un Jupyter Notebook nuevo, deberÃ¡ habilitar la presentaciÃ³n de diapositivas. Puede hacer esto haciendo lo siguiente:\n\nHaga clic en â€œVerâ€ en la barra de herramientas de Jupyter\nColoca el cursor sobre â€œBarra de herramientas de celdaâ€ en el menÃº â€œVerâ€\nHaga clic en â€œPresentaciÃ³n de diapositivasâ€ en el menÃº â€œBarra de herramientas de celdaâ€\n\n\n\n\nEn este punto, deberÃ­a tener una barra de herramientas de celda con un menÃº desplegable en el lado derecho: \nDeberÃ­a ver seis opciones aquÃ­. Este menÃº desplegable y sus opciones determinan cÃ³mo encaja cada celda en la presentaciÃ³n. Las opciones y sus descripciones se encuentran a continuaciÃ³n:\n\nslide: indica que la celda seleccionada debe ser el comienzo de una nueva diapositiva.\nsub-slide -: indica que la celda seleccionada debe ser el comienzo de una nueva sub-diapositiva, que aparece en un nuevo marco debajo de la diapositiva anterior.\nfragment: indica que la celda seleccionada debe aparecer como una compilaciÃ³n de la diapositiva anterior.\nskip: indica que la celda seleccionada debe omitirse y no ser parte de la presentaciÃ³n de diapositivas.\nnotes: indica que la celda seleccionada debe ser solo notas del presentador.\n- -: indica que la celda seleccionada debe seguir el comportamiento de la celda anterior, lo cual es Ãºtil cuando una celda de rebaja y una celda de cÃ³digo deben aparecer simultÃ¡neamente.\n\nCada una de estas opciones puede incluir cÃ³digo Python o cÃ³digo Markdown/HTML/LaTeX como un Jupyter Notebook tradicional.\n\n\n\nUna vez que se han utilizado las celdas para crear material para la presentaciÃ³n, la presentaciÃ³n se puede ver directamente desde el notebook.\nHay dos opciones para ver la presentaciÃ³n de diapositivas:\n\nUsar el acceso directo OPTION + R shortcut (ALT + R on Windows) para ingresar y salir del modo de presentaciÃ³n desde dentro de la computadora portÃ¡til\nAl hacer clic en el botÃ³n â€œModo de presentaciÃ³nâ€ de la computadora portÃ¡til, esto solo aparecerÃ¡ si ha instalado RISE.\n\n\nDespuÃ©s de ingresar al modo de presentaciÃ³n, deberÃ­a ver una pantalla similar a esta:\n\n\n\n\nSi bien puede ser tentador usar las teclas &lt;- y -&gt; para cambiar las diapositivas en la presentaciÃ³n, esto no funcionarÃ¡ por completo: omitirÃ¡ las celdas marcadas como sub-slides. En su lugar, se debe usar ESPACIO para mover la presentaciÃ³n de diapositivas hacia adelante y MAYÃšS + ESPACIO para mover la presentaciÃ³n de diapositivas hacia atrÃ¡s.\nHay muchos otros atajos de teclado a los que se puede acceder dentro de la presentaciÃ³n haciendo clic en el signo de interrogaciÃ³n (?) en la esquina inferior izquierda.\n\n\n\nUna de las mejores cosas de RISE es que funciona en una sesiÃ³n de Python en vivo, lo que significa que puede editar y ejecutar cÃ³digo mientras se ejecuta la presentaciÃ³n.\n\n\n\n\nPuedes exportar tu presentaciÃ³n desplegando la opciÃ³n: File -&gt; Download as.\n\nNota: Para poder descargar en formato .pdf, necesita tener instalado pandoc."
  },
  {
    "objectID": "posts/2021/2021-08-05-rise.html#referencias",
    "href": "posts/2021/2021-08-05-rise.html#referencias",
    "title": "RISE",
    "section": "",
    "text": "RISE - Documentation\nCreating Interactive Slideshows in Jupyter Notebooks"
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html",
    "href": "posts/2022/2021-07-15-tdd.html",
    "title": "Test Driven Development",
    "section": "",
    "text": "Esta secciÃ³n busca dar seÃ±ales de cÃ³mo abordar el desarrollo de software para Data Science usando Test Driven Development, una tÃ©cnica ampliamente usada en otros rubros de la programaciÃ³n.\n\n\nEn palabras simples, el desarrollo guiado por pruebas pone las pruebas en el corazÃ³n de nuestro trabajo. En su forma mÃ¡s simple consiste en un proceso iterativo de 3 fases:\n\n\nRed: Escribe un test que ponga a prueba una nueva funcionalidad y asegurate de que el test falla\nGreen: Escribe el cÃ³digo mÃ­nimo necesario para pasar ese test\nRefactor: Refactoriza de ser necesario\n\n\n\n\nA modo de ejemplo, vamos a testear la funciÃ³n paridad, que determina si un nÃºmero natural es par o no.\nLo primero que se debe hacer es crear el test, para ello se ocuparÃ¡ la librerÃ­a pytest.\n\nNota: No es necesario conocer previamente la librerÃ­a pytest para entender el ejemplo.\n\n@pytest.mark.parametrize(\n    \"number, expected\",\n    [\n        (2, 'par'),\n])\ndef test_paridad(number, expected):\n    assert paridad(number) == expected\nEl test nos dice que si el input es el nÃºmero 2, la funciÃ³n paridad devuelve el output 'par'. CÃ³mo aÃºn no hemos escrito la funciÃ³n, el test fallarÃ¡ (fase red).\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 1 item                                                                                                                                                                          \n\ntemp/test_funcion.py F                                              [100%]\n========= 1 failed in 0.14s  ===============================================\nAhora, se escribe la funciÃ³n paridad (fase green):\ndef paridad(n:int)-&gt;str:\n    \"\"\"\n    Determina si un numero natural es par o no.\n    \n    :param n: numero entero\n    :return: 'par' si es el numero es par; 'impar' en otro caso\n    \"\"\"\n    return 'par' if n%2==0 else 'impar'\nVolvemos a correr el test:\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 1 item                                                                                                                                                                          \n\ntemp/test_funcion.py .                                              [100%]\n========= 1 passed in 0.06s  ===============================================\nHemos cometido un descuido a proposito, no hemos testeado el caso si el nÃºmero fuese impar, por lo cual reescribimos el test (fase refactor)\n@pytest.mark.parametrize(\n    \"number, expected\",\n    [\n        (2, 'par'),\n        (3, 'impar'),\n])\ndef test_paridad(number, expected):\n    assert paridad(number) == expected\ny corremos nuevamente los test:\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 2 items                                                                                                                                                                          \n\ntemp/test_funcion.py ..                                              [100%]\n========= 2 passed in 0.06s  ===============================================\nListo, nuestra funciÃ³n paridad ha sido testeado correctamente!.\n\n\n\n\nExisten varias razones por las que uno deberÃ­a usar TDD. Entre ellas podemos encontrar: - Formular bien nuestros pensamientos mediante la escritura de un test significativo antes de ponernos a solucionar el problema nos ayuda a clarificar los lÃ­mites del problema y cÃ³mo podemos resolverlo. Con el tiempo esto ayuda a obtener un diseÃ±o modular y reusable del cÃ³digo. - Escribir tests ayuda la forma en que escribimos cÃ³digo, haciÃ©ndolo mÃ¡s legible a otros. Sin embargo, no es un acto de altruismo, la mayorÃ­a de las veces ese otro es tu futuro yo. - Verifica que el cÃ³digo funciona de la manera que se espera, y lo hace de forma automÃ¡tica. - Te permite realizar refactoring con la certeza de que no has roto nada. - Los tests escritos sirven como documentaciÃ³n para otros desarrolladores. - Es una prÃ¡ctica requerida en metodologÃ­as de desarrollo de software agile.\n\n\n\nEl 2008, Nagappan, Maximilien, Bhat y Williams publicaron el paper llamado Realizing Quality Improvement Through Test Driven Development - Results and Experiences of Four Industrial Teams, en donde estudiaron 4 equipos de trabajo (3 de Microsoft y 1 de IBM), con proyectos que variaban entre las 6000 lineas de cÃ³digo hasta las 155k. Estas son parte de sus conclusiones:\n\nTodos los equipos demostraron una baja considerable en la densidad de defectos: 40% para el equipo de IBM, y entre 60-90% para los equipos de Microsoft.\n\nComo todo en la vida, nada es gratis:\n\nIncremento del tiempo de desarrollo varÃ­a entre un 15% a 35%.\n\nSin embargo\n\nDesde un punto de vista de eficacia este incremento en tiempo de desarrollo se compensa por los costos de mantenciÃ³n reducidos debido al incremento en calidad.\n\nAdemÃ¡s, es importante escribir tests junto con la implementaciÃ³n en pequeÃ±as iteraciones. George y Williams encontraron que escribir tests despuÃ©s de que la aplicaciÃ³n estÃ¡ mas o menos lista hace que se testee menos porque los desarrolladores piensan en menos casos, y ademÃ¡s la aplicaciÃ³n se vuelve menos testeable. Otra conclusiÃ³n interesante del estudio de George y Williams es que un 79% de los desarrolladores experimentaron que el uso de TDD conlleva a un diseÃ±o mÃ¡s simple.\n\n\n\nNo, pero puedes usarlo casi siempre. El anÃ¡lisis exploratorio es un caso en que el uso de TDD no hace sentido. Una vez que tenemos definido el problema a solucionar y un mejor entendimiento del problema podemos aterrizar nuestras ideas a la implementaciÃ³n vÃ­a testing.\n\n\n\nAcÃ¡ listamos algunas librerÃ­as de TDD en Python: - unittest: MÃ³dulo dentro de la librerÃ­a estÃ¡ndar de Python. Permite realizar tests unitarios, de integraciÃ³n y end to end. - doctest: Permite realizar test de la documentaciÃ³n del cÃ³digo (ejemplos: Numpy o Pandas). - pytest: LibrerÃ­a de testing ampliamente usada en proyectos nuevos de Python. - nose: LibrerÃ­a que extiende unittest para hacerlo mÃ¡s simple. - coverage: Herramienta para medir la cobertura de cÃ³digo de los proyectos. - tox: Herramienta para facilitar el test de una librerÃ­a en diferentes versiones e intÃ©rpretes de Python. - hypothesis: LibrerÃ­a para escribir tests vÃ­a reglas que ayuda a encontrar casos borde. - behave: Permite utilizar Behavior Driven Development, un proceso de desarrollo derivado del TDD.\n\n\n\n\nRealizing Quality Improvement Through Test Driven Development - Results and Experiences of Four Industrial Teams, es una buena lectura, sobretodo los consejos que dan en las conclusiones.\nGoogle Testing Blog: Poseen varios artÃ­culos sobre cÃ³mo abordar problemas tipo, buenas prÃ¡cticas de diseÃ±o para generar cÃ³digo testeable, entre otros. En particular destaca la serie Testing on the Toilet.\nCualquier artÃ­culo de Martin Fowler sobre testing, empezando por Ã©ste\nDesign Patterns: Los patrones de diseÃ±o de software tienen en consideraciÃ³n que el cÃ³digo sea testeable."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#introducciÃ³n",
    "href": "posts/2022/2021-07-15-tdd.html#introducciÃ³n",
    "title": "Test Driven Development",
    "section": "",
    "text": "Esta secciÃ³n busca dar seÃ±ales de cÃ³mo abordar el desarrollo de software para Data Science usando Test Driven Development, una tÃ©cnica ampliamente usada en otros rubros de la programaciÃ³n.\n\n\nEn palabras simples, el desarrollo guiado por pruebas pone las pruebas en el corazÃ³n de nuestro trabajo. En su forma mÃ¡s simple consiste en un proceso iterativo de 3 fases:\n\n\nRed: Escribe un test que ponga a prueba una nueva funcionalidad y asegurate de que el test falla\nGreen: Escribe el cÃ³digo mÃ­nimo necesario para pasar ese test\nRefactor: Refactoriza de ser necesario\n\n\n\n\nA modo de ejemplo, vamos a testear la funciÃ³n paridad, que determina si un nÃºmero natural es par o no.\nLo primero que se debe hacer es crear el test, para ello se ocuparÃ¡ la librerÃ­a pytest.\n\nNota: No es necesario conocer previamente la librerÃ­a pytest para entender el ejemplo.\n\n@pytest.mark.parametrize(\n    \"number, expected\",\n    [\n        (2, 'par'),\n])\ndef test_paridad(number, expected):\n    assert paridad(number) == expected\nEl test nos dice que si el input es el nÃºmero 2, la funciÃ³n paridad devuelve el output 'par'. CÃ³mo aÃºn no hemos escrito la funciÃ³n, el test fallarÃ¡ (fase red).\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 1 item                                                                                                                                                                          \n\ntemp/test_funcion.py F                                              [100%]\n========= 1 failed in 0.14s  ===============================================\nAhora, se escribe la funciÃ³n paridad (fase green):\ndef paridad(n:int)-&gt;str:\n    \"\"\"\n    Determina si un numero natural es par o no.\n    \n    :param n: numero entero\n    :return: 'par' si es el numero es par; 'impar' en otro caso\n    \"\"\"\n    return 'par' if n%2==0 else 'impar'\nVolvemos a correr el test:\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 1 item                                                                                                                                                                          \n\ntemp/test_funcion.py .                                              [100%]\n========= 1 passed in 0.06s  ===============================================\nHemos cometido un descuido a proposito, no hemos testeado el caso si el nÃºmero fuese impar, por lo cual reescribimos el test (fase refactor)\n@pytest.mark.parametrize(\n    \"number, expected\",\n    [\n        (2, 'par'),\n        (3, 'impar'),\n])\ndef test_paridad(number, expected):\n    assert paridad(number) == expected\ny corremos nuevamente los test:\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 2 items                                                                                                                                                                          \n\ntemp/test_funcion.py ..                                              [100%]\n========= 2 passed in 0.06s  ===============================================\nListo, nuestra funciÃ³n paridad ha sido testeado correctamente!."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#porquÃ©-deberÃ­a-usarlo",
    "href": "posts/2022/2021-07-15-tdd.html#porquÃ©-deberÃ­a-usarlo",
    "title": "Test Driven Development",
    "section": "",
    "text": "Existen varias razones por las que uno deberÃ­a usar TDD. Entre ellas podemos encontrar: - Formular bien nuestros pensamientos mediante la escritura de un test significativo antes de ponernos a solucionar el problema nos ayuda a clarificar los lÃ­mites del problema y cÃ³mo podemos resolverlo. Con el tiempo esto ayuda a obtener un diseÃ±o modular y reusable del cÃ³digo. - Escribir tests ayuda la forma en que escribimos cÃ³digo, haciÃ©ndolo mÃ¡s legible a otros. Sin embargo, no es un acto de altruismo, la mayorÃ­a de las veces ese otro es tu futuro yo. - Verifica que el cÃ³digo funciona de la manera que se espera, y lo hace de forma automÃ¡tica. - Te permite realizar refactoring con la certeza de que no has roto nada. - Los tests escritos sirven como documentaciÃ³n para otros desarrolladores. - Es una prÃ¡ctica requerida en metodologÃ­as de desarrollo de software agile."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#evidencia-empÃ­rica",
    "href": "posts/2022/2021-07-15-tdd.html#evidencia-empÃ­rica",
    "title": "Test Driven Development",
    "section": "",
    "text": "El 2008, Nagappan, Maximilien, Bhat y Williams publicaron el paper llamado Realizing Quality Improvement Through Test Driven Development - Results and Experiences of Four Industrial Teams, en donde estudiaron 4 equipos de trabajo (3 de Microsoft y 1 de IBM), con proyectos que variaban entre las 6000 lineas de cÃ³digo hasta las 155k. Estas son parte de sus conclusiones:\n\nTodos los equipos demostraron una baja considerable en la densidad de defectos: 40% para el equipo de IBM, y entre 60-90% para los equipos de Microsoft.\n\nComo todo en la vida, nada es gratis:\n\nIncremento del tiempo de desarrollo varÃ­a entre un 15% a 35%.\n\nSin embargo\n\nDesde un punto de vista de eficacia este incremento en tiempo de desarrollo se compensa por los costos de mantenciÃ³n reducidos debido al incremento en calidad.\n\nAdemÃ¡s, es importante escribir tests junto con la implementaciÃ³n en pequeÃ±as iteraciones. George y Williams encontraron que escribir tests despuÃ©s de que la aplicaciÃ³n estÃ¡ mas o menos lista hace que se testee menos porque los desarrolladores piensan en menos casos, y ademÃ¡s la aplicaciÃ³n se vuelve menos testeable. Otra conclusiÃ³n interesante del estudio de George y Williams es que un 79% de los desarrolladores experimentaron que el uso de TDD conlleva a un diseÃ±o mÃ¡s simple."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#puedo-usar-tdd-siempre",
    "href": "posts/2022/2021-07-15-tdd.html#puedo-usar-tdd-siempre",
    "title": "Test Driven Development",
    "section": "",
    "text": "No, pero puedes usarlo casi siempre. El anÃ¡lisis exploratorio es un caso en que el uso de TDD no hace sentido. Una vez que tenemos definido el problema a solucionar y un mejor entendimiento del problema podemos aterrizar nuestras ideas a la implementaciÃ³n vÃ­a testing."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#librerÃ­as-disponibles",
    "href": "posts/2022/2021-07-15-tdd.html#librerÃ­as-disponibles",
    "title": "Test Driven Development",
    "section": "",
    "text": "AcÃ¡ listamos algunas librerÃ­as de TDD en Python: - unittest: MÃ³dulo dentro de la librerÃ­a estÃ¡ndar de Python. Permite realizar tests unitarios, de integraciÃ³n y end to end. - doctest: Permite realizar test de la documentaciÃ³n del cÃ³digo (ejemplos: Numpy o Pandas). - pytest: LibrerÃ­a de testing ampliamente usada en proyectos nuevos de Python. - nose: LibrerÃ­a que extiende unittest para hacerlo mÃ¡s simple. - coverage: Herramienta para medir la cobertura de cÃ³digo de los proyectos. - tox: Herramienta para facilitar el test de una librerÃ­a en diferentes versiones e intÃ©rpretes de Python. - hypothesis: LibrerÃ­a para escribir tests vÃ­a reglas que ayuda a encontrar casos borde. - behave: Permite utilizar Behavior Driven Development, un proceso de desarrollo derivado del TDD."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#referencias",
    "href": "posts/2022/2021-07-15-tdd.html#referencias",
    "title": "Test Driven Development",
    "section": "",
    "text": "Realizing Quality Improvement Through Test Driven Development - Results and Experiences of Four Industrial Teams, es una buena lectura, sobretodo los consejos que dan en las conclusiones.\nGoogle Testing Blog: Poseen varios artÃ­culos sobre cÃ³mo abordar problemas tipo, buenas prÃ¡cticas de diseÃ±o para generar cÃ³digo testeable, entre otros. En particular destaca la serie Testing on the Toilet.\nCualquier artÃ­culo de Martin Fowler sobre testing, empezando por Ã©ste\nDesign Patterns: Los patrones de diseÃ±o de software tienen en consideraciÃ³n que el cÃ³digo sea testeable."
  }
]