[
  {
    "objectID": "posts/2022/2021-07-15-tdd.html",
    "href": "posts/2022/2021-07-15-tdd.html",
    "title": "Test Driven Development",
    "section": "",
    "text": "Esta sección busca dar señales de cómo abordar el desarrollo de software para Data Science usando Test Driven Development, una técnica ampliamente usada en otros rubros de la programación.\n\n🔑 Nota: Les comparto de manera complementaria la charla que impartí en la conferencia de Python Chile sobre Test Driven Development (TDD).\n\n\n\nEn palabras simples, el desarrollo guiado por pruebas pone las pruebas en el corazón de nuestro trabajo. En su forma más simple consiste en un proceso iterativo de 3 fases:\n\n\nRed: Escribe un test que ponga a prueba una nueva funcionalidad y asegurate de que el test falla\nGreen: Escribe el código mínimo necesario para pasar ese test\nRefactor: Refactoriza de ser necesario\n\n\n\nA modo de ejemplo, vamos a testear la función paridad, que determina si un número natural es par o no.\nLo primero que se debe hacer es crear el test, para ello se ocupará la librería pytest.\n\nNota: No es necesario conocer previamente la librería pytest para entender el ejemplo.\n\n@pytest.mark.parametrize(\n    \"number, expected\",\n    [\n        (2, 'par'),\n])\ndef test_paridad(number, expected):\n    assert paridad(number) == expected\nEl test nos dice que si el input es el número 2, la función paridad devuelve el output 'par'. Cómo aún no hemos escrito la función, el test fallará (fase red).\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 1 item                                                                                                                                                                          \n\ntemp/test_funcion.py F                                              [100%]\n========= 1 failed in 0.14s  ===============================================\nAhora, se escribe la función paridad (fase green):\ndef paridad(n:int)-&gt;str:\n    \"\"\"\n    Determina si un numero natural es par o no.\n    \n    :param n: numero entero\n    :return: 'par' si es el numero es par; 'impar' en otro caso\n    \"\"\"\n    return 'par' if n%2==0 else 'impar'\nVolvemos a correr el test:\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 1 item                                                                                                                                                                          \n\ntemp/test_funcion.py .                                              [100%]\n========= 1 passed in 0.06s  ===============================================\nHemos cometido un descuido a proposito, no hemos testeado el caso si el número fuese impar, por lo cual reescribimos el test (fase refactor)\n@pytest.mark.parametrize(\n    \"number, expected\",\n    [\n        (2, 'par'),\n        (3, 'impar'),\n])\ndef test_paridad(number, expected):\n    assert paridad(number) == expected\ny corremos nuevamente los test:\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 2 items                                                                                                                                                                          \n\ntemp/test_funcion.py ..                                              [100%]\n========= 2 passed in 0.06s  ===============================================\nListo, nuestra función paridad ha sido testeado correctamente!.\n\n\n\n\nExisten varias razones por las que uno debería usar TDD. Entre ellas podemos encontrar: - Formular bien nuestros pensamientos mediante la escritura de un test significativo antes de ponernos a solucionar el problema nos ayuda a clarificar los límites del problema y cómo podemos resolverlo. Con el tiempo esto ayuda a obtener un diseño modular y reusable del código. - Escribir tests ayuda la forma en que escribimos código, haciéndolo más legible a otros. Sin embargo, no es un acto de altruismo, la mayoría de las veces ese otro es tu futuro yo. - Verifica que el código funciona de la manera que se espera, y lo hace de forma automática. - Te permite realizar refactoring con la certeza de que no has roto nada. - Los tests escritos sirven como documentación para otros desarrolladores. - Es una práctica requerida en metodologías de desarrollo de software agile.\n\n\n\nEl 2008, Nagappan, Maximilien, Bhat y Williams publicaron el paper llamado Realizing Quality Improvement Through Test Driven Development - Results and Experiences of Four Industrial Teams, en donde estudiaron 4 equipos de trabajo (3 de Microsoft y 1 de IBM), con proyectos que variaban entre las 6000 lineas de código hasta las 155k. Estas son parte de sus conclusiones:\n\nTodos los equipos demostraron una baja considerable en la densidad de defectos: 40% para el equipo de IBM, y entre 60-90% para los equipos de Microsoft.\n\nComo todo en la vida, nada es gratis:\n\nIncremento del tiempo de desarrollo varía entre un 15% a 35%.\n\nSin embargo\n\nDesde un punto de vista de eficacia este incremento en tiempo de desarrollo se compensa por los costos de mantención reducidos debido al incremento en calidad.\n\nAdemás, es importante escribir tests junto con la implementación en pequeñas iteraciones. George y Williams encontraron que escribir tests después de que la aplicación está mas o menos lista hace que se testee menos porque los desarrolladores piensan en menos casos, y además la aplicación se vuelve menos testeable. Otra conclusión interesante del estudio de George y Williams es que un 79% de los desarrolladores experimentaron que el uso de TDD conlleva a un diseño más simple.\n\n\n\nNo, pero puedes usarlo casi siempre. El análisis exploratorio es un caso en que el uso de TDD no hace sentido. Una vez que tenemos definido el problema a solucionar y un mejor entendimiento del problema podemos aterrizar nuestras ideas a la implementación vía testing.\n\n\n\nAcá listamos algunas librerías de TDD en Python: - unittest: Módulo dentro de la librería estándar de Python. Permite realizar tests unitarios, de integración y end to end. - doctest: Permite realizar test de la documentación del código (ejemplos: Numpy o Pandas). - pytest: Librería de testing ampliamente usada en proyectos nuevos de Python. - nose: Librería que extiende unittest para hacerlo más simple. - coverage: Herramienta para medir la cobertura de código de los proyectos. - tox: Herramienta para facilitar el test de una librería en diferentes versiones e intérpretes de Python. - hypothesis: Librería para escribir tests vía reglas que ayuda a encontrar casos borde. - behave: Permite utilizar Behavior Driven Development, un proceso de desarrollo derivado del TDD.\n\n\n\n\nRealizing Quality Improvement Through Test Driven Development - Results and Experiences of Four Industrial Teams, es una buena lectura, sobretodo los consejos que dan en las conclusiones.\nGoogle Testing Blog: Poseen varios artículos sobre cómo abordar problemas tipo, buenas prácticas de diseño para generar código testeable, entre otros. En particular destaca la serie Testing on the Toilet.\nCualquier artículo de Martin Fowler sobre testing, empezando por éste\nDesign Patterns: Los patrones de diseño de software tienen en consideración que el código sea testeable."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#qué-es-el-test-driven-development",
    "href": "posts/2022/2021-07-15-tdd.html#qué-es-el-test-driven-development",
    "title": "Test Driven Development",
    "section": "",
    "text": "En palabras simples, el desarrollo guiado por pruebas pone las pruebas en el corazón de nuestro trabajo. En su forma más simple consiste en un proceso iterativo de 3 fases:\n\n\nRed: Escribe un test que ponga a prueba una nueva funcionalidad y asegurate de que el test falla\nGreen: Escribe el código mínimo necesario para pasar ese test\nRefactor: Refactoriza de ser necesario\n\n\n\nA modo de ejemplo, vamos a testear la función paridad, que determina si un número natural es par o no.\nLo primero que se debe hacer es crear el test, para ello se ocupará la librería pytest.\n\nNota: No es necesario conocer previamente la librería pytest para entender el ejemplo.\n\n@pytest.mark.parametrize(\n    \"number, expected\",\n    [\n        (2, 'par'),\n])\ndef test_paridad(number, expected):\n    assert paridad(number) == expected\nEl test nos dice que si el input es el número 2, la función paridad devuelve el output 'par'. Cómo aún no hemos escrito la función, el test fallará (fase red).\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 1 item                                                                                                                                                                          \n\ntemp/test_funcion.py F                                              [100%]\n========= 1 failed in 0.14s  ===============================================\nAhora, se escribe la función paridad (fase green):\ndef paridad(n:int)-&gt;str:\n    \"\"\"\n    Determina si un numero natural es par o no.\n    \n    :param n: numero entero\n    :return: 'par' si es el numero es par; 'impar' en otro caso\n    \"\"\"\n    return 'par' if n%2==0 else 'impar'\nVolvemos a correr el test:\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 1 item                                                                                                                                                                          \n\ntemp/test_funcion.py .                                              [100%]\n========= 1 passed in 0.06s  ===============================================\nHemos cometido un descuido a proposito, no hemos testeado el caso si el número fuese impar, por lo cual reescribimos el test (fase refactor)\n@pytest.mark.parametrize(\n    \"number, expected\",\n    [\n        (2, 'par'),\n        (3, 'impar'),\n])\ndef test_paridad(number, expected):\n    assert paridad(number) == expected\ny corremos nuevamente los test:\n========= test session starts ============================================ \nplatform linux -- Python 3.8.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\nrootdir: /home/fralfaro/PycharmProjects/ds_blog\nplugins: anyio-3.3.0\ncollected 2 items                                                                                                                                                                          \n\ntemp/test_funcion.py ..                                              [100%]\n========= 2 passed in 0.06s  ===============================================\nListo, nuestra función paridad ha sido testeado correctamente!."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#porqué-debería-usarlo",
    "href": "posts/2022/2021-07-15-tdd.html#porqué-debería-usarlo",
    "title": "Test Driven Development",
    "section": "",
    "text": "Existen varias razones por las que uno debería usar TDD. Entre ellas podemos encontrar: - Formular bien nuestros pensamientos mediante la escritura de un test significativo antes de ponernos a solucionar el problema nos ayuda a clarificar los límites del problema y cómo podemos resolverlo. Con el tiempo esto ayuda a obtener un diseño modular y reusable del código. - Escribir tests ayuda la forma en que escribimos código, haciéndolo más legible a otros. Sin embargo, no es un acto de altruismo, la mayoría de las veces ese otro es tu futuro yo. - Verifica que el código funciona de la manera que se espera, y lo hace de forma automática. - Te permite realizar refactoring con la certeza de que no has roto nada. - Los tests escritos sirven como documentación para otros desarrolladores. - Es una práctica requerida en metodologías de desarrollo de software agile."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#evidencia-empírica",
    "href": "posts/2022/2021-07-15-tdd.html#evidencia-empírica",
    "title": "Test Driven Development",
    "section": "",
    "text": "El 2008, Nagappan, Maximilien, Bhat y Williams publicaron el paper llamado Realizing Quality Improvement Through Test Driven Development - Results and Experiences of Four Industrial Teams, en donde estudiaron 4 equipos de trabajo (3 de Microsoft y 1 de IBM), con proyectos que variaban entre las 6000 lineas de código hasta las 155k. Estas son parte de sus conclusiones:\n\nTodos los equipos demostraron una baja considerable en la densidad de defectos: 40% para el equipo de IBM, y entre 60-90% para los equipos de Microsoft.\n\nComo todo en la vida, nada es gratis:\n\nIncremento del tiempo de desarrollo varía entre un 15% a 35%.\n\nSin embargo\n\nDesde un punto de vista de eficacia este incremento en tiempo de desarrollo se compensa por los costos de mantención reducidos debido al incremento en calidad.\n\nAdemás, es importante escribir tests junto con la implementación en pequeñas iteraciones. George y Williams encontraron que escribir tests después de que la aplicación está mas o menos lista hace que se testee menos porque los desarrolladores piensan en menos casos, y además la aplicación se vuelve menos testeable. Otra conclusión interesante del estudio de George y Williams es que un 79% de los desarrolladores experimentaron que el uso de TDD conlleva a un diseño más simple."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#puedo-usar-tdd-siempre",
    "href": "posts/2022/2021-07-15-tdd.html#puedo-usar-tdd-siempre",
    "title": "Test Driven Development",
    "section": "",
    "text": "No, pero puedes usarlo casi siempre. El análisis exploratorio es un caso en que el uso de TDD no hace sentido. Una vez que tenemos definido el problema a solucionar y un mejor entendimiento del problema podemos aterrizar nuestras ideas a la implementación vía testing."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#librerías-disponibles",
    "href": "posts/2022/2021-07-15-tdd.html#librerías-disponibles",
    "title": "Test Driven Development",
    "section": "",
    "text": "Acá listamos algunas librerías de TDD en Python: - unittest: Módulo dentro de la librería estándar de Python. Permite realizar tests unitarios, de integración y end to end. - doctest: Permite realizar test de la documentación del código (ejemplos: Numpy o Pandas). - pytest: Librería de testing ampliamente usada en proyectos nuevos de Python. - nose: Librería que extiende unittest para hacerlo más simple. - coverage: Herramienta para medir la cobertura de código de los proyectos. - tox: Herramienta para facilitar el test de una librería en diferentes versiones e intérpretes de Python. - hypothesis: Librería para escribir tests vía reglas que ayuda a encontrar casos borde. - behave: Permite utilizar Behavior Driven Development, un proceso de desarrollo derivado del TDD."
  },
  {
    "objectID": "posts/2022/2021-07-15-tdd.html#referencias",
    "href": "posts/2022/2021-07-15-tdd.html#referencias",
    "title": "Test Driven Development",
    "section": "",
    "text": "Realizing Quality Improvement Through Test Driven Development - Results and Experiences of Four Industrial Teams, es una buena lectura, sobretodo los consejos que dan en las conclusiones.\nGoogle Testing Blog: Poseen varios artículos sobre cómo abordar problemas tipo, buenas prácticas de diseño para generar código testeable, entre otros. En particular destaca la serie Testing on the Toilet.\nCualquier artículo de Martin Fowler sobre testing, empezando por éste\nDesign Patterns: Los patrones de diseño de software tienen en consideración que el código sea testeable."
  },
  {
    "objectID": "posts/2024/github_repos.html",
    "href": "posts/2024/github_repos.html",
    "title": "Github Repository",
    "section": "",
    "text": "Cuando trabajas en un proyecto en GitHub, a menudo te encuentras con el desafío de presentar tus trabajos de manera efectiva.\nYa sea que estés desarrollando una aplicación, quieras mostrar los proyectos realizados durante un diplomado o en algún curso en línea (MOOC), es crucial saber cómo destacar tu trabajo de la mejor manera posible.\nEn este artículo, te guiaré a través de algunos métodos efectivos para mostrar tus diversos repositorios según tus necesidades específicas.\n\n🔑 Nota: Para seguir este tutorial, es necesario disponer de una Cuenta en GitHub. Además, se recomienda actualizar tu foto de perfil y tu nombre de usuario.\n\n\n\nUn repositorio en GitHub es un espacio donde se almacenan y gestionan los archivos de un proyecto de software utilizando el sistema de control de versiones Git.\nEn términos simples, es como una carpeta o un directorio en tu computadora donde guardas todos los archivos relacionados con tu proyecto, pero alojado en la nube y accesible para ti y para otros colaboradores.\nAdemás de ser un lugar para almacenar archivos, GitHub proporciona una serie de herramientas y funcionalidades que facilitan la colaboración entre desarrolladores.\nEstas incluyen seguimiento de problemas (issue tracking), solicitudes de extracción (pull requests), revisión de código (code review), integración continua (continuous integration) y mucho más.\nEstas características hacen que GitHub sea una plataforma poderosa para el desarrollo de software en equipo y la colaboración en proyectos de código abierto.\n\n\n\n\nLos archivos README.md son documentos de texto con formato Markdown que se encuentran comúnmente en los repositorios de GitHub y en otros sistemas de control de versiones.\nEl nombre “README” proviene de “Read Me”, que indica su propósito principal: proporcionar información relevante sobre el proyecto para que los usuarios puedan leerlo rápidamente.\nLos README.md suelen contener información importante sobre el proyecto, como una descripción general del mismo, instrucciones de instalación, ejemplos de uso, requisitos del sistema, créditos y cualquier otra información relevante que los usuarios o colaboradores puedan necesitar.\nDado que el README.md es el primer documento que muchos visitantes de un repositorio verán, es importante redactarlo de manera clara y concisa para que puedan comprender rápidamente de qué se trata el proyecto y cómo pueden interactuar con él. Un README.md bien elaborado puede ser crucial.\n\n\n\n\nCuando se trata de crear un archivo README.md, la estructura y el contenido dependen en gran medida del enfoque que deseamos darle. En términos generales, podemos dividir este proceso en dos partes distintas, adaptadas a diferentes propósitos:\nPara Proyectos:\n\nDescripción Breve: Título claro y breve descripción del proyecto.\nInstrucciones de Uso: Pasos para instalar y utilizar el proyecto.\nContribuciones: Guía para contribuir al proyecto.\nLicencia: Información sobre la licencia del proyecto.\n\nPara Portafolios:\n\nDescripción Breve: Título claro y breve descripción del portafolio.\nLista de Proyectos: Títulos y descripciones breves de proyectos anteriores.\nTecnologías Utilizadas: Destacar las tecnologías empleadas en cada proyecto.\n\n\n\n\n🔑 Nota: Para una referencia sobre la estructura y contenido de un README de Proyectos, utilizaremos el siguiente proyecto como ejemplo: Proyecto Inventado.\n\n\nTítulo y Logotipo:\n\nEl título del proyecto, “Proyecto Inventado”, es claro y conciso, proporcionando a los usuarios una identificación inmediata del proyecto.\nEl logotipo centrado agrega un toque visual al README, lo que puede hacer que el proyecto sea más memorable. Sin embargo, asegúrate de que el enlace a la imagen sea correcto y accesible.\n\nTabla de Estado:\n\nEsta tabla muestra el estado del proyecto en términos de pruebas, paquete y metadatos.\nLos badges proporcionan información instantánea sobre el estado del proyecto, como los resultados de las pruebas, la cobertura del código, la versión del paquete, etc. Esto ayuda a los usuarios a evaluar rápidamente la salud y la calidad del proyecto.\n\nDescripción del Proyecto:\n\nLa descripción del proyecto proporciona una visión general del propósito, los objetivos y las características principales del proyecto.\nEs importante que esta descripción sea clara y concisa, pero lo suficientemente detallada como para transmitir la utilidad y el valor del proyecto a los posibles usuarios.\n\n\nTabla de Contenidos:\n\nLa tabla de contenidos enumera los diferentes apartados del README con enlaces directos a cada sección. Esto facilita la navegación y la búsqueda de información específica para los usuarios.\n\n\nInstalación:\n\nLa sección de instalación proporciona instrucciones detalladas sobre cómo instalar el proyecto en diferentes entornos.\nLos requisitos previos enumeran cualquier software adicional, configuraciones del sistema o permisos de usuario necesarios para la instalación.\nLos pasos de instalación proporcionan comandos específicos que los usuarios pueden seguir para instalar el proyecto correctamente.\n\n\nUso:\n\nLa sección de uso ofrece instrucciones detalladas sobre cómo utilizar el proyecto una vez instalado.\nLa configuración informa a los usuarios sobre cualquier configuración adicional que necesiten realizar antes de utilizar el proyecto, como la configuración de variables de entorno o archivos de configuración.\nLos ejemplos de uso proporcionan casos de uso comunes y comandos que los usuarios pueden ejecutar para interactuar con el software.\n\n\nCaracterísticas:\n\nEsta sección enumera y describe las características principales del proyecto, resaltando las funcionalidades únicas o importantes que lo diferencian de otros proyectos similares.\nEs importante destacar las características que hacen que el proyecto sea valioso para los usuarios y cómo estas características pueden beneficiarlos.\n\n\nContribuciones:\n\nLa sección de contribuciones proporciona instrucciones detalladas sobre cómo contribuir al proyecto.\nLa guía de contribución ofrece una guía paso a paso sobre cómo enviar solicitudes de extracción, informar problemas y cualquier otro proceso de contribución relevante.\nEs importante facilitar a los posibles colaboradores el proceso de contribución al proyecto para fomentar la participación y el desarrollo continuo.\n\n\nLicencia:\n\nLa sección de licencia informa a los usuarios sobre los términos de la licencia bajo la cual se distribuye el proyecto.\nProporciona un enlace a los términos de la licencia para que los usuarios puedan revisarlos y asegurarse de cumplir con ellos antes de utilizar, modificar o distribuir el software.\n\n\n\n\n\n\n\n🔑 Nota: Para una referencia sobre la estructura y contenido de un README de Portafolio, utilizaremos el siguiente proyecto como ejemplo: Curso de Desarrollo Web.\n\n\nTítulo:\n\nEl título “Curso de Desarrollo Web” es claro y describe el contenido principal del repositorio.\n\nDescripción:\n\nLa descripción ofrece una visión general del curso, mencionando que abarca desde conceptos básicos hasta proyectos avanzados en el campo del desarrollo web.\nIndica que los estudiantes aprenderán a crear aplicaciones web completas utilizando diferentes tecnologías y herramientas.\n\n\nProyectos:\n\nLos proyectos están organizados en categorías según el nivel de habilidad y las tecnologías utilizadas.\nCada categoría de proyecto incluye una tabla que enumera los nombres y descripciones de los proyectos correspondientes.\nLas descripciones proporcionan información sobre el propósito de cada proyecto y las tecnologías específicas utilizadas en su desarrollo.\n\n\nNotas:\n\nOfrece algunas notas adicionales para proporcionar contexto adicional sobre los proyectos.\nIndica que los proyectos están listados en el orden en que se completaron, lo que puede ser útil para seguir una progresión lógica.\nDestaca que cada proyecto incluye una descripción detallada y las tecnologías utilizadas, lo que brinda a los estudiantes información importante sobre lo que aprenderán en cada proyecto.\nSugiere que los usuarios pueden obtener más detalles sobre cada proyecto consultando los directorios correspondientes en el repositorio, lo que facilita la navegación y la búsqueda de información adicional.\n\n\n\n\n\n\n\n\nUna valiosa fuente de inspiración y orientación en este sentido es el repositorio awesome-readme creado por Matías Singers en GitHub. Este repositorio recopila una amplia variedad de ejemplos inspiradores y recursos útiles para la creación de READMEs impresionantes.\nDesde estructuras organizadas hasta consejos prácticos y ejemplos de READMEs destacados, “awesome-readme” ofrece una amplia gama de recursos para ayudarte a mejorar la presentación y documentación de tus proyectos en GitHub.\nAl explorar este repositorio, los desarrolladores pueden encontrar ideas innovadoras, plantillas útiles y ejemplos reales que les ayudarán a crear READMEs que destaquen entre la multitud y comuniquen eficazmente el valor de sus proyectos.\n\n\n\nLa presentación de tus proyectos en GitHub es clave para avanzar en tu carrera profesional. Este tutorial te ha mostrado cómo personalizar tus repositorios de manera efectiva, ya sea para proyectos de software o portafolios profesionales.\nAl seguir estas prácticas recomendadas, puedes:\n\nAtraer la atención de potenciales colaboradores y usuarios.\nComunicar claramente el valor de tus proyectos.\nFomentar la colaboración y el crecimiento de la comunidad.\nDemostrar tus habilidades y experiencia de manera efectiva.\nDestacar entre otros repositorios y aumentar la visibilidad de tu trabajo.\n\nAl dominar la presentación de tus proyectos en GitHub, puedes mejorar significativamente tu presencia en línea, impulsar tu carrera profesional y abrir nuevas oportunidades de colaboración y crecimiento."
  },
  {
    "objectID": "posts/2024/github_repos.html#sobre-los-repositorios-de-github",
    "href": "posts/2024/github_repos.html#sobre-los-repositorios-de-github",
    "title": "Github Repository",
    "section": "",
    "text": "Un repositorio en GitHub es un espacio donde se almacenan y gestionan los archivos de un proyecto de software utilizando el sistema de control de versiones Git.\nEn términos simples, es como una carpeta o un directorio en tu computadora donde guardas todos los archivos relacionados con tu proyecto, pero alojado en la nube y accesible para ti y para otros colaboradores.\nAdemás de ser un lugar para almacenar archivos, GitHub proporciona una serie de herramientas y funcionalidades que facilitan la colaboración entre desarrolladores.\nEstas incluyen seguimiento de problemas (issue tracking), solicitudes de extracción (pull requests), revisión de código (code review), integración continua (continuous integration) y mucho más.\nEstas características hacen que GitHub sea una plataforma poderosa para el desarrollo de software en equipo y la colaboración en proyectos de código abierto."
  },
  {
    "objectID": "posts/2024/github_repos.html#sobre-los-readme.md",
    "href": "posts/2024/github_repos.html#sobre-los-readme.md",
    "title": "Github Repository",
    "section": "",
    "text": "Los archivos README.md son documentos de texto con formato Markdown que se encuentran comúnmente en los repositorios de GitHub y en otros sistemas de control de versiones.\nEl nombre “README” proviene de “Read Me”, que indica su propósito principal: proporcionar información relevante sobre el proyecto para que los usuarios puedan leerlo rápidamente.\nLos README.md suelen contener información importante sobre el proyecto, como una descripción general del mismo, instrucciones de instalación, ejemplos de uso, requisitos del sistema, créditos y cualquier otra información relevante que los usuarios o colaboradores puedan necesitar.\nDado que el README.md es el primer documento que muchos visitantes de un repositorio verán, es importante redactarlo de manera clara y concisa para que puedan comprender rápidamente de qué se trata el proyecto y cómo pueden interactuar con él. Un README.md bien elaborado puede ser crucial."
  },
  {
    "objectID": "posts/2024/github_repos.html#creando-un-readme.md-a-la-medida",
    "href": "posts/2024/github_repos.html#creando-un-readme.md-a-la-medida",
    "title": "Github Repository",
    "section": "",
    "text": "Cuando se trata de crear un archivo README.md, la estructura y el contenido dependen en gran medida del enfoque que deseamos darle. En términos generales, podemos dividir este proceso en dos partes distintas, adaptadas a diferentes propósitos:\nPara Proyectos:\n\nDescripción Breve: Título claro y breve descripción del proyecto.\nInstrucciones de Uso: Pasos para instalar y utilizar el proyecto.\nContribuciones: Guía para contribuir al proyecto.\nLicencia: Información sobre la licencia del proyecto.\n\nPara Portafolios:\n\nDescripción Breve: Título claro y breve descripción del portafolio.\nLista de Proyectos: Títulos y descripciones breves de proyectos anteriores.\nTecnologías Utilizadas: Destacar las tecnologías empleadas en cada proyecto.\n\n\n\n\n🔑 Nota: Para una referencia sobre la estructura y contenido de un README de Proyectos, utilizaremos el siguiente proyecto como ejemplo: Proyecto Inventado.\n\n\nTítulo y Logotipo:\n\nEl título del proyecto, “Proyecto Inventado”, es claro y conciso, proporcionando a los usuarios una identificación inmediata del proyecto.\nEl logotipo centrado agrega un toque visual al README, lo que puede hacer que el proyecto sea más memorable. Sin embargo, asegúrate de que el enlace a la imagen sea correcto y accesible.\n\nTabla de Estado:\n\nEsta tabla muestra el estado del proyecto en términos de pruebas, paquete y metadatos.\nLos badges proporcionan información instantánea sobre el estado del proyecto, como los resultados de las pruebas, la cobertura del código, la versión del paquete, etc. Esto ayuda a los usuarios a evaluar rápidamente la salud y la calidad del proyecto.\n\nDescripción del Proyecto:\n\nLa descripción del proyecto proporciona una visión general del propósito, los objetivos y las características principales del proyecto.\nEs importante que esta descripción sea clara y concisa, pero lo suficientemente detallada como para transmitir la utilidad y el valor del proyecto a los posibles usuarios.\n\n\nTabla de Contenidos:\n\nLa tabla de contenidos enumera los diferentes apartados del README con enlaces directos a cada sección. Esto facilita la navegación y la búsqueda de información específica para los usuarios.\n\n\nInstalación:\n\nLa sección de instalación proporciona instrucciones detalladas sobre cómo instalar el proyecto en diferentes entornos.\nLos requisitos previos enumeran cualquier software adicional, configuraciones del sistema o permisos de usuario necesarios para la instalación.\nLos pasos de instalación proporcionan comandos específicos que los usuarios pueden seguir para instalar el proyecto correctamente.\n\n\nUso:\n\nLa sección de uso ofrece instrucciones detalladas sobre cómo utilizar el proyecto una vez instalado.\nLa configuración informa a los usuarios sobre cualquier configuración adicional que necesiten realizar antes de utilizar el proyecto, como la configuración de variables de entorno o archivos de configuración.\nLos ejemplos de uso proporcionan casos de uso comunes y comandos que los usuarios pueden ejecutar para interactuar con el software.\n\n\nCaracterísticas:\n\nEsta sección enumera y describe las características principales del proyecto, resaltando las funcionalidades únicas o importantes que lo diferencian de otros proyectos similares.\nEs importante destacar las características que hacen que el proyecto sea valioso para los usuarios y cómo estas características pueden beneficiarlos.\n\n\nContribuciones:\n\nLa sección de contribuciones proporciona instrucciones detalladas sobre cómo contribuir al proyecto.\nLa guía de contribución ofrece una guía paso a paso sobre cómo enviar solicitudes de extracción, informar problemas y cualquier otro proceso de contribución relevante.\nEs importante facilitar a los posibles colaboradores el proceso de contribución al proyecto para fomentar la participación y el desarrollo continuo.\n\n\nLicencia:\n\nLa sección de licencia informa a los usuarios sobre los términos de la licencia bajo la cual se distribuye el proyecto.\nProporciona un enlace a los términos de la licencia para que los usuarios puedan revisarlos y asegurarse de cumplir con ellos antes de utilizar, modificar o distribuir el software.\n\n\n\n\n\n\n\n🔑 Nota: Para una referencia sobre la estructura y contenido de un README de Portafolio, utilizaremos el siguiente proyecto como ejemplo: Curso de Desarrollo Web.\n\n\nTítulo:\n\nEl título “Curso de Desarrollo Web” es claro y describe el contenido principal del repositorio.\n\nDescripción:\n\nLa descripción ofrece una visión general del curso, mencionando que abarca desde conceptos básicos hasta proyectos avanzados en el campo del desarrollo web.\nIndica que los estudiantes aprenderán a crear aplicaciones web completas utilizando diferentes tecnologías y herramientas.\n\n\nProyectos:\n\nLos proyectos están organizados en categorías según el nivel de habilidad y las tecnologías utilizadas.\nCada categoría de proyecto incluye una tabla que enumera los nombres y descripciones de los proyectos correspondientes.\nLas descripciones proporcionan información sobre el propósito de cada proyecto y las tecnologías específicas utilizadas en su desarrollo.\n\n\nNotas:\n\nOfrece algunas notas adicionales para proporcionar contexto adicional sobre los proyectos.\nIndica que los proyectos están listados en el orden en que se completaron, lo que puede ser útil para seguir una progresión lógica.\nDestaca que cada proyecto incluye una descripción detallada y las tecnologías utilizadas, lo que brinda a los estudiantes información importante sobre lo que aprenderán en cada proyecto.\nSugiere que los usuarios pueden obtener más detalles sobre cada proyecto consultando los directorios correspondientes en el repositorio, lo que facilita la navegación y la búsqueda de información adicional."
  },
  {
    "objectID": "posts/2024/github_repos.html#awesome-readme",
    "href": "posts/2024/github_repos.html#awesome-readme",
    "title": "Github Repository",
    "section": "",
    "text": "Una valiosa fuente de inspiración y orientación en este sentido es el repositorio awesome-readme creado por Matías Singers en GitHub. Este repositorio recopila una amplia variedad de ejemplos inspiradores y recursos útiles para la creación de READMEs impresionantes.\nDesde estructuras organizadas hasta consejos prácticos y ejemplos de READMEs destacados, “awesome-readme” ofrece una amplia gama de recursos para ayudarte a mejorar la presentación y documentación de tus proyectos en GitHub.\nAl explorar este repositorio, los desarrolladores pueden encontrar ideas innovadoras, plantillas útiles y ejemplos reales que les ayudarán a crear READMEs que destaquen entre la multitud y comuniquen eficazmente el valor de sus proyectos."
  },
  {
    "objectID": "posts/2024/github_repos.html#conclusión",
    "href": "posts/2024/github_repos.html#conclusión",
    "title": "Github Repository",
    "section": "",
    "text": "La presentación de tus proyectos en GitHub es clave para avanzar en tu carrera profesional. Este tutorial te ha mostrado cómo personalizar tus repositorios de manera efectiva, ya sea para proyectos de software o portafolios profesionales.\nAl seguir estas prácticas recomendadas, puedes:\n\nAtraer la atención de potenciales colaboradores y usuarios.\nComunicar claramente el valor de tus proyectos.\nFomentar la colaboración y el crecimiento de la comunidad.\nDemostrar tus habilidades y experiencia de manera efectiva.\nDestacar entre otros repositorios y aumentar la visibilidad de tu trabajo.\n\nAl dominar la presentación de tus proyectos en GitHub, puedes mejorar significativamente tu presencia en línea, impulsar tu carrera profesional y abrir nuevas oportunidades de colaboración y crecimiento."
  },
  {
    "objectID": "posts/2024/github_profile.html",
    "href": "posts/2024/github_profile.html",
    "title": "Github Profile",
    "section": "",
    "text": "Un perfil de GitHub es una tarjeta de presentación online para desarrolladores. Te permite mostrar tus habilidades, proyectos y experiencia a la comunidad de código abierto.\nUn perfil bien elaborado puede ayudarte a encontrar trabajo, colaborar con otros desarrolladores y construir tu marca personal.\nEn este artículo, te guiaremos paso a paso para crear un perfil de GitHub completo y profesional.\n\n🔑 Nota: Para seguir este tutorial, es necesario disponer de una Cuenta en GitHub. Además, se recomienda actualizar tu foto de perfil y tu nombre de usuario.\n\n\n\nUn GitHub profile es una página personalizada que muestra tu actividad y contribuciones en la plataforma GitHub.\nFunciona como tu identidad digital en la comunidad de desarrollo de software, donde puedes compartir información sobre ti mismo, tus proyectos, y tu experiencia en el desarrollo de software colaborativo. Tu perfil de GitHub muestra una variedad de elementos, incluyendo tu biografía, repositorios destacados, actividad de colaboración, organizaciones a las que perteneces, logros y reconocimientos, entre otros.\nEs una herramienta importante para conectarte con otros desarrolladores, reclutadores y colaboradores potenciales, y para mostrar tu habilidad y compromiso en el mundo del desarrollo de software.\n\n\n\n\n\n🔑 Nota: Utilizaremos mi propio perfil de GitHub como referencia.\n\n\n\n\nDirígete a la página principal de GitHub y haz clic en el botón “New” (Nuevo) en la esquina superior derecha.\nNombre del repositorio: Debe coincidir exactamente con tu nombre de usuario. Por ejemplo, si tu nombre de usuario es fralfaro, el repositorio se llamará fralfaro.\nAsegúrate de que el repositorio sea “Público”.\nSelecciona la opción para “Add a README file” (Agregar un archivo README). \nHaz clic en “Create repository” (Crear repositorio).\nLa estructura del repositorio será la siguiente: \n\n\n\n\n\nVisita tu perfil de GitHub y verás el siguiente diseño: \nLuego, haz clic en el icono del lápiz en la esquina superior derecha para editar el archivo. \nAgrega la información que deseas mostrar en tu perfil, como una breve biografía, enlaces a proyectos destacados, etc.\nDespués de editar el README, desplázate hacia abajo y encontrarás el botón “Commit changes” (Confirmar cambios).\nHaz clic en este botón para guardar tus modificaciones.\n\n\n\n\n\nVisita tu perfil de GitHub y verás las nuevas modificaciones que has realizado en tu README.\n\n\n¡Listo! Ahora tu perfil de GitHub está configurado con la información que deseas mostrar. Los visitantes podrán conocer más sobre ti y tu trabajo gracias a tu README personalizado.\n\n\n\n\nPara crear un GitHub Profile que refleje tu profesionalismo y destaque tus habilidades como desarrollador, te dejamos algunos tips.\n\n\nUn GitHub Profile README Generator es una herramienta o aplicación en línea que te permite crear de manera rápida y sencilla un README personalizado para tu perfil de GitHub.\nEste tipo de generadores suelen ofrecer una interfaz amigable donde puedes ingresar información como tu biografía, enlaces a proyectos destacados, estadísticas de tu actividad en GitHub, y otros detalles relevantes. Una vez que hayas completado la información requerida, el generador te proporcionará el código Markdown necesario para agregar el README a tu perfil de GitHub.\nGitHub Profile README Generator - rahuldkjain\n\nGitHub Profile README Generator - maurodesouza\n\n\n\n\n\nAwesome GitHub Profile READMEs es una colección de ejemplos inspiradores y creativos de READMEs para perfiles de GitHub. Este recurso recopila una variedad de perfiles de GitHub que han sido personalizados de manera única y creativa utilizando Markdown y otros recursos disponibles en GitHub.\nSirven como fuente de inspiración para los usuarios que desean mejorar la apariencia y el contenido de su propio perfil de GitHub. Además, esta colección puede ayudar a los usuarios a aprender nuevas técnicas y trucos para destacar sus habilidades, proyectos y personalidad a través de su perfil de GitHub.\n\n\n\n\nLos GitHub Profile ofrecen una plataforma única para que los desarrolladores muestren su trabajo, experiencia y personalidad en la comunidad de desarrollo de software.\n\nIdentidad Digital: Los perfiles de GitHub sirven como la identidad digital de los desarrolladores en la comunidad de GitHub, permitiéndoles presentarse a sí mismos y su trabajo de manera efectiva.\nTransparencia y Colaboración: La sección de actividad de colaboración proporciona una visión transparente de la contribución y el compromiso del usuario en proyectos de código abierto y colaboraciones con otros desarrolladores.\nPersonalización y Creatividad: Los usuarios tienen la libertad de personalizar sus perfiles con biografías, repositorios destacados, logros y otros elementos para reflejar su personalidad y habilidades únicas.\nFuente de Inspiración: Los GitHub Profile pueden servir como fuente de inspiración para otros desarrolladores, proporcionando ejemplos creativos y únicos de cómo presentar su trabajo de manera efectiva en la plataforma.\n\nAl seguir los consejos y las mejores prácticas compartidas en este artículo, puedes crear un perfil de GitHub que refleje tu profesionalismo, creatividad y pasión por la programación. ¡Aprovecha al máximo esta poderosa herramienta y haz que tu GitHub Profile sea un reflejo auténtico de quién eres como desarrollador!."
  },
  {
    "objectID": "posts/2024/github_profile.html#sobre-github-profile",
    "href": "posts/2024/github_profile.html#sobre-github-profile",
    "title": "Github Profile",
    "section": "",
    "text": "Un GitHub profile es una página personalizada que muestra tu actividad y contribuciones en la plataforma GitHub.\nFunciona como tu identidad digital en la comunidad de desarrollo de software, donde puedes compartir información sobre ti mismo, tus proyectos, y tu experiencia en el desarrollo de software colaborativo. Tu perfil de GitHub muestra una variedad de elementos, incluyendo tu biografía, repositorios destacados, actividad de colaboración, organizaciones a las que perteneces, logros y reconocimientos, entre otros.\nEs una herramienta importante para conectarte con otros desarrolladores, reclutadores y colaboradores potenciales, y para mostrar tu habilidad y compromiso en el mundo del desarrollo de software."
  },
  {
    "objectID": "posts/2024/github_profile.html#crear-github-profile",
    "href": "posts/2024/github_profile.html#crear-github-profile",
    "title": "Github Profile",
    "section": "",
    "text": "🔑 Nota: Utilizaremos mi propio perfil de GitHub como referencia.\n\n\n\n\nDirígete a la página principal de GitHub y haz clic en el botón “New” (Nuevo) en la esquina superior derecha.\nNombre del repositorio: Debe coincidir exactamente con tu nombre de usuario. Por ejemplo, si tu nombre de usuario es fralfaro, el repositorio se llamará fralfaro.\nAsegúrate de que el repositorio sea “Público”.\nSelecciona la opción para “Add a README file” (Agregar un archivo README). \nHaz clic en “Create repository” (Crear repositorio).\nLa estructura del repositorio será la siguiente: \n\n\n\n\n\nVisita tu perfil de GitHub y verás el siguiente diseño: \nLuego, haz clic en el icono del lápiz en la esquina superior derecha para editar el archivo. \nAgrega la información que deseas mostrar en tu perfil, como una breve biografía, enlaces a proyectos destacados, etc.\nDespués de editar el README, desplázate hacia abajo y encontrarás el botón “Commit changes” (Confirmar cambios).\nHaz clic en este botón para guardar tus modificaciones.\n\n\n\n\n\nVisita tu perfil de GitHub y verás las nuevas modificaciones que has realizado en tu README.\n\n\n¡Listo! Ahora tu perfil de GitHub está configurado con la información que deseas mostrar. Los visitantes podrán conocer más sobre ti y tu trabajo gracias a tu README personalizado."
  },
  {
    "objectID": "posts/2024/github_profile.html#github-profile-pro",
    "href": "posts/2024/github_profile.html#github-profile-pro",
    "title": "Github Profile",
    "section": "",
    "text": "Para crear un GitHub Profile que refleje tu profesionalismo y destaque tus habilidades como desarrollador, te dejamos algunos tips.\n\n\nUn GitHub Profile README Generator es una herramienta o aplicación en línea que te permite crear de manera rápida y sencilla un README personalizado para tu perfil de GitHub.\nEste tipo de generadores suelen ofrecer una interfaz amigable donde puedes ingresar información como tu biografía, enlaces a proyectos destacados, estadísticas de tu actividad en GitHub, y otros detalles relevantes. Una vez que hayas completado la información requerida, el generador te proporcionará el código Markdown necesario para agregar el README a tu perfil de GitHub.\nGitHub Profile README Generator - rahuldkjain\n\nGitHub Profile README Generator - maurodesouza\n\n\n\n\n\nAwesome GitHub Profile READMEs es una colección de ejemplos inspiradores y creativos de READMEs para perfiles de GitHub. Este recurso recopila una variedad de perfiles de GitHub que han sido personalizados de manera única y creativa utilizando Markdown y otros recursos disponibles en GitHub.\nSirven como fuente de inspiración para los usuarios que desean mejorar la apariencia y el contenido de su propio perfil de GitHub. Además, esta colección puede ayudar a los usuarios a aprender nuevas técnicas y trucos para destacar sus habilidades, proyectos y personalidad a través de su perfil de GitHub."
  },
  {
    "objectID": "posts/2024/github_profile.html#conclusión",
    "href": "posts/2024/github_profile.html#conclusión",
    "title": "Github Profile",
    "section": "",
    "text": "Los GitHub Profile ofrecen una plataforma única para que los desarrolladores muestren su trabajo, experiencia y personalidad en la comunidad de desarrollo de software.\n\nIdentidad Digital: Los perfiles de GitHub sirven como la identidad digital de los desarrolladores en la comunidad de GitHub, permitiéndoles presentarse a sí mismos y su trabajo de manera efectiva.\nTransparencia y Colaboración: La sección de actividad de colaboración proporciona una visión transparente de la contribución y el compromiso del usuario en proyectos de código abierto y colaboraciones con otros desarrolladores.\nPersonalización y Creatividad: Los usuarios tienen la libertad de personalizar sus perfiles con biografías, repositorios destacados, logros y otros elementos para reflejar su personalidad y habilidades únicas.\nFuente de Inspiración: Los GitHub Profile pueden servir como fuente de inspiración para otros desarrolladores, proporcionando ejemplos creativos y únicos de cómo presentar su trabajo de manera efectiva en la plataforma.\n\nAl seguir los consejos y las mejores prácticas compartidas en este artículo, puedes crear un perfil de GitHub que refleje tu profesionalismo, creatividad y pasión por la programación. ¡Aprovecha al máximo esta poderosa herramienta y haz que tu GitHub Profile sea un reflejo auténtico de quién eres como desarrollador!."
  },
  {
    "objectID": "posts/2023/art_docs.html",
    "href": "posts/2023/art_docs.html",
    "title": "Documentación",
    "section": "",
    "text": "Esperamos que, si estás leyendo este tutorial, ya comprendas la importancia de documentar tu código. Pero, por si acaso, permíteme citar algo que Guido mencionó en la reciente PyCon 2016:\n\n\n\n\n\n\nCita\n\n\n\n“El código se lee más a menudo de lo que se escribe.” — Guido van Rossum\n\n\n\n\nCuando escribes código, lo haces para dos audiencias principales: tus usuarios y tus desarrolladores (incluyéndote a ti mismo). Ambas audiencias son igualmente cruciales. Si eres como yo, es posible que hayas abierto antiguas bases de código y te hayas preguntado: “¿En qué estaba pensando?”. Si tienes dificultades para entender tu propio código, imagina lo que tus usuarios u otros desarrolladores sienten cuando intentan utilizarlo o contribuir a tu código.\nPor otro lado, es probable que hayas pasado por situaciones en las que deseabas realizar algo en Python y encontraste lo que parecía ser una excelente biblioteca que podría hacer el trabajo. Sin embargo, al comenzar a usar la biblioteca, buscaste ejemplos, descripciones o incluso documentación oficial sobre cómo realizar una tarea específica y no pudiste encontrar una solución de inmediato.\nDespués de buscar durante un tiempo, te das cuenta de que la documentación es insuficiente o, peor aún, está completamente ausente. Esta es una experiencia frustrante que te impide utilizar la biblioteca, sin importar cuán bueno o eficiente sea el código. Daniele Procida resumió esta situación de manera acertada:\n\n\n\n\n\n\nCita\n\n\n\n“No importa cuán bueno sea tu software, porque si la documentación no es lo suficientemente buena, la gente no lo usará.” — Daniele Procida\n\n\nEn esta guía, aprenderás desde cero cómo documentar adecuadamente tu código en Python, desde los scripts más pequeños hasta los proyectos más grandes de Python, para evitar que tus usuarios se sientan frustrados al usar o contribuir a tu proyecto.\n\n\n\n\nAntes de sumergirnos en el arte de documentar tu código en Python, es crucial establecer una distinción fundamental: los comentarios y la documentación desempeñan roles distintos y están dirigidos a audiencias diferentes.\nComentarios:\nEn términos generales, los comentarios están diseñados para proporcionar información sobre tu código a los desarrolladores.\nLa audiencia principal a la que se dirigen son aquellos que mantienen y trabajan en el código Python. Cuando se combinan con un código bien escrito, los comentarios actúan como guías que ayudan a los lectores a comprender mejor el código, su propósito y su estructura. Esto se alinea perfectamente con la sabia observación de Jeff Atwood,\n\n\n\n\n\n\nCita\n\n\n\n“El código te dice cómo; los comentarios te dicen por qué.” — Jeff Atwood\n\n\nDocumentación del Código:\nPor otro lado, la documentación del código se enfoca en describir el uso y la funcionalidad del código a los usuarios. Aunque puede ser útil durante el proceso de desarrollo, su audiencia principal son los usuarios finales del software. La siguiente sección de este artículo se adentrará en cuándo y cómo debes abordar la tarea de comentar tu código en Python.\n\n\n\n\nEn Python, los comentarios son esenciales para proporcionar información adicional sobre tu código.\nSe crean utilizando el símbolo de número (#) y deben ser declaraciones breves, no más largas que unas pocas frases. Aquí tienes un ejemplo simple:\ndef hello_world():    \n    # Un comentario simple antes de una simple declaración de impresión\n    print(\"Hola Mundo\")\nDe acuerdo con las pautas de estilo de código de Python (PEP 8), los comentarios deben tener una longitud máxima de 72 caracteres. Esto es válido incluso si tu proyecto cambia la longitud máxima de línea recomendada para que sea mayor que los 80 caracteres. Si un comentario va a superar el límite de caracteres recomendado, es apropiado usar múltiples líneas para el comentario:\ndef hello_long_world():     \n    # Una declaración muy larga que sigue y sigue y sigue y sigue y sigue \n    # sin terminar hasta que alcance el límite de 80 caracteres\n    print(\"¡Hola Mundoooooooooooooooooooooooooooooooooooooooooooooooooooooo!\")\nComentar tu código sirve para varios propósitos, incluyendo:\n\nPlanificación y Revisión: Durante el desarrollo de nuevas partes de tu código, los comentarios pueden servir como una forma de planificar o esquematizar esa sección. Es importante recordar eliminar estos comentarios una vez que se haya implementado y revisado/testeado el código real:\n# Primer paso\n# Segundo paso\n# Tercer paso\nDescripción del Código: Los comentarios se utilizan para explicar la intención de secciones específicas del código:\n# Intentar una conexión basada en configuraciones anteriores. Si no tiene éxito,\n# solicitar al usuario nuevas configuraciones.\nDescripción Algorítmica: Al usar algoritmos, especialmente los complicados, es útil explicar cómo funcionan o cómo se implementan en tu código. También es apropiado describir por qué seleccionaste un algoritmo específico en lugar de otro:\n# Usar el ordenamiento rápido para obtener ganancias de rendimiento.\nEtiquetado: Puedes utilizar etiquetas para señalar secciones específicas de código donde se encuentran problemas conocidos o áreas de mejora. Algunos ejemplos son BUG, FIXME y TODO:\n# TODO: Agregar condición para cuando 'val' sea None\n\nLos comentarios en tu código deben ser breves y centrados. Evita comentarios largos cuando sea posible. Además, sigue las siguientes cuatro reglas esenciales sugeridas por Jeff Atwood:\n\nMantén los Comentarios Cerca del Código: Los comentarios deben estar lo más cerca posible del código que describen. Los comentarios distantes del código descriptivo son frustrantes y pueden pasarse por alto fácilmente al realizar actualizaciones.\nEvita el Formato Complejo: No uses formatos complejos como tablas o figuras ASCII. Estos formatos pueden distraer y ser difíciles de mantener con el tiempo.\nEvita Información Redundante: Supón que el lector del código tiene un entendimiento básico de los principios de programación y la sintaxis del lenguaje. No incluyas información redundante.\nDiseña Tu Código para que se Comente por Sí Mismo: La forma más fácil de entender el código es leyéndolo. Cuando diseñes tu código utilizando conceptos claros y fáciles de entender, ayudarás al lector a comprender tu intención de manera rápida y sencilla.\n\nRecuerda que los comentarios están diseñados para los lectores, incluyéndote a ti mismo, para ayudarlos a comprender el propósito y diseño del software.\n\n\n\nEl Type Hinting es una característica que te permite indicar explícitamente los tipos de datos que esperas en las funciones y métodos. Aunque Python es un lenguaje de programación de tipado dinámico, el Type Hinting no cambia esa naturaleza, pero proporciona información adicional a los desarrolladores y a las herramientas de análisis estático sobre cómo debería funcionar el código.\nEl Type Hinting no afecta el comportamiento en tiempo de ejecución, por lo que no impide que el código funcione si los tipos no coinciden.\nEn cambio, es una herramienta para ayudar a los desarrolladores a comprender y depurar el código de manera más eficiente y prevenir posibles errores.\nConsidera la siguiente función hello_name:\ndef hello_name(name: str) -&gt; str:\n    return f\"Hello {name}\"\nEn este ejemplo, hemos utilizado Type Hinting para especificar que el parámetro name debe ser una cadena (str) y que la función hello_name debe devolver una cadena (str). Esta información es útil para otros desarrolladores que utilicen esta función porque ahora saben qué tipo de dato esperar como entrada y qué tipo de dato obtendrán como resultado.\n\n\n\n\n\nUna parte fundamental de la documentación en Python son las docstrings, que son cadenas de texto utilizadas para describir funciones, clases, módulos y más.\n\n\nLas docstrings son cadenas de documentación que se encuentran dentro del código fuente Python. Estas cadenas proporcionan información sobre el propósito y el funcionamiento de funciones, clases y otros elementos del código.\nLas docstrings son especialmente valiosas para ayudar a los usuarios y desarrolladores a comprender cómo utilizar y trabajar con tu código.\n¿Cómo Funcionan las Docstrings?\nCuando definimos una función, clase o módulo en Python, podemos incluir una docstring justo debajo de la definición. Por ejemplo:\ndef saludar(nombre):\n    \"\"\"Esta función imprime un saludo personalizado.\"\"\"\n    print(f\"Hola, {nombre}!\")\nLas docstrings se pueden acceder a través del atributo __doc__ del objeto. Por ejemplo:\nprint(saludar.__doc__)\nLa salida sería: “Esta función imprime un saludo personalizado.” Las docstrings también se utilizan en entornos de desarrollo interactivo y se muestran al utilizar la función help().\nManipulación de Docstrings\nEs importante destacar que puedes manipular directamente las docstrings. Sin embargo, existen restricciones para los objetos incorporados en Python. Por ejemplo, no puedes cambiar la docstring de un objeto str incorporado:\nstr.__doc__ = \"¡Esto no funcionará para objetos incorporados!\"\nPero para funciones y objetos personalizados, puedes establecer o modificar sus docstrings de la siguiente manera:\ndef decir_hola(nombre):\n    \"\"\"Una función simple que saluda a la manera de Richie.\"\"\"\n    print(f\"Hola {nombre}, ¿soy yo a quien estás buscando?\")\n\ndecir_hola.__doc__ = \"Una función que saluda estilo Richie Rich.\"\nUbicación Estratégica de las Docstrings\nUna forma más sencilla de definir docstrings es colocar una cadena literal justo debajo de la definición de la función o clase. Python automáticamente interpreta esta cadena como la docstring. Por ejemplo:\ndef decir_hola(nombre):\n    \"\"\"Una función simple que saluda a la manera de Richie.\"\"\"\n    print(f\"Hola {nombre}, ¿soy yo a quien estás buscando?\")\n\n\n\nLas docstrings son elementos esenciales para documentar tu código Python de manera clara y coherente. Siguen convenciones y pautas que se describen en PEP 257.\nEl propósito de las docstrings es proporcionar a los usuarios de tu código un resumen conciso y útil del objeto, como una función, clase, módulo o script. Deben ser lo suficientemente concisas como para ser fáciles de mantener, pero lo suficientemente detalladas como para que los nuevos usuarios comprendan su propósito y cómo utilizar el objeto documentado.\n\n\nTodas las docstrings deben utilizar el formato de triple comilla doble (\"\"\") y deben colocarse justo debajo de la definición del objeto, ya sea en una sola línea o en varias líneas:\nUna línea:\n\"\"\"Esta es una línea de resumen rápida utilizada como descripción del objeto.\"\"\"\nVarias líneas:\n\"\"\"\nEsta es la línea de resumen\nEsta es la elaboración adicional de la docstring. Dentro de esta sección, puedes proporcionar más detalles según sea apropiado para la situación. Observa que el resumen y la elaboración están separados por una nueva línea en blanco.\n\"\"\"\nEs importante destacar que todas las docstrings de varias líneas deben seguir un patrón específico:\n\nUna línea de resumen de una sola línea.\nUna línea en blanco después del resumen.\nCualquier elaboración adicional de la docstring.\nOtra línea en blanco.\n\nAdemás, todas las docstrings deben tener una longitud máxima de caracteres que sigue las mismas pautas que los comentarios, que es de 72 caracteres.\n\n\n\nLas docstrings de clase se crean para la clase en sí, así como para cualquier método de clase. Las docstrings se colocan inmediatamente después de la clase o el método de clase, con un nivel de sangría:\nclass ClaseSimple:\n    \"\"\"Aquí van las docstrings de clase.\"\"\"\n    def decir_hola(self, nombre: str):\n        \"\"\"Aquí van las docstrings de método de clase.\"\"\"\n        print(f'Hola {nombre}')\nLas docstrings de clase deben contener la siguiente información:\n\nUn breve resumen de su propósito y comportamiento.\nCualquier método público, junto con una breve descripción.\nCualquier propiedad de clase (atributos).\nCualquier cosa relacionada con la interfaz para los subclases, si la clase está destinada a ser subclaseada.\n\nLos parámetros del constructor de clase deben documentarse dentro de la docstring del método __init__ de la clase. Los métodos individuales deben documentarse utilizando sus propias docstrings individuales. Las docstrings de método de clase deben contener lo siguiente:\n\nUna breve descripción de lo que hace el método y para qué se utiliza.\nCualquier argumento (tanto requerido como opcional) que se pase, incluidos los argumentos de palabras clave.\nEtiqueta para cualquier argumento que se considere opcional o tenga un valor predeterminado.\nCualquier efecto secundario que ocurra al ejecutar el método.\nCualquier excepción que se genere.\nCualquier restricción sobre cuándo se puede llamar al método.\n\nEchemos un vistazo a un ejemplo simple de una clase de datos que representa un Animal. Esta clase contendrá algunas propiedades de clase, propiedades de instancia, un __init__ y un único método de instancia:\nclass Animal:\n    \"\"\"Una clase utilizada para representar un Animal\n    \n    Attributes:\n        dice_str (str): una cadena formateada para imprimir lo que dice el animal\n        nombre (str): el nombre del animal\n        sonido (str): el sonido que hace el animal\n        num_patas (int): el número de patas del animal (predeterminado 4)\n    \"\"\"\n    \n    dice_str = \"Un {nombre} dice {sonido}\"\n    \n    def __init__(self, nombre, sonido, num_patas=4):\n        \"\"\"Inicializa una nueva instancia de Animal\n        \n        Parameters:\n            nombre (str): El nombre del animal\n            sonido (str): El sonido que hace el animal\n            num_patas (int, opcional): El número de patas del animal (predeterminado es 4)\n        \"\"\"\n        self.nombre = nombre\n        self.sonido = sonido\n        self.num_patas = num_patas\n        \n    def dice(self, sonido=None):\n        \"\"\"Imprime el nombre del animal y el sonido que hace.\n        \n        Si no se pasa el argumento `sonido`, se utiliza el sonido predeterminado del Animal.\n        \n        Parameters:\n            sonido (str, opcional): El sonido que hace el animal (predeterminado es None)\n        \n        Raises:\n            NotImplementedError: Si no se establece ningún sonido para el animal o se pasa como parámetro.\n        \"\"\"\n        if self.sonido is None and sonido is None:\n            raise NotImplementedError(\"¡No se admiten animales silenciosos!\")\n        sonido_salida = self.sonido if sonido is None else sonido\n        print(self.dice_str.format(nombre=self.nombre, sonido=sonido_salida))\n\n\n\n\n\nExisten formatos específicos de docstrings que pueden ser utilizados para ayudar a los analizadores de docstrings y a los usuarios a tener un formato familiar y reconocido.\nAlgunos de los formatos más comunes son los siguientes:\n\n\n\nTipo de Formato\nDescripción\nCompatible con Sphinx\nEspecificación Formal\n\n\n\n\nGoogle docstrings\nForma de documentación recomendada por Google\nSí\nNo\n\n\nreStructuredText\nEstándar oficial de documentación de Python; no es amigable para principiantes pero rico en características\nSí\nSí\n\n\nNumPy/SciPy docstrings\nCombinación de reStructuredText y Docstrings de Google utilizada por NumPy\nSí\nSí\n\n\nEpytext\nUna adaptación de Epydoc para Python; ideal para desarrolladores de Java\nNo oficialmente\nSí\n\n\n\nLa elección del formato de docstring depende de ti, pero debes mantener el mismo formato en todo tu documento o proyecto. A continuación, se presentan ejemplos de cada tipo para darte una idea de cómo se ve cada formato de documentación.\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cálculo\n\nArgs:\n    file_loc (str): La ubicación del archivo de la hoja de cálculo.\n    print_cols (bool): Una bandera utilizada para imprimir las columnas en la consola\n        (el valor predeterminado es Falso)\n\nReturns:\n    list: una lista de cadenas que representan las columnas de encabezado\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cálculo\n\n:param file_loc: La ubicación del archivo de la hoja de cálculo\n:type file_loc: str\n:param print_cols: Una bandera utilizada para imprimir las columnas en la consola\n    (el valor predeterminado es Falso)\n:type print_cols: bool\n\n:returns: una lista de cadenas que representan las columnas de encabezado\n:rtype: list\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cálculo\n\nParameters\n----------\nfile_loc : str\n    La ubicación del archivo de la hoja de cálculo\nprint_cols : bool, opcional\n    Una bandera utilizada para imprimir las columnas en la consola (el valor predeterminado es Falso)\n\nReturns\n-------\nlist\n    una lista de cadenas que representan las columnas de encabezado\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cálculo\n\n@type file_loc: str\n@param file_loc: La ubicación del archivo de la hoja de cálculo\n@type print_cols: bool\n@param print_cols: Una bandera utilizada para imprimir las columnas en la consola\n    (el valor predeterminado es Falso)\n@rtype: list\n@returns: una lista de cadenas que representan las columnas de encabezado\n\"\"\"\nEstos ejemplos te proporcionan una idea de cómo se estructuran y formatean las docstrings en diferentes estilos de documentación.\nPuedes elegir el que mejor se adapte a tus preferencias y necesidades de documentación, pero asegúrate de mantener la coherencia en todo tu proyecto.\n\n\n\n\n\nLos proyectos de Python vienen en todo tipo de formas, tamaños y propósitos. La forma en que documentas tu proyecto debe adaptarse a tu situación específica. Ten en cuenta quiénes serán los usuarios de tu proyecto y adáptate a sus necesidades. Dependiendo del tipo de proyecto, se recomiendan ciertos aspectos de la documentación. La estructura general del proyecto y su documentación debe ser la siguiente:\nproject_root/\n│\n├── project/  # Project source code\n├── docs/\n├── README\n├── HOW_TO_CONTRIBUTE\n├── CODE_OF_CONDUCT\n├── examples.py\nEsta estructura de directorios es un diseño común para organizar un proyecto de software en Python. A continuación, se explica en detalle cada elemento de esta estructura:\n\nproject_root (Directorio Raíz del Proyecto): Este es el directorio principal que contiene todos los archivos y carpetas relacionados con tu proyecto. Es el punto de partida para tu proyecto.\nproject/ (Carpeta “project”): Esta carpeta suele contener el código fuente principal de tu proyecto. Aquí se almacenan todos los archivos de Python que forman parte de tu proyecto. Puedes organizar estos archivos en subdirectorios según la estructura de tu proyecto. Por ejemplo, puedes tener subdirectorios para módulos específicos o componentes del proyecto.\ndocs/ (Carpeta “docs”): La carpeta “docs” se utiliza para almacenar la documentación de tu proyecto. Aquí puedes incluir documentos explicativos, manuales de usuario, instrucciones de instalación y cualquier otra documentación relevante. Mantener una documentación clara y organizada es esencial para que los usuarios comprendan y utilicen tu proyecto de manera efectiva.\nREADME: El archivo “README” es un documento importante que proporciona una breve descripción de tu proyecto y su propósito. Suele incluir información sobre cómo instalar y utilizar el proyecto, así como otros detalles importantes. Los usuarios suelen consultar este archivo primero cuando exploran un proyecto.\nHOW_TO_CONTRIBUTE: Este archivo contiene instrucciones para las personas que deseen contribuir al desarrollo de tu proyecto. Incluye detalles sobre cómo pueden colaborar, enviar correcciones, agregar nuevas funciones y seguir las pautas de contribución.\nCODE_OF_CONDUCT: El archivo “CODE_OF_CONDUCT” establece las reglas y pautas de comportamiento que deben seguir los colaboradores y usuarios del proyecto. Define cómo deben interactuar entre sí de manera respetuosa y profesional. También puede indicar las consecuencias en caso de violación del código de conducta.\nexamples.py: Este archivo es un script de Python que contiene ejemplos simples de cómo utilizar las funcionalidades de tu proyecto. Estos ejemplos pueden ayudar a los usuarios a comprender cómo utilizar tu código en situaciones reales y proporcionar ejemplos de uso práctico.\n\n\n\n\nLa documentación es una parte fundamental de cualquier proyecto de desarrollo de software. Proporciona información crucial sobre cómo utilizar, mantener y contribuir al código. En el ecosistema de Python, existen varias bibliotecas y herramientas que facilitan la tarea de documentar el código de manera efectiva. En este artículo, exploraremos algunas de las principales bibliotecas de Python utilizadas para documentar código.\n\n\n\nSphinx es una de las herramientas de documentación más populares en el mundo de Python. Fue originalmente desarrollada para documentar la propia documentación de Python y se ha convertido en una elección común para proyectos de código abierto y proyectos internos. Algunas de sus características clave incluyen:\n\nGeneración de documentación en varios formatos, incluyendo HTML, PDF, ePub y más.\nUtiliza reStructuredText como su formato de marcado predeterminado, que es altamente estructurado y permite documentar de manera eficiente los aspectos técnicos.\nAmplia gama de extensiones y complementos que permiten personalizar y mejorar la documentación.\nAdmite la generación automática de documentación a partir de docstrings en el código Python.\nEs especialmente adecuado para documentar bibliotecas, API y proyectos técnicos.\n\nSphinx es altamente configurable y puede generar documentación de alta calidad y profesional. Sin embargo, puede requerir un tiempo de configuración inicial y tiene una curva de aprendizaje empinada para los principiantes.\n\n\n\n\nMkDocs es una herramienta de generación de documentación que se centra en la simplicidad y la facilidad de uso. Está diseñada para crear documentación de proyectos de una manera simple y rápida, principalmente enfocada en la generación de sitios web de documentación. Algunas de sus características clave incluyen:\n\nUtiliza Markdown como formato de marcado predeterminado, que es fácil de aprender y escribir.\nOfrece una interfaz de línea de comandos simple para iniciar y generar sitios de documentación.\nProporciona temas y extensiones para personalizar el aspecto y la funcionalidad de la documentación generada.\nIdeal para proyectos de código abierto y documentación de proyectos pequeños a medianos.\n\nMkDocs es especialmente adecuado para proyectos con necesidades de documentación simples. Es fácil de aprender y usar, lo que lo convierte en una excelente opción para principiantes. Sin embargo, puede ser limitado en funcionalidad en comparación con Sphinx para proyectos técnicos y complejos.\n\n\n\nMkDocs-Material es un tema personalizado para MkDocs, una popular herramienta de generación de sitios web estáticos diseñada para crear documentación de proyectos de manera sencilla y efectiva. Este tema, conocido como “Material for MkDocs”, se inspira en el elegante diseño de Material Design de Google y está diseñado para ofrecer una experiencia de documentación moderna y atractiva.\nUna de las principales características de MkDocs-Material es su enfoque en la legibilidad y la facilidad de navegación. Esto se logra mediante un diseño limpio y organizado que hace que la documentación sea más accesible para los usuarios. Además, el tema proporciona herramientas útiles para mejorar la experiencia de los lectores, como una función de búsqueda integrada que permite a los usuarios encontrar rápidamente la información que necesitan.\nOtra ventaja de MkDocs-Material es su navegación intuitiva, que facilita a los usuarios la exploración de la documentación y la navegación entre secciones y páginas. Esto es fundamental para garantizar que los usuarios puedan acceder fácilmente a la información que están buscando sin esfuerzo.\n\n\n\n\n\nLa documentación de proyectos sigue una progresión simple:\n\nSin Documentación\nAlguna Documentación\nDocumentación Completa\nBuena Documentación\nExcelente Documentación\n\nSi te sientes perdido acerca de por dónde continuar con tu documentación, observa en qué punto se encuentra tu proyecto en relación con la progresión mencionada anteriormente. ¿Tienes alguna documentación? Si no la tienes, comienza por ahí. Si ya tienes algo de documentación pero te faltan algunos de los archivos clave del proyecto, comienza agregándolos.\nAl final, no te desanimes ni te sientas abrumado por la cantidad de trabajo necesario para documentar el código.\nUna vez que comiences a documentar tu código, te resultará más fácil seguir adelante.\n\n\n\n\nDocumenting Python Code: A Complete Guide\nDocument Your Python Code and Projects With ChatGPT"
  },
  {
    "objectID": "posts/2023/art_docs.html#introducción",
    "href": "posts/2023/art_docs.html#introducción",
    "title": "Documentación",
    "section": "",
    "text": "Cuando escribes código, lo haces para dos audiencias principales: tus usuarios y tus desarrolladores (incluyéndote a ti mismo). Ambas audiencias son igualmente cruciales. Si eres como yo, es posible que hayas abierto antiguas bases de código y te hayas preguntado: “¿En qué estaba pensando?”. Si tienes dificultades para entender tu propio código, imagina lo que tus usuarios u otros desarrolladores sienten cuando intentan utilizarlo o contribuir a tu código.\nPor otro lado, es probable que hayas pasado por situaciones en las que deseabas realizar algo en Python y encontraste lo que parecía ser una excelente biblioteca que podría hacer el trabajo. Sin embargo, al comenzar a usar la biblioteca, buscaste ejemplos, descripciones o incluso documentación oficial sobre cómo realizar una tarea específica y no pudiste encontrar una solución de inmediato.\nDespués de buscar durante un tiempo, te das cuenta de que la documentación es insuficiente o, peor aún, está completamente ausente. Esta es una experiencia frustrante que te impide utilizar la biblioteca, sin importar cuán bueno o eficiente sea el código. Daniele Procida resumió esta situación de manera acertada:\n\n\n\n\n\n\nCita\n\n\n\n“No importa cuán bueno sea tu software, porque si la documentación no es lo suficientemente buena, la gente no lo usará.” — Daniele Procida\n\n\nEn esta guía, aprenderás desde cero cómo documentar adecuadamente tu código en Python, desde los scripts más pequeños hasta los proyectos más grandes de Python, para evitar que tus usuarios se sientan frustrados al usar o contribuir a tu proyecto."
  },
  {
    "objectID": "posts/2023/art_docs.html#comentarios-vs-documentación",
    "href": "posts/2023/art_docs.html#comentarios-vs-documentación",
    "title": "Documentación",
    "section": "",
    "text": "Antes de sumergirnos en el arte de documentar tu código en Python, es crucial establecer una distinción fundamental: los comentarios y la documentación desempeñan roles distintos y están dirigidos a audiencias diferentes.\nComentarios:\nEn términos generales, los comentarios están diseñados para proporcionar información sobre tu código a los desarrolladores.\nLa audiencia principal a la que se dirigen son aquellos que mantienen y trabajan en el código Python. Cuando se combinan con un código bien escrito, los comentarios actúan como guías que ayudan a los lectores a comprender mejor el código, su propósito y su estructura. Esto se alinea perfectamente con la sabia observación de Jeff Atwood,\n\n\n\n\n\n\nCita\n\n\n\n“El código te dice cómo; los comentarios te dicen por qué.” — Jeff Atwood\n\n\nDocumentación del Código:\nPor otro lado, la documentación del código se enfoca en describir el uso y la funcionalidad del código a los usuarios. Aunque puede ser útil durante el proceso de desarrollo, su audiencia principal son los usuarios finales del software. La siguiente sección de este artículo se adentrará en cuándo y cómo debes abordar la tarea de comentar tu código en Python."
  },
  {
    "objectID": "posts/2023/art_docs.html#comentarios",
    "href": "posts/2023/art_docs.html#comentarios",
    "title": "Documentación",
    "section": "",
    "text": "En Python, los comentarios son esenciales para proporcionar información adicional sobre tu código.\nSe crean utilizando el símbolo de número (#) y deben ser declaraciones breves, no más largas que unas pocas frases. Aquí tienes un ejemplo simple:\ndef hello_world():    \n    # Un comentario simple antes de una simple declaración de impresión\n    print(\"Hola Mundo\")\nDe acuerdo con las pautas de estilo de código de Python (PEP 8), los comentarios deben tener una longitud máxima de 72 caracteres. Esto es válido incluso si tu proyecto cambia la longitud máxima de línea recomendada para que sea mayor que los 80 caracteres. Si un comentario va a superar el límite de caracteres recomendado, es apropiado usar múltiples líneas para el comentario:\ndef hello_long_world():     \n    # Una declaración muy larga que sigue y sigue y sigue y sigue y sigue \n    # sin terminar hasta que alcance el límite de 80 caracteres\n    print(\"¡Hola Mundoooooooooooooooooooooooooooooooooooooooooooooooooooooo!\")\nComentar tu código sirve para varios propósitos, incluyendo:\n\nPlanificación y Revisión: Durante el desarrollo de nuevas partes de tu código, los comentarios pueden servir como una forma de planificar o esquematizar esa sección. Es importante recordar eliminar estos comentarios una vez que se haya implementado y revisado/testeado el código real:\n# Primer paso\n# Segundo paso\n# Tercer paso\nDescripción del Código: Los comentarios se utilizan para explicar la intención de secciones específicas del código:\n# Intentar una conexión basada en configuraciones anteriores. Si no tiene éxito,\n# solicitar al usuario nuevas configuraciones.\nDescripción Algorítmica: Al usar algoritmos, especialmente los complicados, es útil explicar cómo funcionan o cómo se implementan en tu código. También es apropiado describir por qué seleccionaste un algoritmo específico en lugar de otro:\n# Usar el ordenamiento rápido para obtener ganancias de rendimiento.\nEtiquetado: Puedes utilizar etiquetas para señalar secciones específicas de código donde se encuentran problemas conocidos o áreas de mejora. Algunos ejemplos son BUG, FIXME y TODO:\n# TODO: Agregar condición para cuando 'val' sea None\n\nLos comentarios en tu código deben ser breves y centrados. Evita comentarios largos cuando sea posible. Además, sigue las siguientes cuatro reglas esenciales sugeridas por Jeff Atwood:\n\nMantén los Comentarios Cerca del Código: Los comentarios deben estar lo más cerca posible del código que describen. Los comentarios distantes del código descriptivo son frustrantes y pueden pasarse por alto fácilmente al realizar actualizaciones.\nEvita el Formato Complejo: No uses formatos complejos como tablas o figuras ASCII. Estos formatos pueden distraer y ser difíciles de mantener con el tiempo.\nEvita Información Redundante: Supón que el lector del código tiene un entendimiento básico de los principios de programación y la sintaxis del lenguaje. No incluyas información redundante.\nDiseña Tu Código para que se Comente por Sí Mismo: La forma más fácil de entender el código es leyéndolo. Cuando diseñes tu código utilizando conceptos claros y fáciles de entender, ayudarás al lector a comprender tu intención de manera rápida y sencilla.\n\nRecuerda que los comentarios están diseñados para los lectores, incluyéndote a ti mismo, para ayudarlos a comprender el propósito y diseño del software.\n\n\n\nEl Type Hinting es una característica que te permite indicar explícitamente los tipos de datos que esperas en las funciones y métodos. Aunque Python es un lenguaje de programación de tipado dinámico, el Type Hinting no cambia esa naturaleza, pero proporciona información adicional a los desarrolladores y a las herramientas de análisis estático sobre cómo debería funcionar el código.\nEl Type Hinting no afecta el comportamiento en tiempo de ejecución, por lo que no impide que el código funcione si los tipos no coinciden.\nEn cambio, es una herramienta para ayudar a los desarrolladores a comprender y depurar el código de manera más eficiente y prevenir posibles errores.\nConsidera la siguiente función hello_name:\ndef hello_name(name: str) -&gt; str:\n    return f\"Hello {name}\"\nEn este ejemplo, hemos utilizado Type Hinting para especificar que el parámetro name debe ser una cadena (str) y que la función hello_name debe devolver una cadena (str). Esta información es útil para otros desarrolladores que utilicen esta función porque ahora saben qué tipo de dato esperar como entrada y qué tipo de dato obtendrán como resultado."
  },
  {
    "objectID": "posts/2023/art_docs.html#docstrings",
    "href": "posts/2023/art_docs.html#docstrings",
    "title": "Documentación",
    "section": "",
    "text": "Una parte fundamental de la documentación en Python son las docstrings, que son cadenas de texto utilizadas para describir funciones, clases, módulos y más.\n\n\nLas docstrings son cadenas de documentación que se encuentran dentro del código fuente Python. Estas cadenas proporcionan información sobre el propósito y el funcionamiento de funciones, clases y otros elementos del código.\nLas docstrings son especialmente valiosas para ayudar a los usuarios y desarrolladores a comprender cómo utilizar y trabajar con tu código.\n¿Cómo Funcionan las Docstrings?\nCuando definimos una función, clase o módulo en Python, podemos incluir una docstring justo debajo de la definición. Por ejemplo:\ndef saludar(nombre):\n    \"\"\"Esta función imprime un saludo personalizado.\"\"\"\n    print(f\"Hola, {nombre}!\")\nLas docstrings se pueden acceder a través del atributo __doc__ del objeto. Por ejemplo:\nprint(saludar.__doc__)\nLa salida sería: “Esta función imprime un saludo personalizado.” Las docstrings también se utilizan en entornos de desarrollo interactivo y se muestran al utilizar la función help().\nManipulación de Docstrings\nEs importante destacar que puedes manipular directamente las docstrings. Sin embargo, existen restricciones para los objetos incorporados en Python. Por ejemplo, no puedes cambiar la docstring de un objeto str incorporado:\nstr.__doc__ = \"¡Esto no funcionará para objetos incorporados!\"\nPero para funciones y objetos personalizados, puedes establecer o modificar sus docstrings de la siguiente manera:\ndef decir_hola(nombre):\n    \"\"\"Una función simple que saluda a la manera de Richie.\"\"\"\n    print(f\"Hola {nombre}, ¿soy yo a quien estás buscando?\")\n\ndecir_hola.__doc__ = \"Una función que saluda estilo Richie Rich.\"\nUbicación Estratégica de las Docstrings\nUna forma más sencilla de definir docstrings es colocar una cadena literal justo debajo de la definición de la función o clase. Python automáticamente interpreta esta cadena como la docstring. Por ejemplo:\ndef decir_hola(nombre):\n    \"\"\"Una función simple que saluda a la manera de Richie.\"\"\"\n    print(f\"Hola {nombre}, ¿soy yo a quien estás buscando?\")\n\n\n\nLas docstrings son elementos esenciales para documentar tu código Python de manera clara y coherente. Siguen convenciones y pautas que se describen en PEP 257.\nEl propósito de las docstrings es proporcionar a los usuarios de tu código un resumen conciso y útil del objeto, como una función, clase, módulo o script. Deben ser lo suficientemente concisas como para ser fáciles de mantener, pero lo suficientemente detalladas como para que los nuevos usuarios comprendan su propósito y cómo utilizar el objeto documentado.\n\n\nTodas las docstrings deben utilizar el formato de triple comilla doble (\"\"\") y deben colocarse justo debajo de la definición del objeto, ya sea en una sola línea o en varias líneas:\nUna línea:\n\"\"\"Esta es una línea de resumen rápida utilizada como descripción del objeto.\"\"\"\nVarias líneas:\n\"\"\"\nEsta es la línea de resumen\nEsta es la elaboración adicional de la docstring. Dentro de esta sección, puedes proporcionar más detalles según sea apropiado para la situación. Observa que el resumen y la elaboración están separados por una nueva línea en blanco.\n\"\"\"\nEs importante destacar que todas las docstrings de varias líneas deben seguir un patrón específico:\n\nUna línea de resumen de una sola línea.\nUna línea en blanco después del resumen.\nCualquier elaboración adicional de la docstring.\nOtra línea en blanco.\n\nAdemás, todas las docstrings deben tener una longitud máxima de caracteres que sigue las mismas pautas que los comentarios, que es de 72 caracteres.\n\n\n\nLas docstrings de clase se crean para la clase en sí, así como para cualquier método de clase. Las docstrings se colocan inmediatamente después de la clase o el método de clase, con un nivel de sangría:\nclass ClaseSimple:\n    \"\"\"Aquí van las docstrings de clase.\"\"\"\n    def decir_hola(self, nombre: str):\n        \"\"\"Aquí van las docstrings de método de clase.\"\"\"\n        print(f'Hola {nombre}')\nLas docstrings de clase deben contener la siguiente información:\n\nUn breve resumen de su propósito y comportamiento.\nCualquier método público, junto con una breve descripción.\nCualquier propiedad de clase (atributos).\nCualquier cosa relacionada con la interfaz para los subclases, si la clase está destinada a ser subclaseada.\n\nLos parámetros del constructor de clase deben documentarse dentro de la docstring del método __init__ de la clase. Los métodos individuales deben documentarse utilizando sus propias docstrings individuales. Las docstrings de método de clase deben contener lo siguiente:\n\nUna breve descripción de lo que hace el método y para qué se utiliza.\nCualquier argumento (tanto requerido como opcional) que se pase, incluidos los argumentos de palabras clave.\nEtiqueta para cualquier argumento que se considere opcional o tenga un valor predeterminado.\nCualquier efecto secundario que ocurra al ejecutar el método.\nCualquier excepción que se genere.\nCualquier restricción sobre cuándo se puede llamar al método.\n\nEchemos un vistazo a un ejemplo simple de una clase de datos que representa un Animal. Esta clase contendrá algunas propiedades de clase, propiedades de instancia, un __init__ y un único método de instancia:\nclass Animal:\n    \"\"\"Una clase utilizada para representar un Animal\n    \n    Attributes:\n        dice_str (str): una cadena formateada para imprimir lo que dice el animal\n        nombre (str): el nombre del animal\n        sonido (str): el sonido que hace el animal\n        num_patas (int): el número de patas del animal (predeterminado 4)\n    \"\"\"\n    \n    dice_str = \"Un {nombre} dice {sonido}\"\n    \n    def __init__(self, nombre, sonido, num_patas=4):\n        \"\"\"Inicializa una nueva instancia de Animal\n        \n        Parameters:\n            nombre (str): El nombre del animal\n            sonido (str): El sonido que hace el animal\n            num_patas (int, opcional): El número de patas del animal (predeterminado es 4)\n        \"\"\"\n        self.nombre = nombre\n        self.sonido = sonido\n        self.num_patas = num_patas\n        \n    def dice(self, sonido=None):\n        \"\"\"Imprime el nombre del animal y el sonido que hace.\n        \n        Si no se pasa el argumento `sonido`, se utiliza el sonido predeterminado del Animal.\n        \n        Parameters:\n            sonido (str, opcional): El sonido que hace el animal (predeterminado es None)\n        \n        Raises:\n            NotImplementedError: Si no se establece ningún sonido para el animal o se pasa como parámetro.\n        \"\"\"\n        if self.sonido is None and sonido is None:\n            raise NotImplementedError(\"¡No se admiten animales silenciosos!\")\n        sonido_salida = self.sonido if sonido is None else sonido\n        print(self.dice_str.format(nombre=self.nombre, sonido=sonido_salida))\n\n\n\n\n\nExisten formatos específicos de docstrings que pueden ser utilizados para ayudar a los analizadores de docstrings y a los usuarios a tener un formato familiar y reconocido.\nAlgunos de los formatos más comunes son los siguientes:\n\n\n\nTipo de Formato\nDescripción\nCompatible con Sphinx\nEspecificación Formal\n\n\n\n\nGoogle docstrings\nForma de documentación recomendada por Google\nSí\nNo\n\n\nreStructuredText\nEstándar oficial de documentación de Python; no es amigable para principiantes pero rico en características\nSí\nSí\n\n\nNumPy/SciPy docstrings\nCombinación de reStructuredText y Docstrings de Google utilizada por NumPy\nSí\nSí\n\n\nEpytext\nUna adaptación de Epydoc para Python; ideal para desarrolladores de Java\nNo oficialmente\nSí\n\n\n\nLa elección del formato de docstring depende de ti, pero debes mantener el mismo formato en todo tu documento o proyecto. A continuación, se presentan ejemplos de cada tipo para darte una idea de cómo se ve cada formato de documentación.\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cálculo\n\nArgs:\n    file_loc (str): La ubicación del archivo de la hoja de cálculo.\n    print_cols (bool): Una bandera utilizada para imprimir las columnas en la consola\n        (el valor predeterminado es Falso)\n\nReturns:\n    list: una lista de cadenas que representan las columnas de encabezado\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cálculo\n\n:param file_loc: La ubicación del archivo de la hoja de cálculo\n:type file_loc: str\n:param print_cols: Una bandera utilizada para imprimir las columnas en la consola\n    (el valor predeterminado es Falso)\n:type print_cols: bool\n\n:returns: una lista de cadenas que representan las columnas de encabezado\n:rtype: list\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cálculo\n\nParameters\n----------\nfile_loc : str\n    La ubicación del archivo de la hoja de cálculo\nprint_cols : bool, opcional\n    Una bandera utilizada para imprimir las columnas en la consola (el valor predeterminado es Falso)\n\nReturns\n-------\nlist\n    una lista de cadenas que representan las columnas de encabezado\n\"\"\"\n\n\n\n\"\"\"Obtiene e imprime las columnas de encabezado de la hoja de cálculo\n\n@type file_loc: str\n@param file_loc: La ubicación del archivo de la hoja de cálculo\n@type print_cols: bool\n@param print_cols: Una bandera utilizada para imprimir las columnas en la consola\n    (el valor predeterminado es Falso)\n@rtype: list\n@returns: una lista de cadenas que representan las columnas de encabezado\n\"\"\"\nEstos ejemplos te proporcionan una idea de cómo se estructuran y formatean las docstrings en diferentes estilos de documentación.\nPuedes elegir el que mejor se adapte a tus preferencias y necesidades de documentación, pero asegúrate de mantener la coherencia en todo tu proyecto."
  },
  {
    "objectID": "posts/2023/art_docs.html#documentar-tus-proyectos-de-python",
    "href": "posts/2023/art_docs.html#documentar-tus-proyectos-de-python",
    "title": "Documentación",
    "section": "",
    "text": "Los proyectos de Python vienen en todo tipo de formas, tamaños y propósitos. La forma en que documentas tu proyecto debe adaptarse a tu situación específica. Ten en cuenta quiénes serán los usuarios de tu proyecto y adáptate a sus necesidades. Dependiendo del tipo de proyecto, se recomiendan ciertos aspectos de la documentación. La estructura general del proyecto y su documentación debe ser la siguiente:\nproject_root/\n│\n├── project/  # Project source code\n├── docs/\n├── README\n├── HOW_TO_CONTRIBUTE\n├── CODE_OF_CONDUCT\n├── examples.py\nEsta estructura de directorios es un diseño común para organizar un proyecto de software en Python. A continuación, se explica en detalle cada elemento de esta estructura:\n\nproject_root (Directorio Raíz del Proyecto): Este es el directorio principal que contiene todos los archivos y carpetas relacionados con tu proyecto. Es el punto de partida para tu proyecto.\nproject/ (Carpeta “project”): Esta carpeta suele contener el código fuente principal de tu proyecto. Aquí se almacenan todos los archivos de Python que forman parte de tu proyecto. Puedes organizar estos archivos en subdirectorios según la estructura de tu proyecto. Por ejemplo, puedes tener subdirectorios para módulos específicos o componentes del proyecto.\ndocs/ (Carpeta “docs”): La carpeta “docs” se utiliza para almacenar la documentación de tu proyecto. Aquí puedes incluir documentos explicativos, manuales de usuario, instrucciones de instalación y cualquier otra documentación relevante. Mantener una documentación clara y organizada es esencial para que los usuarios comprendan y utilicen tu proyecto de manera efectiva.\nREADME: El archivo “README” es un documento importante que proporciona una breve descripción de tu proyecto y su propósito. Suele incluir información sobre cómo instalar y utilizar el proyecto, así como otros detalles importantes. Los usuarios suelen consultar este archivo primero cuando exploran un proyecto.\nHOW_TO_CONTRIBUTE: Este archivo contiene instrucciones para las personas que deseen contribuir al desarrollo de tu proyecto. Incluye detalles sobre cómo pueden colaborar, enviar correcciones, agregar nuevas funciones y seguir las pautas de contribución.\nCODE_OF_CONDUCT: El archivo “CODE_OF_CONDUCT” establece las reglas y pautas de comportamiento que deben seguir los colaboradores y usuarios del proyecto. Define cómo deben interactuar entre sí de manera respetuosa y profesional. También puede indicar las consecuencias en caso de violación del código de conducta.\nexamples.py: Este archivo es un script de Python que contiene ejemplos simples de cómo utilizar las funcionalidades de tu proyecto. Estos ejemplos pueden ayudar a los usuarios a comprender cómo utilizar tu código en situaciones reales y proporcionar ejemplos de uso práctico."
  },
  {
    "objectID": "posts/2023/art_docs.html#principales-librerías",
    "href": "posts/2023/art_docs.html#principales-librerías",
    "title": "Documentación",
    "section": "",
    "text": "La documentación es una parte fundamental de cualquier proyecto de desarrollo de software. Proporciona información crucial sobre cómo utilizar, mantener y contribuir al código. En el ecosistema de Python, existen varias bibliotecas y herramientas que facilitan la tarea de documentar el código de manera efectiva. En este artículo, exploraremos algunas de las principales bibliotecas de Python utilizadas para documentar código.\n\n\n\nSphinx es una de las herramientas de documentación más populares en el mundo de Python. Fue originalmente desarrollada para documentar la propia documentación de Python y se ha convertido en una elección común para proyectos de código abierto y proyectos internos. Algunas de sus características clave incluyen:\n\nGeneración de documentación en varios formatos, incluyendo HTML, PDF, ePub y más.\nUtiliza reStructuredText como su formato de marcado predeterminado, que es altamente estructurado y permite documentar de manera eficiente los aspectos técnicos.\nAmplia gama de extensiones y complementos que permiten personalizar y mejorar la documentación.\nAdmite la generación automática de documentación a partir de docstrings en el código Python.\nEs especialmente adecuado para documentar bibliotecas, API y proyectos técnicos.\n\nSphinx es altamente configurable y puede generar documentación de alta calidad y profesional. Sin embargo, puede requerir un tiempo de configuración inicial y tiene una curva de aprendizaje empinada para los principiantes.\n\n\n\n\nMkDocs es una herramienta de generación de documentación que se centra en la simplicidad y la facilidad de uso. Está diseñada para crear documentación de proyectos de una manera simple y rápida, principalmente enfocada en la generación de sitios web de documentación. Algunas de sus características clave incluyen:\n\nUtiliza Markdown como formato de marcado predeterminado, que es fácil de aprender y escribir.\nOfrece una interfaz de línea de comandos simple para iniciar y generar sitios de documentación.\nProporciona temas y extensiones para personalizar el aspecto y la funcionalidad de la documentación generada.\nIdeal para proyectos de código abierto y documentación de proyectos pequeños a medianos.\n\nMkDocs es especialmente adecuado para proyectos con necesidades de documentación simples. Es fácil de aprender y usar, lo que lo convierte en una excelente opción para principiantes. Sin embargo, puede ser limitado en funcionalidad en comparación con Sphinx para proyectos técnicos y complejos.\n\n\n\nMkDocs-Material es un tema personalizado para MkDocs, una popular herramienta de generación de sitios web estáticos diseñada para crear documentación de proyectos de manera sencilla y efectiva. Este tema, conocido como “Material for MkDocs”, se inspira en el elegante diseño de Material Design de Google y está diseñado para ofrecer una experiencia de documentación moderna y atractiva.\nUna de las principales características de MkDocs-Material es su enfoque en la legibilidad y la facilidad de navegación. Esto se logra mediante un diseño limpio y organizado que hace que la documentación sea más accesible para los usuarios. Además, el tema proporciona herramientas útiles para mejorar la experiencia de los lectores, como una función de búsqueda integrada que permite a los usuarios encontrar rápidamente la información que necesitan.\nOtra ventaja de MkDocs-Material es su navegación intuitiva, que facilita a los usuarios la exploración de la documentación y la navegación entre secciones y páginas. Esto es fundamental para garantizar que los usuarios puedan acceder fácilmente a la información que están buscando sin esfuerzo."
  },
  {
    "objectID": "posts/2023/art_docs.html#por-dónde-empiezo",
    "href": "posts/2023/art_docs.html#por-dónde-empiezo",
    "title": "Documentación",
    "section": "",
    "text": "La documentación de proyectos sigue una progresión simple:\n\nSin Documentación\nAlguna Documentación\nDocumentación Completa\nBuena Documentación\nExcelente Documentación\n\nSi te sientes perdido acerca de por dónde continuar con tu documentación, observa en qué punto se encuentra tu proyecto en relación con la progresión mencionada anteriormente. ¿Tienes alguna documentación? Si no la tienes, comienza por ahí. Si ya tienes algo de documentación pero te faltan algunos de los archivos clave del proyecto, comienza agregándolos.\nAl final, no te desanimes ni te sientas abrumado por la cantidad de trabajo necesario para documentar el código.\nUna vez que comiences a documentar tu código, te resultará más fácil seguir adelante."
  },
  {
    "objectID": "posts/2023/art_docs.html#referencias",
    "href": "posts/2023/art_docs.html#referencias",
    "title": "Documentación",
    "section": "",
    "text": "Documenting Python Code: A Complete Guide\nDocument Your Python Code and Projects With ChatGPT"
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html",
    "href": "posts/2021/2021-07-31-jupyter.html",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Jupyter Notebook, es un entorno de trabajo interactivo que permite desarrollar código en Python (por defecto, aunque permite otros lenguajes) de manera dinámica, a la vez que integrar en un mismo documento tanto bloques de código como texto, gráficas o imágenes. Es un SaaS utilizado ampliamente en análisis numérico, estadística y machine learning, entre otros campos de la informática y las matemáticas.\nPor otro lado, JupyterLab es similar a Jupyter Notebook en cuanto a sus funcionalidade, pero tiene un interfaz más interesante para los usuarios. Eventualmente Jupyter Lab reemplazará a Jupyter Notebok.\nNos centraremos en comprender aspectos básicos de cómo trabajar un archivo en jupyter notebook (extensión .ipynb).\n\n\n\n\n\nPara instalar RISE, necesitará usar la línea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge notebook\nDe lo contrario, puede instalar con pip:\npip install notebook\n\nNota: SI desea instalar JupyterLab, simplemente reemplaza notebook por jupyterlab.\n\n\n\n\n\n\n\nUna vez que haya instalado Jupyter Notebook en su computadora, estará listo para ejecutar el servidor de la computadora portátil. Puede iniciar el servidor del portátil desde la línea de comandos (usando Terminal en Mac/Linux, Símbolo del sistema en Windows) ejecutando:\njupyter notebook\n\nEsto imprimirá cierta información sobre el servidor en su terminal, incluida la URL de la aplicación web (de forma predeterminada, http://localhost:8888):\n$ jupyter notebook\n[I 08:58:24.417 NotebookApp] Serving notebooks from local directory: /Users/catherine\n[I 08:58:24.417 NotebookApp] 0 active kernels\n[I 08:58:24.417 NotebookApp] The Jupyter Notebook is running at: http://localhost:8888/\n[I 08:58:24.417 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\nA continuación, abrirá su navegador web predeterminado a esta URL. Cuando el notebook se abra en su navegador, verá el Panel, que mostrará una lista de notebooks, archivos y subdirectorios en el directorio donde se inició el servidor.\n\nLa parte superior de la lista de notebooks se muestran rutas de navegación en las que se puede hacer clic del directorio actual.\nPara crear un nuevo notebook, haga clic en el botón New en la parte superior de la lista y seleccione el kernel del menú desplegable (como se ve a continuación). Los kernels que se enumeran dependen de lo que esté instalado en el servidor.\n\nNota: Es posible que algunos de los kernels de la siguiente captura de pantalla no existan como una opción para usted.\n\n\nUna vez seleccionado el kernel, se abrira nuestro primer notebook!.\n\n\n\n\nJupyter notebook nos ofrece el siguiente toolbox:\n\n\nFile: En él, puede crear un nuevo cuaderno o abrir uno preexistente. Aquí es también a donde iría para cambiar el nombre de un Cuaderno. Creo que el elemento de menú más interesante es la opción Guardar y Checkpoint. Esto le permite crear puntos de control a los que puede retroceder si lo necesita.\nEdit: Aquí puede cortar, copiar y pegar celdas. Aquí también es donde irías si quisieras eliminar, dividir o fusionar una celda. Puede reordenar celdas aquí también.\nView: es útil para alternar la visibilidad del encabezado y la barra de herramientas. También puede activar o desactivar los números de línea dentro de las celdas. Aquí también es donde irías si quieres meterte con la barra de herramientas de la celda.\nInsert: es solo para insertar celdas encima o debajo de la celda seleccionada actualmente.\nCell: le permite ejecutar una celda, un grupo de celdas o todas las celdas. También puede ir aquí para cambiar el tipo de celda, aunque personalmente considero que la barra de herramientas es más intuitiva para eso.\nKernel: es para trabajar con el kernel que se ejecuta en segundo plano. Aquí puede reiniciar el kernel, volver a conectarlo, apagarlo o incluso cambiar el kernel que está utilizando su computadora portátil.\nWidgets: es para guardar y borrar el estado del widget. Los widgets son básicamente widgets de JavaScript que puede agregar a sus celdas para crear contenido dinámico utilizando Python (u otro Kernel).\nHelp: es donde debe aprender sobre los atajos de teclado del Notebook, un recorrido por la interfaz de usuario y mucho material de referencia.\n\n\n\n\n\n\nJupyter Notebook permite que escribamos texto formateado, es decir, texto con cursiva, negritas, títulos de distintos tamaños, etc., de forma simple. Para ello Jupyter nos permite usar Markdown, que es un lenguaje de marcado (markup) muy popular.\nLos lenguajes de markup son lenguajes ideados para procesar texto, algunos de los más conocidos son HTML y \\(\\LaTeX\\). Markdown tiene como objetivo ser un lenguaje de sintaxis minimalista, simple de aprender y usar; de esa forma uno puede dar formato al texto pero sin perder demasiado tiempo en los detalles.\nLa cantidad de tutoriales en la red sobre Markdown es inmenso, por lo que nos centraremos en indicar las opciones que más se utilizan.\n\nTexto en negrita/cursiva: El texto en negrita se indica entre dos pares de asteriscos. De este modo **palabra** aparecerá como palabra. Por otro lado, el texto en cursiva se indica entre dos asteriscos simples; es decir *palabra* aparecerá como palabra.\nListas: Las listas en Markdown se realizan indicando un asterisco o un número seguido de un punto si se desean listas numeradas. Markdown organiza automáticamente los items asignándoles el número correcto.\nInclusión de imágenes: La sintaxis para incluir imágenes en Markdown es ![nombre alternativo](dirección de la imagen) en donde el nombre alternativo aparecerá en caso de que no se pueda cargar la imágen y la dirección puede referirse a una imagen local o un enlace en Internet.\nInclusión de código HTML: El lenguaje Markdown es un subconjunto del lenguaje HTML y en donde se necesite un mayor control del formato, se puede incluir directamente el código HTML.\nEnlaces: Las celdas de texto pueden contener enlaces, tanto a otras partes del documento, como a páginas en internet u otros archivos locales. Su sintaxis es [texto](dirección del enlace).\nFórmulas matemáticas: Gracias al uso de MathJax, se puede incluir código en \\(\\LaTeX\\) para mostrar todo tipo de fórmulas y expresiones matemáticas. Las fórmulas dentro de una línea de texto se escriben entre símbolos de dólar $...$, mientras que las expresiones separadas del texto utilizan símbolos de dólar dobles $$...$$. Los siguientes son ejemplos de fórmulas matemáticas escritas en \\(\\LaTeX\\):\n\n\\[p(x) = 3x^2 + 5y^2 + x^2y^2\\]\n\\[e^{\\pi i} - 1 = 0\\]\n\\[\\lim_{x \\rightarrow \\infty} 3x+1\\]\n\\[\\sum_{n=1}^\\infty\\frac{1}{n^2}\\]\n\\[\\int_0^\\infty\\frac{\\sin x}{x}\\,\\mathrm{d}x=\\frac{\\pi}{2}\\]\n\n\n\n\nJupyter Notebook permite que escribamos código dependiendo del kernel a trabajar. Por defecto, se trabaja con el kernel de Python.\nVeamos unos ejemplos sencillos de código:\n\nimport math\nn = 16\nprint(f\"La raiz cuadra de {n} es {math.sqrt(n)}\")\n\nLa raiz cuadra de 16 es 4.0\n\n\nTambién es posible visualizar tablas de datos con la librería pandas:\n\n#collapse-hide\nimport pandas as pd\nimport altair as alt\n\n# datasets\nmovies = 'https://vega.github.io/vega-datasets/data/movies.json'\nstocks = 'https://vega.github.io/vega-datasets/data/stocks.csv'\n\n\ndf = pd.read_json(movies) # load movies data\ndf.columns = [x.replace(' ', '_') for x in df.columns.values]\n\ndf.head()\n\n\n\n\n\n\n\n\nTitle\nUS_Gross\nWorldwide_Gross\nUS_DVD_Sales\nProduction_Budget\nRelease_Date\nMPAA_Rating\nRunning_Time_min\nDistributor\nSource\nMajor_Genre\nCreative_Type\nDirector\nRotten_Tomatoes_Rating\nIMDB_Rating\nIMDB_Votes\n\n\n\n\n0\nThe Land Girls\n146083.0\n146083.0\nNaN\n8000000.0\nJun 12 1998\nR\nNaN\nGramercy\nNone\nNone\nNone\nNone\nNaN\n6.1\n1071.0\n\n\n1\nFirst Love, Last Rites\n10876.0\n10876.0\nNaN\n300000.0\nAug 07 1998\nR\nNaN\nStrand\nNone\nDrama\nNone\nNone\nNaN\n6.9\n207.0\n\n\n2\nI Married a Strange Person\n203134.0\n203134.0\nNaN\n250000.0\nAug 28 1998\nNone\nNaN\nLionsgate\nNone\nComedy\nNone\nNone\nNaN\n6.8\n865.0\n\n\n3\nLet's Talk About Sex\n373615.0\n373615.0\nNaN\n300000.0\nSep 11 1998\nNone\nNaN\nFine Line\nNone\nComedy\nNone\nNone\n13.0\nNaN\nNaN\n\n\n4\nSlam\n1009819.0\n1087521.0\nNaN\n1000000.0\nOct 09 1998\nR\nNaN\nTrimark\nOriginal Screenplay\nDrama\nContemporary Fiction\nNone\n62.0\n3.4\n165.0\n\n\n\n\n\n\n\nUnas de las cosas más significativas de Jupyter notebook es poder trabajar con distintos tipos de gráficos (imagen estática o interactiva). Estos son de bastante utilidad para poder comprender nuestros procedimientos.\n\n#collapse-hide\n\n# select a point for which to provide details-on-demand\nlabel = alt.selection_single(\n    encodings=['x'], # limit selection to x-axis value\n    on='mouseover',  # select on mouseover events\n    nearest=True,    # select data point nearest the cursor\n    empty='none'     # empty selection includes no data points\n)\n\n# define our base line chart of stock prices\nbase = alt.Chart().mark_line().encode(\n    alt.X('date:T'),\n    alt.Y('price:Q', scale=alt.Scale(type='log')),\n    alt.Color('symbol:N')\n)\n\nalt.layer(\n    base, # base line chart\n    \n    # add a rule mark to serve as a guide line\n    alt.Chart().mark_rule(color='#aaa').encode(\n        x='date:T'\n    ).transform_filter(label),\n    \n    # add circle marks for selected time points, hide unselected points\n    base.mark_circle().encode(\n        opacity=alt.condition(label, alt.value(1), alt.value(0))\n    ).add_selection(label),\n\n    # add white stroked text to provide a legible background for labels\n    base.mark_text(align='left', dx=5, dy=-5, stroke='white', strokeWidth=2).encode(\n        text='price:Q'\n    ).transform_filter(label),\n\n    # add text labels for stock prices\n    base.mark_text(align='left', dx=5, dy=-5).encode(\n        text='price:Q'\n    ).transform_filter(label),\n    \n    data=stocks\n).properties(\n    width=500,\n    height=400\n)\n\n\n\n\n\n\n\n\nLa completación mediante tabs, especialmente para los atributos, es una forma conveniente de explorar la estructura de cualquier objeto con el que esté tratando.\nSimplemente escriba object_name.&lt;TAB&gt; para ver los atributos del objeto. Además de los objetos y palabras clave de Python, la finalización de pestañas también funciona en nombres de archivos y directorios.\nimport collections\ncollections. # aprete la tecla &lt;𝑇𝐴𝐵&gt;\n\n\n\nEn caso de necesitar ayuda sobre cualquier comando de Python, Jupyter nos ofrece una función llamada help.\nEn resumen, ¡suele ser más importante saber como buscar información que memorizarla! Por todo esto, Jupyter nos ofrece ayuda sobre cualquier comando agregando un signo de interrogación ? luego del nombre del comando (y luego ejecutar la celda con la combinación de teclas SHIFT + ENTER).\nimport numpy as np\nnp.sum?\n\n\n\nJupyter posee varias funciones mágicas predefinidas que sirven para simplificar tareas comunes.\nHay dos tipos de magias:\n\nMagias por linea (line magics): son comandos que empiezan con el caracter % y que toman como argumentos valores escritos en la misma línea.\nMagias por celda (cell magics): son comandos que empiezan con los caracteres %%, y que reciben argumentos en la misma línea y en toda la celda.\n\nEn general solo se puede usar una sola mágias por celda en cada celda y debe ser escrita en la primer linea de la celda.\nUn buen ejemplo de mágia es %lsmagic que lista todas las magias disponibles:\n\n%lsmagic\n\nAvailable line magics:\n%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n\nAvailable cell magics:\n%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n\nAutomagic is ON, % prefix IS NOT needed for line magics.\n\n\nEn varias situaciones resulta necesario medir el tiempo de ejecución de una porción de código. Para ello podemos usar la magia %timeit. Esta magia está disponible tanto para línea como para celda:\n\n%%timeit \n1+1 # timeit repite (adaptativamente) la medición a fin de reducir el error.\n\n8.68 ns ± 0.387 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n\n\nJupyter notebook permite también mezclar varios lenguajes de programación en una misma notebook. Por ejemplo, podríamos escribir en bash lo siguiente:\n\n%%bash\nfor i in {3..1}; do\n    echo $i\ndone\necho \"Hola desde $BASH\"\n\n3\n2\n1\nHola desde /usr/bin/bash\n\n\nTambién, puede acceder a la línea de comandos, anteponiendo el símbolo de !. Esto es de bastante utilidad cuando se quiere mostrar las dependencias que se necesitan instalar. (ejemplo: !pip install pandas).\nVeamos un ejemplo:\n\n!pwd\n\n/home/fralfaro/PycharmProjects/ds_blog/_notebooks\n\n\n\n\n\n\n\nNotebook Basics\nRunning the Notebook"
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#introducción",
    "href": "posts/2021/2021-07-31-jupyter.html#introducción",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Jupyter Notebook, es un entorno de trabajo interactivo que permite desarrollar código en Python (por defecto, aunque permite otros lenguajes) de manera dinámica, a la vez que integrar en un mismo documento tanto bloques de código como texto, gráficas o imágenes. Es un SaaS utilizado ampliamente en análisis numérico, estadística y machine learning, entre otros campos de la informática y las matemáticas.\nPor otro lado, JupyterLab es similar a Jupyter Notebook en cuanto a sus funcionalidade, pero tiene un interfaz más interesante para los usuarios. Eventualmente Jupyter Lab reemplazará a Jupyter Notebok.\nNos centraremos en comprender aspectos básicos de cómo trabajar un archivo en jupyter notebook (extensión .ipynb)."
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#primeros-pasos",
    "href": "posts/2021/2021-07-31-jupyter.html#primeros-pasos",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Para instalar RISE, necesitará usar la línea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge notebook\nDe lo contrario, puede instalar con pip:\npip install notebook\n\nNota: SI desea instalar JupyterLab, simplemente reemplaza notebook por jupyterlab."
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#primeros-pasos-1",
    "href": "posts/2021/2021-07-31-jupyter.html#primeros-pasos-1",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Una vez que haya instalado Jupyter Notebook en su computadora, estará listo para ejecutar el servidor de la computadora portátil. Puede iniciar el servidor del portátil desde la línea de comandos (usando Terminal en Mac/Linux, Símbolo del sistema en Windows) ejecutando:\njupyter notebook\n\nEsto imprimirá cierta información sobre el servidor en su terminal, incluida la URL de la aplicación web (de forma predeterminada, http://localhost:8888):\n$ jupyter notebook\n[I 08:58:24.417 NotebookApp] Serving notebooks from local directory: /Users/catherine\n[I 08:58:24.417 NotebookApp] 0 active kernels\n[I 08:58:24.417 NotebookApp] The Jupyter Notebook is running at: http://localhost:8888/\n[I 08:58:24.417 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\nA continuación, abrirá su navegador web predeterminado a esta URL. Cuando el notebook se abra en su navegador, verá el Panel, que mostrará una lista de notebooks, archivos y subdirectorios en el directorio donde se inició el servidor.\n\nLa parte superior de la lista de notebooks se muestran rutas de navegación en las que se puede hacer clic del directorio actual.\nPara crear un nuevo notebook, haga clic en el botón New en la parte superior de la lista y seleccione el kernel del menú desplegable (como se ve a continuación). Los kernels que se enumeran dependen de lo que esté instalado en el servidor.\n\nNota: Es posible que algunos de los kernels de la siguiente captura de pantalla no existan como una opción para usted.\n\n\nUna vez seleccionado el kernel, se abrira nuestro primer notebook!.\n\n\n\n\nJupyter notebook nos ofrece el siguiente toolbox:\n\n\nFile: En él, puede crear un nuevo cuaderno o abrir uno preexistente. Aquí es también a donde iría para cambiar el nombre de un Cuaderno. Creo que el elemento de menú más interesante es la opción Guardar y Checkpoint. Esto le permite crear puntos de control a los que puede retroceder si lo necesita.\nEdit: Aquí puede cortar, copiar y pegar celdas. Aquí también es donde irías si quisieras eliminar, dividir o fusionar una celda. Puede reordenar celdas aquí también.\nView: es útil para alternar la visibilidad del encabezado y la barra de herramientas. También puede activar o desactivar los números de línea dentro de las celdas. Aquí también es donde irías si quieres meterte con la barra de herramientas de la celda.\nInsert: es solo para insertar celdas encima o debajo de la celda seleccionada actualmente.\nCell: le permite ejecutar una celda, un grupo de celdas o todas las celdas. También puede ir aquí para cambiar el tipo de celda, aunque personalmente considero que la barra de herramientas es más intuitiva para eso.\nKernel: es para trabajar con el kernel que se ejecuta en segundo plano. Aquí puede reiniciar el kernel, volver a conectarlo, apagarlo o incluso cambiar el kernel que está utilizando su computadora portátil.\nWidgets: es para guardar y borrar el estado del widget. Los widgets son básicamente widgets de JavaScript que puede agregar a sus celdas para crear contenido dinámico utilizando Python (u otro Kernel).\nHelp: es donde debe aprender sobre los atajos de teclado del Notebook, un recorrido por la interfaz de usuario y mucho material de referencia."
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#markdown",
    "href": "posts/2021/2021-07-31-jupyter.html#markdown",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Jupyter Notebook permite que escribamos texto formateado, es decir, texto con cursiva, negritas, títulos de distintos tamaños, etc., de forma simple. Para ello Jupyter nos permite usar Markdown, que es un lenguaje de marcado (markup) muy popular.\nLos lenguajes de markup son lenguajes ideados para procesar texto, algunos de los más conocidos son HTML y \\(\\LaTeX\\). Markdown tiene como objetivo ser un lenguaje de sintaxis minimalista, simple de aprender y usar; de esa forma uno puede dar formato al texto pero sin perder demasiado tiempo en los detalles.\nLa cantidad de tutoriales en la red sobre Markdown es inmenso, por lo que nos centraremos en indicar las opciones que más se utilizan.\n\nTexto en negrita/cursiva: El texto en negrita se indica entre dos pares de asteriscos. De este modo **palabra** aparecerá como palabra. Por otro lado, el texto en cursiva se indica entre dos asteriscos simples; es decir *palabra* aparecerá como palabra.\nListas: Las listas en Markdown se realizan indicando un asterisco o un número seguido de un punto si se desean listas numeradas. Markdown organiza automáticamente los items asignándoles el número correcto.\nInclusión de imágenes: La sintaxis para incluir imágenes en Markdown es ![nombre alternativo](dirección de la imagen) en donde el nombre alternativo aparecerá en caso de que no se pueda cargar la imágen y la dirección puede referirse a una imagen local o un enlace en Internet.\nInclusión de código HTML: El lenguaje Markdown es un subconjunto del lenguaje HTML y en donde se necesite un mayor control del formato, se puede incluir directamente el código HTML.\nEnlaces: Las celdas de texto pueden contener enlaces, tanto a otras partes del documento, como a páginas en internet u otros archivos locales. Su sintaxis es [texto](dirección del enlace).\nFórmulas matemáticas: Gracias al uso de MathJax, se puede incluir código en \\(\\LaTeX\\) para mostrar todo tipo de fórmulas y expresiones matemáticas. Las fórmulas dentro de una línea de texto se escriben entre símbolos de dólar $...$, mientras que las expresiones separadas del texto utilizan símbolos de dólar dobles $$...$$. Los siguientes son ejemplos de fórmulas matemáticas escritas en \\(\\LaTeX\\):\n\n\\[p(x) = 3x^2 + 5y^2 + x^2y^2\\]\n\\[e^{\\pi i} - 1 = 0\\]\n\\[\\lim_{x \\rightarrow \\infty} 3x+1\\]\n\\[\\sum_{n=1}^\\infty\\frac{1}{n^2}\\]\n\\[\\int_0^\\infty\\frac{\\sin x}{x}\\,\\mathrm{d}x=\\frac{\\pi}{2}\\]"
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#código",
    "href": "posts/2021/2021-07-31-jupyter.html#código",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Jupyter Notebook permite que escribamos código dependiendo del kernel a trabajar. Por defecto, se trabaja con el kernel de Python.\nVeamos unos ejemplos sencillos de código:\n\nimport math\nn = 16\nprint(f\"La raiz cuadra de {n} es {math.sqrt(n)}\")\n\nLa raiz cuadra de 16 es 4.0\n\n\nTambién es posible visualizar tablas de datos con la librería pandas:\n\n#collapse-hide\nimport pandas as pd\nimport altair as alt\n\n# datasets\nmovies = 'https://vega.github.io/vega-datasets/data/movies.json'\nstocks = 'https://vega.github.io/vega-datasets/data/stocks.csv'\n\n\ndf = pd.read_json(movies) # load movies data\ndf.columns = [x.replace(' ', '_') for x in df.columns.values]\n\ndf.head()\n\n\n\n\n\n\n\n\nTitle\nUS_Gross\nWorldwide_Gross\nUS_DVD_Sales\nProduction_Budget\nRelease_Date\nMPAA_Rating\nRunning_Time_min\nDistributor\nSource\nMajor_Genre\nCreative_Type\nDirector\nRotten_Tomatoes_Rating\nIMDB_Rating\nIMDB_Votes\n\n\n\n\n0\nThe Land Girls\n146083.0\n146083.0\nNaN\n8000000.0\nJun 12 1998\nR\nNaN\nGramercy\nNone\nNone\nNone\nNone\nNaN\n6.1\n1071.0\n\n\n1\nFirst Love, Last Rites\n10876.0\n10876.0\nNaN\n300000.0\nAug 07 1998\nR\nNaN\nStrand\nNone\nDrama\nNone\nNone\nNaN\n6.9\n207.0\n\n\n2\nI Married a Strange Person\n203134.0\n203134.0\nNaN\n250000.0\nAug 28 1998\nNone\nNaN\nLionsgate\nNone\nComedy\nNone\nNone\nNaN\n6.8\n865.0\n\n\n3\nLet's Talk About Sex\n373615.0\n373615.0\nNaN\n300000.0\nSep 11 1998\nNone\nNaN\nFine Line\nNone\nComedy\nNone\nNone\n13.0\nNaN\nNaN\n\n\n4\nSlam\n1009819.0\n1087521.0\nNaN\n1000000.0\nOct 09 1998\nR\nNaN\nTrimark\nOriginal Screenplay\nDrama\nContemporary Fiction\nNone\n62.0\n3.4\n165.0\n\n\n\n\n\n\n\nUnas de las cosas más significativas de Jupyter notebook es poder trabajar con distintos tipos de gráficos (imagen estática o interactiva). Estos son de bastante utilidad para poder comprender nuestros procedimientos.\n\n#collapse-hide\n\n# select a point for which to provide details-on-demand\nlabel = alt.selection_single(\n    encodings=['x'], # limit selection to x-axis value\n    on='mouseover',  # select on mouseover events\n    nearest=True,    # select data point nearest the cursor\n    empty='none'     # empty selection includes no data points\n)\n\n# define our base line chart of stock prices\nbase = alt.Chart().mark_line().encode(\n    alt.X('date:T'),\n    alt.Y('price:Q', scale=alt.Scale(type='log')),\n    alt.Color('symbol:N')\n)\n\nalt.layer(\n    base, # base line chart\n    \n    # add a rule mark to serve as a guide line\n    alt.Chart().mark_rule(color='#aaa').encode(\n        x='date:T'\n    ).transform_filter(label),\n    \n    # add circle marks for selected time points, hide unselected points\n    base.mark_circle().encode(\n        opacity=alt.condition(label, alt.value(1), alt.value(0))\n    ).add_selection(label),\n\n    # add white stroked text to provide a legible background for labels\n    base.mark_text(align='left', dx=5, dy=-5, stroke='white', strokeWidth=2).encode(\n        text='price:Q'\n    ).transform_filter(label),\n\n    # add text labels for stock prices\n    base.mark_text(align='left', dx=5, dy=-5).encode(\n        text='price:Q'\n    ).transform_filter(label),\n    \n    data=stocks\n).properties(\n    width=500,\n    height=400\n)\n\n\n\n\n\n\n\n\nLa completación mediante tabs, especialmente para los atributos, es una forma conveniente de explorar la estructura de cualquier objeto con el que esté tratando.\nSimplemente escriba object_name.&lt;TAB&gt; para ver los atributos del objeto. Además de los objetos y palabras clave de Python, la finalización de pestañas también funciona en nombres de archivos y directorios.\nimport collections\ncollections. # aprete la tecla &lt;𝑇𝐴𝐵&gt;\n\n\n\nEn caso de necesitar ayuda sobre cualquier comando de Python, Jupyter nos ofrece una función llamada help.\nEn resumen, ¡suele ser más importante saber como buscar información que memorizarla! Por todo esto, Jupyter nos ofrece ayuda sobre cualquier comando agregando un signo de interrogación ? luego del nombre del comando (y luego ejecutar la celda con la combinación de teclas SHIFT + ENTER).\nimport numpy as np\nnp.sum?\n\n\n\nJupyter posee varias funciones mágicas predefinidas que sirven para simplificar tareas comunes.\nHay dos tipos de magias:\n\nMagias por linea (line magics): son comandos que empiezan con el caracter % y que toman como argumentos valores escritos en la misma línea.\nMagias por celda (cell magics): son comandos que empiezan con los caracteres %%, y que reciben argumentos en la misma línea y en toda la celda.\n\nEn general solo se puede usar una sola mágias por celda en cada celda y debe ser escrita en la primer linea de la celda.\nUn buen ejemplo de mágia es %lsmagic que lista todas las magias disponibles:\n\n%lsmagic\n\nAvailable line magics:\n%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n\nAvailable cell magics:\n%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n\nAutomagic is ON, % prefix IS NOT needed for line magics.\n\n\nEn varias situaciones resulta necesario medir el tiempo de ejecución de una porción de código. Para ello podemos usar la magia %timeit. Esta magia está disponible tanto para línea como para celda:\n\n%%timeit \n1+1 # timeit repite (adaptativamente) la medición a fin de reducir el error.\n\n8.68 ns ± 0.387 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n\n\nJupyter notebook permite también mezclar varios lenguajes de programación en una misma notebook. Por ejemplo, podríamos escribir en bash lo siguiente:\n\n%%bash\nfor i in {3..1}; do\n    echo $i\ndone\necho \"Hola desde $BASH\"\n\n3\n2\n1\nHola desde /usr/bin/bash\n\n\nTambién, puede acceder a la línea de comandos, anteponiendo el símbolo de !. Esto es de bastante utilidad cuando se quiere mostrar las dependencias que se necesitan instalar. (ejemplo: !pip install pandas).\nVeamos un ejemplo:\n\n!pwd\n\n/home/fralfaro/PycharmProjects/ds_blog/_notebooks"
  },
  {
    "objectID": "posts/2021/2021-07-31-jupyter.html#referencias",
    "href": "posts/2021/2021-07-31-jupyter.html#referencias",
    "title": "Jupyter Noteboook",
    "section": "",
    "text": "Notebook Basics\nRunning the Notebook"
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html",
    "href": "posts/2021/2021-08-31-buenas_practicas.html",
    "title": "Buenas Prácticas - Python",
    "section": "",
    "text": "Una pregunta que surgue a menudo cuando uno se encuentra programando es saber cuál es la forma correcta de programar. La respuesta es que no existe la forma correcta de programar (ya sea en Python o cualquier otro lenguaje), sin embargo, existen estandares dentro del mundo de la programación, con el fin de hacer el código más legible, sencillo de entender y ayudar a encontrar posibles errores.\nEn esta sección se mostrará algunos conceptos sencillos que te ayudarán a mejorar tus skills en el desarrollo de software (con Python).\n\n\n\nEl PEP8 es un estilo de codificación que proporciona convenciones de codificación para el código Python que comprende la biblioteca estándar en la distribución principal de Python.\nAlgunos aspectos importantes:\n\nEl PEP8 y el PEP 257 (Docstring Conventions) fueron adaptados del ensayo original de la Guía de estilo Python de Guido, con algunas adiciones de la guía de estilo de Barry.\nEsta guía de estilo evoluciona con el tiempo a medida que se identifican convenciones adicionales y las convenciones pasadas se vuelven obsoletas debido a cambios en el propio lenguaje.\nMuchos proyectos tienen sus propias pautas de estilo de codificación. En caso de conflicto, dichas guías específicas del proyecto tienen prioridad para ese proyecto.\n\nBasados en el PEP8 y algunas buenas prácticas del diseño de software, veamos ejemplo para poder escribir de mejor forma nuestros códigos.\n\n\nCuando sea posible, define variables con nombres que tengan algún sentido o que puedas identificar fácilmente, no importa que sean más largas. Por ejemplo, en un programa podríamos escribir:\n\na = 10.  \nb = 3.5 \nprint(f\"El area es {a*b}\" )\n\nEl area es 35.0\n\n\npero, ¿qué significan a y b? lo sabemos por el comentario (bien hecho), pero si más adelante nos encontramos con esas variables, tendremos que recordar cual es cual. Es mejor usar nombres con significado:\n\naltura = 10.  \nbase = 3.5 \nprint(f\"El area es {a*b}\" )\n\nEl area es 35.0\n\n\n\n\n\nLas líneas de codigo no deben ser muy largas, como mucho 72 caracteres. Si se tiene una línea larga, se puede cortar con una barra invertida (\\) y continuar en la siguiente línea:\n\nprint(\"Esta es una frase muy larga, se puede cortar con un \\\n       y seguir en la línea inferior.\")\n\nEsta es una frase muy larga, se puede cortar con un        y seguir en la línea inferior.\n\n\n\n\n\nLos comentarios son muy importantes al escribir un programa. Describen lo que está sucediendo dentro de un programa, para que una persona que mira el código fuente no tenga dificultades para descifrarlo.\n\n#\n# esto es un comentario\nprint('Hola')\n\nHola\n\n\nTambién podemos tener comentarios multilíneas:\n\n#\n# Este es un comentario largo\n# y se extiende\n# a varias líneas\n\n\n\n\nLas importaciones generalmente deben estar en líneas separadas:\n\n#\n# no:\nimport sys, os\n\n\n#\n# si:\nimport os\nimport sys\n\n\n\n\nExisten varias formas de hacer comparaciones de objetos (principalmente en el uso del bucle if), acá se dejan alguna recomendaciones:\n# no\nif greeting == True:\n\n# no\nif greeting is True:\n# si\nif greeting:\n\n\n\nDentro de paréntesis, corchetes o llaves, no dejar espacios inmediatamente dentro de ellos:\n\n#\n# no\nlista_01 = [1, 2, 3,4, 5, 6,7, 8, 9,]\n\n\n#\n# si \nlista_01 = [\n    1, 2, 3,\n    4, 5, 6,\n    7, 8, 9, \n]\n\nAunque en Python se pueden hacer varias declaraciones en una línea, se recomienda hacer sólo una en cada línea:\n\n#\n# no\na = 10; b = 20\n\n\n#\n# si\na = 10\nb = 20  \n\nCuando se trabaja con lista, conjuntos y/o tuplas se recomienda poner en cada línea sus argumentos.\n\n#\n# no\nlista = [(1, 'hola'),(2, 'mundo'),]  \n\n\n#\n# si\nlista = [\n    (1, 'hola'),\n    (2, 'mundo'),\n]\n\nLo anterior se puede extender para funciones con muchos argumentos\n\n#\n# no\ndef funcion_01(x1,x2,x3,x4):\n    print(x1,x2,x3,x4)\n    \ndef funcion_02(\n    x1,x2,x3,x4):\n    print(x1,x2,x3,x4)\n\n\n#\n# si\ndef funcion_01(x1,x2,\n               x3,x4):\n    \n    print(x1,x2,x3,x4)\n    \ndef funcion_02(\n        x1,x2,\n        x3,x4):\n    \n    print(x1,x2,x3,x4)\n\n\n\n\nUn tema interesante es corresponde a la identación respecto a los operadores binarios, acá se muestra la forma correcta de hacerlo:\n# no\nincome = (gross_wages +\n          taxable_interest +\n          (dividends - qualified_dividends) -\n          ira_deduction -\n          student_loan_interest)\n# si\nincome = (gross_wages\n          + taxable_interest\n          + (dividends - qualified_dividends)\n          - ira_deduction\n          - student_loan_interest)\n\n\n\nAunque combinar iterables con elementos de control de flujo para manipular listas es muy sencillo con Python, hay métodos específicos más eficientes para hacer lo mismo. Pensemos el fitrado de datos de una lista:\n\n#\n# Seleccionar los números positivos\nnumeros = [-3, 2, 1, -8, -2, 7]\npositivos = []\nfor i in numeros:\n    if i &gt; 0:\n        positivos.append(i)\n        \nprint(f\"positivos: {positivos}\")\n\npositivos: [2, 1, 7]\n\n\nAunque técnicamente es correcto, es más eficiente hacer List Comprehension:\n\n#\n# comprension de lista\nnumeros = [-3, 2, 1, -8, -2, 7]\npositivos = [i for i in numeros if i &gt; 0] # List Comprehension\nprint(f\"positivos: {positivos}\")\n\npositivos: [2, 1, 7]\n\n\n\n\n\nCuando se ocupa try/except, es necesario especificar el tipo de error que se está cometiendo.\n\n#\n# importar librerias\nimport sys\n\n\n#\n# no\ntry:\n    r = 1/0\nexcept:\n    print(\"Oops! ocurrio un\",sys.exc_info()[0])\n\nOops! ocurrio un &lt;class 'ZeroDivisionError'&gt;\n\n\n\n#\n# si\ntry:\n    r = 1/0\nexcept ZeroDivisionError:\n    print(\"Oops! ocurrio un\",sys.exc_info()[0])\n\nOops! ocurrio un &lt;class 'ZeroDivisionError'&gt;\n\n\n\n\n\nSiempre es mejor definir las variables dentro de una función y no dejar variables globales.\n\n#\n# no\nvalor = 5\n\ndef funcion_01(variable):\n    return 2*variable + valor\n\n\nfuncion_01(2)\n\n9\n\n\n\n#\n# si\ndef funcion_01(variable,valor):\n    return 2*variable + valor\n\n\nfuncion_01(2,5)\n\n9\n\n\n\n\n\nCon Python 3 se puede especificar el tipo de parámetro y el tipo de retorno de una función (usando la notación PEP484 y PEP526. Se definen dos conceptos claves:\n\nEscritura dinámica: no se especifican los atributos de los inputs ni de los ouputs\nEscritura estática: se especifican los atributos de los inputs y los ouputs\n\n\n#\n# escritura dinámica\ndef suma(x,y):\n    return x+y\n\n\nprint(suma(1,2))\n\n3\n\n\n\n#\n# escritura estatica\ndef suma(x:float,\n         y:float)-&gt;float:\n    return x+y\n\n\nprint(suma(1,2))\n\n3\n\n\nPara la escritura estática, si bien se especifica el tipo de atributo (tanto de los inputs o outputs), la función puede recibir otros tipos de atributos.\n\nprint(suma(\"hola\",\" mundo\"))\n\nhola mundo\n\n\nPara validar los tipos de datos son los correctos, se deben ocupar librerías especializadas en la validación de datos (por ejemplo: pydantic).\n\n\n\nExisten librerías que pueden ayudar a corregir errores de escrituras en tú código (también conocido como Análisis Estático), por ejemplo:\n\nblack: El formateador de código inflexible.\nflake8: La herramienta para aplicar la guía de estilo PEP8.\nmypy: Mypy es un verificador de tipo estático para Python 3.\n\n\n\n\n\nCasi tan importante como la escritura de código, es su correcta documentación, una parte fundamental de cualquier programa que a menudo se infravalora o simplemente se ignora. Aparte de los comentarios entre el código explicando cómo funciona, el elemento básico de documentación de Python es el Docstring o cadena de documentación, que ya hemos visto. Simplemente es una cadena de texto con triple comillas que se coloca justo después de la definición de función o clase que sirve de documentación a ese elemento.\n\ndef potencia(x, y):\n    \"\"\"\n    Calcula la potencia arbitraria de un numero\n    \"\"\"\n    return x**y\n\n\n# Acceso a la documentación\npotencia.__doc__\n\n'\\n    Calcula la potencia arbitraria de un numero\\n    '\n\n\n\n# Acceso a la documentación\nhelp(potencia)\n\nHelp on function potencia in module __main__:\n\npotencia(x, y)\n    Calcula la potencia arbitraria de un numero\n\n\n\nLo correcto es detallar lo mejor posible en el Docstring qué hace y cómo se usa la función o clase y los parámetros que necesita. Se recomienda usar el estilo de documentación del software de documentación sphinx, que emplea reStructuredText como lenguaje de marcado.\nVeamos un ejemplo de una función bien documentada:\n\ndef potencia(x, y):\n    \"\"\"\n    Calcula la potencia arbitraria de un numero\n\n    :param x: base\n    :param y: exponente\n    :return:  potencia de un numero\n    :ejemplos:\n    \n    &gt;&gt;&gt; potencia(2, 1)\n    2\n    &gt;&gt;&gt; potencia(3, 2)\n    9\n    \"\"\"\n\n    return x**y\n\n\n# Acceso a la documentación\npotencia.__doc__\n\n'\\n    Calcula la potencia arbitraria de un numero\\n\\n    :param x: base\\n    :param y: exponente\\n    :return:  potencia de un numero\\n    :ejemplos:\\n    \\n    &gt;&gt;&gt; potencia(2, 1)\\n    2\\n    &gt;&gt;&gt; potencia(3, 2)\\n    9\\n    '\n\n\n\n# Acceso a la documentación\nhelp(potencia)\n\nHelp on function potencia in module __main__:\n\npotencia(x, y)\n    Calcula la potencia arbitraria de un numero\n    \n    :param x: base\n    :param y: exponente\n    :return:  potencia de un numero\n    :ejemplos:\n    \n    &gt;&gt;&gt; potencia(2, 1)\n    2\n    &gt;&gt;&gt; potencia(3, 2)\n    9\n\n\n\nExisten varias formas de documentar tus funciones, las principales encontradas en la literatura son: * Google docstrings: forma de documentación recomendada por Google.. * reStructured Text: estándar oficial de documentación de Python; No es apto para principiantes, pero tiene muchas funciones. * NumPy/SciPy docstrings: combinación de NumPy de reStructured y Google Docstrings.\n\n\n\nEl Zen de Python te dará la guía para decidir sobre que hacer con tu código, no te dice como lo debes escribir, sino como debes pensar si estas programando en Python.\nPrincipios importantes:\n\nExplícito es mejor que implícito: Que no se asuma nada, asegúrate que las cosas sean.\nSimple es mejor que complejo: Evita código complejo, código espagueti o que hace mas cosas para poder hacer una simple tarea.\nPlano es mejor que anidado: Si tu código tiene mas de 3 niveles de identación, deberías mover parte de ese código a una función.\nLos errores nunca deberían pasar silenciosamente: No uses un Try/Except sin definir que tipo de error vas a cachar, viene de la mano con Explicito es mejor que implícito.\nSi la implementación es difícil de explicar, es mala idea.\n\nTambién, podemos ver el mensaje original del zen de python, ejecutando la siguiente linea de comando.\n\nimport this\n\nThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!\n\n\n\n\n\nLos consejos que se presentan son de mucha utilidad si usted quiere llevar sus conociminetos de programación al siguiente nivel, sin embargo, el contenido de cada uno amerita un curso por si solo. Se deja recomienda al lector seguir profundizando en estos temas.\n\n\nPython al ser multiparadigma, nos da una amplia gama de posibilidades de diseñar nuestros códigos. Dentro de estos se destacan:\n\nProgramación orientada a objetos (OOP)\nProgramación funcional\n\nCuándo ocupar uno o la otra, va a depender de cómo queremos abordar una determinada problemática, puesto que en la mayoría de los casos, se puede pasar de un paradigma a o otro (incluso mezclarlos de ser necesario).\n\n\n\nEn ingeniería de software, SOLID (Single responsibility, Open-closed, Liskov substitution, Interface segregation and Dependency inversion) es un acrónimo mnemónico introducido por Robert C. Martin a comienzos de la década del 2000 que representa cinco principios básicos de la programación orientada a objetos y el diseño. Cuando estos principios se aplican en conjunto es más probable que un desarrollador cree un sistema que sea fácil de mantener y ampliar con el tiempo.\nEn el siguiente link se deja una guía para poder entender estos conceptos en python.\n\n\n\nLos patrones de diseño son la base para la búsqueda de soluciones a problemas comunes en el desarrollo de software y otros ámbitos referentes al diseño de interacción o interfaces.\n\nUn patrón de diseño es una solución a un problema de diseño.\n\nSe destacan tres tipos de patrones de diseños:\n\nComportamiento\nCreacionales\nEstructurales\n\nEn el siguiente link se deja una guía para poder entender estos conceptos en python.\n\n\n\n\nEsta sección ofrece una selección de libros fundamentales para programadores, abarcando temas como codificación limpia, manejo de código heredado, refactorización y desarrollo profesional. Escritos por expertos como Robert C. Martin, Michael C. Feathers, Martin Fowler y Thomas Hunt, estos libros proporcionan consejos prácticos y estrategias probadas para mejorar la calidad del código y avanzar en la carrera de programación.\n\nThe Clean Coder: A Code Of Conduct For Professional Programmers Robert C. Martin (2011)\nClean Code: A Handbook of Agile Software - Robert C. Martin (2009).\nWorking effectively with legacy code Michael C. Feathers (2004)\nRefactoring Martin Fowler (1999)\nThe Pragmatic Programmer Thomas Hunt (1999)\n\n\n\n\n\nCode Style\nWrite More Pythonic Code"
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#introducción",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#introducción",
    "title": "Buenas Prácticas - Python",
    "section": "",
    "text": "Una pregunta que surgue a menudo cuando uno se encuentra programando es saber cuál es la forma correcta de programar. La respuesta es que no existe la forma correcta de programar (ya sea en Python o cualquier otro lenguaje), sin embargo, existen estandares dentro del mundo de la programación, con el fin de hacer el código más legible, sencillo de entender y ayudar a encontrar posibles errores.\nEn esta sección se mostrará algunos conceptos sencillos que te ayudarán a mejorar tus skills en el desarrollo de software (con Python)."
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#estilo-de-codificación-pep8",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#estilo-de-codificación-pep8",
    "title": "Buenas Prácticas - Python",
    "section": "",
    "text": "El PEP8 es un estilo de codificación que proporciona convenciones de codificación para el código Python que comprende la biblioteca estándar en la distribución principal de Python.\nAlgunos aspectos importantes:\n\nEl PEP8 y el PEP 257 (Docstring Conventions) fueron adaptados del ensayo original de la Guía de estilo Python de Guido, con algunas adiciones de la guía de estilo de Barry.\nEsta guía de estilo evoluciona con el tiempo a medida que se identifican convenciones adicionales y las convenciones pasadas se vuelven obsoletas debido a cambios en el propio lenguaje.\nMuchos proyectos tienen sus propias pautas de estilo de codificación. En caso de conflicto, dichas guías específicas del proyecto tienen prioridad para ese proyecto.\n\nBasados en el PEP8 y algunas buenas prácticas del diseño de software, veamos ejemplo para poder escribir de mejor forma nuestros códigos.\n\n\nCuando sea posible, define variables con nombres que tengan algún sentido o que puedas identificar fácilmente, no importa que sean más largas. Por ejemplo, en un programa podríamos escribir:\n\na = 10.  \nb = 3.5 \nprint(f\"El area es {a*b}\" )\n\nEl area es 35.0\n\n\npero, ¿qué significan a y b? lo sabemos por el comentario (bien hecho), pero si más adelante nos encontramos con esas variables, tendremos que recordar cual es cual. Es mejor usar nombres con significado:\n\naltura = 10.  \nbase = 3.5 \nprint(f\"El area es {a*b}\" )\n\nEl area es 35.0\n\n\n\n\n\nLas líneas de codigo no deben ser muy largas, como mucho 72 caracteres. Si se tiene una línea larga, se puede cortar con una barra invertida (\\) y continuar en la siguiente línea:\n\nprint(\"Esta es una frase muy larga, se puede cortar con un \\\n       y seguir en la línea inferior.\")\n\nEsta es una frase muy larga, se puede cortar con un        y seguir en la línea inferior.\n\n\n\n\n\nLos comentarios son muy importantes al escribir un programa. Describen lo que está sucediendo dentro de un programa, para que una persona que mira el código fuente no tenga dificultades para descifrarlo.\n\n#\n# esto es un comentario\nprint('Hola')\n\nHola\n\n\nTambién podemos tener comentarios multilíneas:\n\n#\n# Este es un comentario largo\n# y se extiende\n# a varias líneas\n\n\n\n\nLas importaciones generalmente deben estar en líneas separadas:\n\n#\n# no:\nimport sys, os\n\n\n#\n# si:\nimport os\nimport sys\n\n\n\n\nExisten varias formas de hacer comparaciones de objetos (principalmente en el uso del bucle if), acá se dejan alguna recomendaciones:\n# no\nif greeting == True:\n\n# no\nif greeting is True:\n# si\nif greeting:\n\n\n\nDentro de paréntesis, corchetes o llaves, no dejar espacios inmediatamente dentro de ellos:\n\n#\n# no\nlista_01 = [1, 2, 3,4, 5, 6,7, 8, 9,]\n\n\n#\n# si \nlista_01 = [\n    1, 2, 3,\n    4, 5, 6,\n    7, 8, 9, \n]\n\nAunque en Python se pueden hacer varias declaraciones en una línea, se recomienda hacer sólo una en cada línea:\n\n#\n# no\na = 10; b = 20\n\n\n#\n# si\na = 10\nb = 20  \n\nCuando se trabaja con lista, conjuntos y/o tuplas se recomienda poner en cada línea sus argumentos.\n\n#\n# no\nlista = [(1, 'hola'),(2, 'mundo'),]  \n\n\n#\n# si\nlista = [\n    (1, 'hola'),\n    (2, 'mundo'),\n]\n\nLo anterior se puede extender para funciones con muchos argumentos\n\n#\n# no\ndef funcion_01(x1,x2,x3,x4):\n    print(x1,x2,x3,x4)\n    \ndef funcion_02(\n    x1,x2,x3,x4):\n    print(x1,x2,x3,x4)\n\n\n#\n# si\ndef funcion_01(x1,x2,\n               x3,x4):\n    \n    print(x1,x2,x3,x4)\n    \ndef funcion_02(\n        x1,x2,\n        x3,x4):\n    \n    print(x1,x2,x3,x4)\n\n\n\n\nUn tema interesante es corresponde a la identación respecto a los operadores binarios, acá se muestra la forma correcta de hacerlo:\n# no\nincome = (gross_wages +\n          taxable_interest +\n          (dividends - qualified_dividends) -\n          ira_deduction -\n          student_loan_interest)\n# si\nincome = (gross_wages\n          + taxable_interest\n          + (dividends - qualified_dividends)\n          - ira_deduction\n          - student_loan_interest)\n\n\n\nAunque combinar iterables con elementos de control de flujo para manipular listas es muy sencillo con Python, hay métodos específicos más eficientes para hacer lo mismo. Pensemos el fitrado de datos de una lista:\n\n#\n# Seleccionar los números positivos\nnumeros = [-3, 2, 1, -8, -2, 7]\npositivos = []\nfor i in numeros:\n    if i &gt; 0:\n        positivos.append(i)\n        \nprint(f\"positivos: {positivos}\")\n\npositivos: [2, 1, 7]\n\n\nAunque técnicamente es correcto, es más eficiente hacer List Comprehension:\n\n#\n# comprension de lista\nnumeros = [-3, 2, 1, -8, -2, 7]\npositivos = [i for i in numeros if i &gt; 0] # List Comprehension\nprint(f\"positivos: {positivos}\")\n\npositivos: [2, 1, 7]\n\n\n\n\n\nCuando se ocupa try/except, es necesario especificar el tipo de error que se está cometiendo.\n\n#\n# importar librerias\nimport sys\n\n\n#\n# no\ntry:\n    r = 1/0\nexcept:\n    print(\"Oops! ocurrio un\",sys.exc_info()[0])\n\nOops! ocurrio un &lt;class 'ZeroDivisionError'&gt;\n\n\n\n#\n# si\ntry:\n    r = 1/0\nexcept ZeroDivisionError:\n    print(\"Oops! ocurrio un\",sys.exc_info()[0])\n\nOops! ocurrio un &lt;class 'ZeroDivisionError'&gt;\n\n\n\n\n\nSiempre es mejor definir las variables dentro de una función y no dejar variables globales.\n\n#\n# no\nvalor = 5\n\ndef funcion_01(variable):\n    return 2*variable + valor\n\n\nfuncion_01(2)\n\n9\n\n\n\n#\n# si\ndef funcion_01(variable,valor):\n    return 2*variable + valor\n\n\nfuncion_01(2,5)\n\n9\n\n\n\n\n\nCon Python 3 se puede especificar el tipo de parámetro y el tipo de retorno de una función (usando la notación PEP484 y PEP526. Se definen dos conceptos claves:\n\nEscritura dinámica: no se especifican los atributos de los inputs ni de los ouputs\nEscritura estática: se especifican los atributos de los inputs y los ouputs\n\n\n#\n# escritura dinámica\ndef suma(x,y):\n    return x+y\n\n\nprint(suma(1,2))\n\n3\n\n\n\n#\n# escritura estatica\ndef suma(x:float,\n         y:float)-&gt;float:\n    return x+y\n\n\nprint(suma(1,2))\n\n3\n\n\nPara la escritura estática, si bien se especifica el tipo de atributo (tanto de los inputs o outputs), la función puede recibir otros tipos de atributos.\n\nprint(suma(\"hola\",\" mundo\"))\n\nhola mundo\n\n\nPara validar los tipos de datos son los correctos, se deben ocupar librerías especializadas en la validación de datos (por ejemplo: pydantic).\n\n\n\nExisten librerías que pueden ayudar a corregir errores de escrituras en tú código (también conocido como Análisis Estático), por ejemplo:\n\nblack: El formateador de código inflexible.\nflake8: La herramienta para aplicar la guía de estilo PEP8.\nmypy: Mypy es un verificador de tipo estático para Python 3."
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#documentación",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#documentación",
    "title": "Buenas Prácticas - Python",
    "section": "",
    "text": "Casi tan importante como la escritura de código, es su correcta documentación, una parte fundamental de cualquier programa que a menudo se infravalora o simplemente se ignora. Aparte de los comentarios entre el código explicando cómo funciona, el elemento básico de documentación de Python es el Docstring o cadena de documentación, que ya hemos visto. Simplemente es una cadena de texto con triple comillas que se coloca justo después de la definición de función o clase que sirve de documentación a ese elemento.\n\ndef potencia(x, y):\n    \"\"\"\n    Calcula la potencia arbitraria de un numero\n    \"\"\"\n    return x**y\n\n\n# Acceso a la documentación\npotencia.__doc__\n\n'\\n    Calcula la potencia arbitraria de un numero\\n    '\n\n\n\n# Acceso a la documentación\nhelp(potencia)\n\nHelp on function potencia in module __main__:\n\npotencia(x, y)\n    Calcula la potencia arbitraria de un numero\n\n\n\nLo correcto es detallar lo mejor posible en el Docstring qué hace y cómo se usa la función o clase y los parámetros que necesita. Se recomienda usar el estilo de documentación del software de documentación sphinx, que emplea reStructuredText como lenguaje de marcado.\nVeamos un ejemplo de una función bien documentada:\n\ndef potencia(x, y):\n    \"\"\"\n    Calcula la potencia arbitraria de un numero\n\n    :param x: base\n    :param y: exponente\n    :return:  potencia de un numero\n    :ejemplos:\n    \n    &gt;&gt;&gt; potencia(2, 1)\n    2\n    &gt;&gt;&gt; potencia(3, 2)\n    9\n    \"\"\"\n\n    return x**y\n\n\n# Acceso a la documentación\npotencia.__doc__\n\n'\\n    Calcula la potencia arbitraria de un numero\\n\\n    :param x: base\\n    :param y: exponente\\n    :return:  potencia de un numero\\n    :ejemplos:\\n    \\n    &gt;&gt;&gt; potencia(2, 1)\\n    2\\n    &gt;&gt;&gt; potencia(3, 2)\\n    9\\n    '\n\n\n\n# Acceso a la documentación\nhelp(potencia)\n\nHelp on function potencia in module __main__:\n\npotencia(x, y)\n    Calcula la potencia arbitraria de un numero\n    \n    :param x: base\n    :param y: exponente\n    :return:  potencia de un numero\n    :ejemplos:\n    \n    &gt;&gt;&gt; potencia(2, 1)\n    2\n    &gt;&gt;&gt; potencia(3, 2)\n    9\n\n\n\nExisten varias formas de documentar tus funciones, las principales encontradas en la literatura son: * Google docstrings: forma de documentación recomendada por Google.. * reStructured Text: estándar oficial de documentación de Python; No es apto para principiantes, pero tiene muchas funciones. * NumPy/SciPy docstrings: combinación de NumPy de reStructured y Google Docstrings."
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#zen-de-python",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#zen-de-python",
    "title": "Buenas Prácticas - Python",
    "section": "",
    "text": "El Zen de Python te dará la guía para decidir sobre que hacer con tu código, no te dice como lo debes escribir, sino como debes pensar si estas programando en Python.\nPrincipios importantes:\n\nExplícito es mejor que implícito: Que no se asuma nada, asegúrate que las cosas sean.\nSimple es mejor que complejo: Evita código complejo, código espagueti o que hace mas cosas para poder hacer una simple tarea.\nPlano es mejor que anidado: Si tu código tiene mas de 3 niveles de identación, deberías mover parte de ese código a una función.\nLos errores nunca deberían pasar silenciosamente: No uses un Try/Except sin definir que tipo de error vas a cachar, viene de la mano con Explicito es mejor que implícito.\nSi la implementación es difícil de explicar, es mala idea.\n\nTambién, podemos ver el mensaje original del zen de python, ejecutando la siguiente linea de comando.\n\nimport this\n\nThe Zen of Python, by Tim Peters\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren't special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one-- and preferably only one --obvious way to do it.\nAlthough that way may not be obvious at first unless you're Dutch.\nNow is better than never.\nAlthough never is often better than *right* now.\nIf the implementation is hard to explain, it's a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea -- let's do more of those!"
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#más-consejos",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#más-consejos",
    "title": "Buenas Prácticas - Python",
    "section": "",
    "text": "Los consejos que se presentan son de mucha utilidad si usted quiere llevar sus conociminetos de programación al siguiente nivel, sin embargo, el contenido de cada uno amerita un curso por si solo. Se deja recomienda al lector seguir profundizando en estos temas.\n\n\nPython al ser multiparadigma, nos da una amplia gama de posibilidades de diseñar nuestros códigos. Dentro de estos se destacan:\n\nProgramación orientada a objetos (OOP)\nProgramación funcional\n\nCuándo ocupar uno o la otra, va a depender de cómo queremos abordar una determinada problemática, puesto que en la mayoría de los casos, se puede pasar de un paradigma a o otro (incluso mezclarlos de ser necesario).\n\n\n\nEn ingeniería de software, SOLID (Single responsibility, Open-closed, Liskov substitution, Interface segregation and Dependency inversion) es un acrónimo mnemónico introducido por Robert C. Martin a comienzos de la década del 2000 que representa cinco principios básicos de la programación orientada a objetos y el diseño. Cuando estos principios se aplican en conjunto es más probable que un desarrollador cree un sistema que sea fácil de mantener y ampliar con el tiempo.\nEn el siguiente link se deja una guía para poder entender estos conceptos en python.\n\n\n\nLos patrones de diseño son la base para la búsqueda de soluciones a problemas comunes en el desarrollo de software y otros ámbitos referentes al diseño de interacción o interfaces.\n\nUn patrón de diseño es una solución a un problema de diseño.\n\nSe destacan tres tipos de patrones de diseños:\n\nComportamiento\nCreacionales\nEstructurales\n\nEn el siguiente link se deja una guía para poder entender estos conceptos en python."
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#libros",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#libros",
    "title": "Buenas Prácticas - Python",
    "section": "",
    "text": "Esta sección ofrece una selección de libros fundamentales para programadores, abarcando temas como codificación limpia, manejo de código heredado, refactorización y desarrollo profesional. Escritos por expertos como Robert C. Martin, Michael C. Feathers, Martin Fowler y Thomas Hunt, estos libros proporcionan consejos prácticos y estrategias probadas para mejorar la calidad del código y avanzar en la carrera de programación.\n\nThe Clean Coder: A Code Of Conduct For Professional Programmers Robert C. Martin (2011)\nClean Code: A Handbook of Agile Software - Robert C. Martin (2009).\nWorking effectively with legacy code Michael C. Feathers (2004)\nRefactoring Martin Fowler (1999)\nThe Pragmatic Programmer Thomas Hunt (1999)"
  },
  {
    "objectID": "posts/2021/2021-08-31-buenas_practicas.html#referencias",
    "href": "posts/2021/2021-08-31-buenas_practicas.html#referencias",
    "title": "Buenas Prácticas - Python",
    "section": "",
    "text": "Code Style\nWrite More Pythonic Code"
  },
  {
    "objectID": "about-es.html",
    "href": "about-es.html",
    "title": "Francisco Alfaro M.",
    "section": "",
    "text": "English Español\n\n\n\nHola👋 Mi nombre es Francisco!\n\n\n\n\nProfesión: 📊 Ingeniero Matemático\nTrabajo Actual:\n\n💻 Jefe de Analítica Avanzada (Grupo Security)\n📖 Profesor Asociado (UTFSM)\n\n\n\nIntereses\n🎮🦊SSBM-Dark | 🏀👑Basketball-LBJ\n✅ Desarrollo de Software  ✅ Modelado Estadístico, Series Temporales  ✅ Aprendizaje Automático/Profundo  ✅ Computación en la Nube, Big Data"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Francisco Alfaro M.",
    "section": "",
    "text": "English Español\n\n\n\nHi 👋 My name is Francisco!\n\n\n\n\nProfession: 📊 Mathematical Engineer\nCurrent Work:\n\n💻 Head of Advanced Analytics (Grupo Security)\n📖 Associate Lecturer (UTFSM)\n\n\n\nInterests\n🎮🦊SSBM-Dark | 🏀👑Basketball-LBJ\n✅ Software Development  ✅ Statistical Modelling, Time Series  ✅ Machine/Deep Learning  ✅ Cloud computing, Big Data"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Github Actions\n\n\nAprender conceptos básicos de Github Actions y Github Pages.\n\n\n\ngithub\n\n\nmarkdown\n\n\n\n\n\n\n\n\n\n14 may 2024\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nGithub Repository\n\n\nComprender los pasos necesarios para mostrar tus repositorios en Github.\n\n\n\ngithub\n\n\nmarkdown\n\n\n\n\n\n\n\n\n\n7 may 2024\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nGithub Profile\n\n\nComprender los pasos necesarios para crear un perfil de GitHub de alta calidad.\n\n\n\ngithub\n\n\nmarkdown\n\n\n\n\n\n\n\n\n\n8 abr 2024\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentación\n\n\nEnteneder los pasos para crear una buena documentación en Python (más algunas recomendaciones).\n\n\n\npython\n\n\ndocs\n\n\n\n\n\n\n\n\n\n7 oct 2023\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nGitlab PDF\n\n\nCómo aprovechar GitLab CI/CD para generar archivos PDF utilizando los artefactos de un Pipeline.\n\n\n\nci-cd\n\n\nsoftware-development\n\n\n\n\n\n\n\n\n\n1 oct 2023\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nPolars\n\n\nPolars es una librería de DataFrames increíblemente rápida y eficiente implementada en Rust.\n\n\n\npython\n\n\ndata-analysis\n\n\n\n\n\n\n\n\n\n25 may 2022\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nTest Driven Development\n\n\nCómo abordar el desarrollo de software para Data Science usando Test Driven Development.\n\n\n\npython\n\n\nsoftware-development\n\n\n\n\n\n\n\n\n\n25 may 2022\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nImpact on Digital Learning\n\n\nCompetition Solution: LearnPlatform COVID-19 Impact on Digital Learning proposed by Kaggle.\n\n\n\nkaggle\n\n\ndata-analysis\n\n\n\n\n\n\n\n\n\n31 ago 2021\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nBuenas Prácticas - Python\n\n\nConsejos que te ayudarán a mejorar tus skills en el desarrollo de software (con Python).\n\n\n\npython\n\n\nsoftware-development\n\n\n\n\n\n\n\n\n\n15 ago 2021\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nRISE\n\n\nRISE es una extensión a los Jupyter Notebooks que permite transformar tus notebooks en presentaciones interactivas.\n\n\n\npython\n\n\njupyter-notebooks\n\n\n\n\n\n\n\n\n\n5 ago 2021\n\n\nFrancisco Alfaro\n\n\n\n\n\n\n\n\n\n\n\n\nJupyter Noteboook\n\n\nJupyter Notebook, es un entorno de trabajo interactivo que permite desarrollar código en Python.\n\n\n\npython\n\n\njupyter-notebooks\n\n\n\n\n\n\n\n\n\n31 jul 2021\n\n\nFrancisco Alfaro\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html",
    "href": "posts/2021/eda_learnplatform.html",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "Main objective is understand of the best way the challenge LearnPlatform COVID-19 Impact on Digital Learning proposed by Kaggle.\nThe steps to follow are:\n\nOverview of the Dataset: Understanding the datasets available.\nPreprocessing: Preprocessing of the datasets available.\nEDA: Exploratory data analysis using visualization tools in Python.\n\n\nNote: My analysis is inspired by several of the notebooks that different profiles have uploaded to the challenge, so some graphics or images belong to these authors. The most important ones will be found in the references. On the other hand, my project is available in Jupyter Book, click in the following link.\n\n\n\nThe objective of this section is to be able to read and give an interpretation to each one of the available datasets, analyzing column by column. For each dataset we will make a brief description:\n\nFile: File name (.csv).\nShape: Dimensionality of datasets.\nDescription: Basic description of the dataset.\nTop 5 rows: Show first 5 rows + explanation for some columns.\nSummary: Summary of datasets.\n\n\n# libraries\nimport glob\nimport re\n\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# read data\n\n## products dataset\npath = '../input/learnplatform-covid19-impact-on-digital-learning/'\nproducts_df = pd.read_csv(path + \"products_info.csv\")\nproducts_df.columns = [x.lower().replace(' ','_') for x in products_df.columns]\n\n## districts dataset\ndistricts_df = pd.read_csv(path +\"districts_info.csv\")\n#districts_df.state = districts_df.state.replace('District Of Columbia','District of Columbia')\n\n## engagement dataset\npath = '../input/learnplatform-covid19-impact-on-digital-learning/engagement_data/' \nall_files = glob.glob(path + \"/*.csv\")\n\nli = []\n\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"/\")[-1].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    li.append(df)\nengagement_df = pd.concat(li)\nengagement_df = engagement_df.reset_index(drop=True)\n\n# summary\n\ndf_list = [\n    districts_df,\n    products_df,\n    engagement_df\n]\n\ndf_name = [\n    'districts_df',\n    'products_df',\n    'engagement_df'\n]\n\ncols = [\n    'dataframe',\n    'column', \n    'dtype', \n    'Non-Null Count', \n    'Null Count',\n    'unique'\n    \n]\n\nframes=[]\n\n\nfor i in range(len(df_list)):\n    df = df_list[i].copy()\n    a = df.dtypes.reset_index().rename(columns = {'index':'column',0:'dtype'})\n    b = df.count().reset_index().rename(columns = {'index':'column',0:'Non-Null Count'})\n    c = df.isnull().sum().reset_index().rename(columns = {'index':'column',0:'Null Count'})\n    temp = a.merge(b,on = 'column').merge(c,on = 'column')\n    \n    dct = {col: len(df[col].unique()) for col in df.columns}\n    df_unique = pd.DataFrame({\n    'column':dct.keys(),\n    'unique':dct.values(),\n    })\n    temp = temp.merge(df_unique,on = 'column')\n    temp['dataframe'] = df_name[i]\n    frames.append(temp)\n\n\n\n\nFile: districts_info.csv.\nShape: \\(233\\) rows \\(\\times\\) \\(7\\) columns.\nDescription: file contains information about each school district.\nTop 5 rows::\n\n\n\nSummary:\n\n\n\n\n\n\nFile: products_info.csv\nShape: \\(372\\) rows \\(\\times\\) \\(6\\) columns.\nDescription: for each school district, there is an additional file that contains the engagement for each tool for everyday in 2020.\nTop 5 rows:: \nSummary:\n\n\n\n\n\n\nFile: engagement_data/*.csv.\nShape: \\(22324190\\) rows \\(\\times\\) \\(5\\) columns.\nDescription: file contains information about each school district. The files can be joined by the key columns district_id and lp_id.\nTop 5 rows:: \nSummary:\n\n\n\n\n\n\nPreprocessing is an important step in any analytics competition. It helps you to handle your data more efficiently. However, please note that the way I preprocess the data may not be suited for your analysis purposes. Therefore, before you begin preprocessing your data, think about which data you would like to keep and/or modify and which data is not relevant for your analysis.\n\none-hot encoding the product sectors\nsplitting up the primary essential function into main and sub category\n\n\nNote: Preprocessing varies if you see other notebooks of this challenge. The processing will depend on the understanding of each of the datasets and the extra information that you may have.\n\n\n\n# products_df\n\nproducts_df['primary_function_main'] = products_df['primary_essential_function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproducts_df['primary_function_sub'] = products_df['primary_essential_function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproducts_df['primary_function_sub'] = products_df['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\n#products_df.drop(\"Primary Essential Function\", axis=1, inplace=True)\n\ntemp_sectors = products_df['sector(s)'].str.get_dummies(sep=\"; \")\ntemp_sectors.columns = [f\"sector_{re.sub(' ', '', c)}\" for c in temp_sectors.columns]\nproducts_df = products_df.join(temp_sectors)\n#products_df.drop(\"Sector(s)\", axis=1, inplace=True)\n\n#del temp_sectors\n\n# engagement_df\n\nengagement_df['time'] = pd.to_datetime(engagement_df['time'])\n\ntemp = engagement_df[['time']].drop_duplicates('time')\ntemp['week'] = temp['time'].apply(lambda x: x.isocalendar()[1])\nengagement_df = engagement_df.merge(temp,on ='time')\n\nengagement_df['lp_id'] = engagement_df['lp_id'].fillna(-1).astype(int)\nengagement_df['district_id'] = engagement_df['district_id'].fillna(-1).astype(int)\n\nengagement_df_mix = engagement_df.merge(\n    districts_df[['district_id','state']],\n    on = 'district_id'\n)\nengagement_df_mix = engagement_df_mix.merge(\n    products_df[['lp_id','product_name','sector_Corporate', 'sector_HigherEd','sector_PreK-12']],\n    on = 'lp_id'\n)\n\n\n\n\nExploratory data analysis is the most important part of the challenge, since this will make the difference between the winner and the other participants. You should keep in mind that your visualizations must be able to simply and easily summarize the datasets. Also, it is hoped that the proposed visualizations can help to understand behaviors that are not easy to analyze with a simple table.\nVisualizations will be made in matplotlib, seaborn y plotly. Based on the article by Diverging Color Maps for Scientific Visualization (Expanded) - Kenneth Moreland, we will occupy Grays scale next to the technique: dark text on a light background.\n\nNote: Visualizations made on this notebook are static. You can use different tools to be able to make dynamic visualizations (Altair, plotly, etc.). You can also perform tools like Streamlit to make Dashboards. On the other hand, if you fully understand python visualization tools and have knowledge of HTML/CSS, you can make beautiful notebook presentations like this one.\n\n\n\nFirst of all, I am interested how diverse the available school districts are. As you can see in below plot, the available data does not cover all the states in the U.S. . The states with the most available school districts are CT (30) and UT (29) while there are also states with only one school district (FL, TN, NY, AZ).\n\n# map plot: districts\n\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ndistricts_df['state_abbrev'] = districts_df['state'].replace(us_state_abbrev)\ndistricts_info_by_state = districts_df['state_abbrev'].value_counts().to_frame().reset_index(drop=False)\ndistricts_info_by_state.columns = ['state_abbrev', 'num_districts']\n\ntemp = pd.DataFrame({\n    'state_abbrev':us_state_abbrev.values(),\n})\n\ntemp = temp.merge(districts_info_by_state,on='state_abbrev',how='left').fillna(0)\ntemp['num_districts'] = temp['num_districts'].astype(int)\n\nfig = go.Figure()\nlayout = dict(\n    title_text = \"Number of Available School Districts per State\",\n    title_font_color=\"black\",\n    geo_scope='usa',\n)    \n\n\nfig.add_trace(\n    go.Choropleth(\n        locations=temp.state_abbrev,\n        zmax=1,\n        z = temp.num_districts,\n        locationmode = 'USA-states', # set of locations match entries in `locations`\n        marker_line_color='black',\n        geo='geo',\n        colorscale=px.colors.sequential.Greys, \n        \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()\n\n                                                \n\n\n\n# bar plot: districts\n\nplt.style.use('default')\nplt.figure(figsize=(14,8))\n\nplotting = sns.countplot(\n    y=\"state\",\n    data=districts_df,\n    order=districts_df.state.value_counts().index,\n    palette=\"Greys_d\",\n    linewidth=3\n)\n\nfor container in plotting.containers:\n    plotting.bar_label(container,fontsize=16)\n\n#Text\nplotting.text(x = -5, y = -4.2, s = \"State Distribution\",fontsize = 24, weight = 'bold', alpha = .90);\nplotting.text(x = -5, y = -3, s = \"Distribution of United States\",fontsize = 16, alpha = .85)\nplotting.text(x = 31.2, y = 0.08, s = 'Highest', weight = 'bold',fontsize = 14)\nplotting.text(x = 1.7, y = 22.3, s = 'Lowest', weight = 'bold',fontsize = 14)\n\nplt.yticks(fontsize=14)\nplt.xticks(fontsize=14)\n\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nLocales are separated into 4 categories: Suburb,Rural, City and Town, where most of the locales are concentrated in the Suburb category (104).\nFor the pct_black/hispanic variable, Rural and Town categories concentrate their entire population close to the interval $ [0,0.2 [$, while for the others sectors this percentage is varied.\nFor pctfree/reduced and pp_total_raw indicators, the distribution for each location is different, although they tend to focus on a particular interval.\n\n# heatmap: districts -&gt; locale\n\ntemp = districts_df.groupby('locale').pp_total_raw.value_counts().to_frame()\ntemp.columns = ['amount']\n\ntemp = temp.reset_index(drop=False)\n\ntemp = temp.pivot(index='locale', columns='pp_total_raw')['amount']\ntemp = temp[['[4000, 6000[', '[6000, 8000[', '[8000, 10000[', '[10000, 12000[',\n       '[12000, 14000[', '[14000, 16000[', '[16000, 18000[', \n       '[18000, 20000[', '[20000, 22000[', '[22000, 24000[', ]]\n\n\ntemp1 = districts_df.groupby('locale')['pct_black/hispanic'].value_counts().to_frame()\ntemp1.columns = ['amount']\n\ntemp1 = temp1.reset_index(drop=False)\ntemp1 = temp1.pivot(index='locale', columns='pct_black/hispanic')['amount']\n\ntemp2 = districts_df.groupby('locale')['pct_free/reduced'].value_counts().to_frame()\ntemp2.columns = ['amount']\n\ntemp2 = temp2.reset_index(drop=False)\n\ntemp2 = temp2.pivot(index='locale', columns='pct_free/reduced')['amount']\n\nplt.style.use('default')\n\nfig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(24,18))\n\nsns.countplot(data=districts_df, x='locale', ax=ax1, palette='Greys_d')\nax1.text(x = -0.5, y = 120, s = \"Locale Distribution\",fontsize = 24, weight = 'bold', alpha = .90);\nax1.xaxis.set_tick_params(labelsize=16)\n\nfor container in ax1.containers:\n    ax1.bar_label(container,fontsize=16)\n\nsns.heatmap(temp1.fillna(0), annot=True,  cmap='Greys', ax=ax2,annot_kws={\"fontsize\":14})\nax2.set_title('Heatmap: locale and pct_black/hispanic',fontsize=16,loc='left')\nax2.xaxis.set_tick_params(labelsize=16)\nax2.yaxis.set_tick_params(labelsize=16)\n\nsns.heatmap(temp.fillna(0), annot=True,  cmap='Greys', ax=ax3,annot_kws={\"fontsize\":14})\nax3.set_title('Heatmap: locale and pp_total_raw',fontsize=16,loc='left')\nax3.xaxis.set_tick_params(labelsize=16)\nax3.yaxis.set_tick_params(labelsize=16)\n\nsns.heatmap(temp2.fillna(0), annot=True,  cmap='Greys', ax=ax4,annot_kws={\"fontsize\":14})\nax4.set_title('Heatmap: locale and pct_free/reduced',fontsize=16,loc='left')\nax4.xaxis.set_tick_params(labelsize=16)\nax4.yaxis.set_tick_params(labelsize=16)\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSectors are separated into 3 categories: sector_Corporate, sector_HigherEd and sector_PreK-12, donde la categoría mayoritaria corresponde a sector_PreK-12 (350). On the other hand, analyzing the primary_function_main variable, all sectors are focused on theLC category. It is worth mentioning that the distribution of the other categories remains almost the same between sectors.\n\nplt.style.use('default')\nnames = ['sector_Corporate', 'sector_HigherEd','sector_PreK-12']\ncounts = [products_df[x].sum() for x in names]\n\ntemp_bar = pd.DataFrame({\n    'sector':names,\n    'count':counts\n}).sort_values('count',ascending = False)\n\ntemp = products_df.groupby('primary_function_main')[names].sum()\n\n#fig, [ax1, ax2 ]= plt.subplots(nrows=1, ncols=2, figsize=(12,6))\nplt.figure(figsize=(18,18))\n\nplt.subplot(3,2,1)\nax = sns.barplot(x=\"sector\", y=\"count\", data=temp_bar,palette ='Greys_d')\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=12)\n\nplt.subplot(3,2,2)\n\nsns.heatmap(temp.T, annot=True,  cmap='Greys',annot_kws={\"fontsize\":10},fmt='g')\n\nplt.text(x = -6, y = -0.25, s = \"Sectors Distribution\",fontsize = 18, weight = 'bold', alpha = .90);\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nContinuing the analysis of the primary_function_main variable, it was observed that most of these are in theLC category (77%). Within this category, its subcategory is analyzed, where the predominant subcategory is Sites, Resources & Reference (101).\n\n# pieplot: products\n\ncolor = [\n    'darkgray',\n    'silver',\n    'lightgray',\n    'gainsboro',\n]\n\nproducts_df[\"primary_function_main\"].value_counts().plot(\n    kind = 'pie', \n    autopct='%1d%%', \n    figsize=(6,6), \n    colors=color,\n    wedgeprops={\"edgecolor\":\"k\",'linewidth': 0.8,},\n    textprops={'color':\"black\"},\n    startangle=0)\nplt.text(x = -1.4, y = 1.1, s = \"Categories\",fontsize = 18, weight = 'bold', alpha = .90);\nplt.show()\n\n\n\n\n\n\n\n\n\n# pieplot: products -&gt; subcategories\n\nplt.style.use('default')\nplt.figure(figsize=(18,8))\n\ntemp = products_df[products_df.primary_function_main == 'LC']\nax = sns.countplot(\n    data=temp, \n    y='primary_function_sub',\n    order=temp.primary_function_sub.value_counts().index,\n    palette ='Greys_d'\n)\n\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=16)\n\n\n#plt.title('Sub-Categories in Primary Function LC')\nplt.text(x = -50, y = -0.8, \n         s = \"Sub-Categories in Primary Function LC\",fontsize = 24, weight = 'bold', alpha = .90);\n\nplt.text(x = 105, y =0.08, s = 'Highest', weight = 'bold',fontsize=16)\nplt.text(x = 7, y = 6, s = 'Lowest', weight = 'bold',fontsize=16)\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nAfter understanding the functionality of each of the tools, it is necessary to understand the distribution of the tools. The first thing is to study the distribution of the providers of the products we have, where:\n\n258 providers have 1 occurrences.\n18 providers have 2 occurrences.\n9 providers have 3 occurrences.\n2 providers have 4 occurrences.\n2 providers have 6 occurrences.\n1 provider have 30 occurrences.\n\nBased on this, only the top 15 providers will be displayed.\n\ndct = {\n    'Savvas Learning Company | Formerly Pearson K12 Learning': 'Savvas Learning Company'\n}\n\ntemp = products_df['provider/company_name'].value_counts().reset_index()\ntemp.columns = ['provider/company_name','count']\ntemp = temp.replace( {\n    'Savvas Learning Company | Formerly Pearson K12 Learning': 'Savvas Learning Company'\n})\n\nn = 15\ntemp = temp.sort_values('count',ascending = False).head(n)\n\nplt.style.use('default')\nplt.figure(figsize=(18,8))\n\nax = sns.barplot(\n    data=temp, \n    y='provider/company_name',\n    x='count',\n    palette ='Greys_d'\n)\n\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=15)\n    \nplt.text(x = -7, y = -1, \n         s = f\"Top {n} provider/company name\",fontsize = 20, weight = 'bold', alpha = .90);\n   \nplt.text(x = 31, y =0.08, s = 'Highest', weight = 'bold',fontsize=16)\nplt.text(x = 3, y = 14.2, s = 'Lowest', weight = 'bold',fontsize=16)\nplt.yticks(fontsize=16)\n\n\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\nplt.show()\n\n\n\n\n\n\n\n\nWith regard to products, there are about 372 different products.\nWe can make a word cloud to be able to analyze in a different way, words by themselves that are repeated the most in the product_name variable.\n\ncloud = WordCloud(\n    width=1080,\n    height=270,\n    colormap='Greys',\n    background_color='white'\n    ).generate(\" \".join(products_df['product_name'].astype(str)))\n\nplt.figure(figsize=(22, 10))\nplt.imshow(cloud)\nplt.axis('off');\n\n\n\n\n\n\n\n\nTo understand more in detail the use of these products, we will analyze the use of these products with respect to the variable engagement_index. The first graph is related to the average engagement_index (per student) for the year 2020, where the first 15 products will be displayed.\nAn important fact is that 362 products have an average of less than 1!.\n\ngroup_01 = (engagement_df_mix.groupby('product_name')['engagement_index'].mean()/1000).reset_index().sort_values('engagement_index',ascending = False)\ngroup_01['engagement_index'] = group_01['engagement_index'].apply(lambda x: round(x,2))\nless_1 = len(group_01.loc[lambda x:x['engagement_index']&lt;1])\n\n\nplt.style.use('default')\nplt.figure(figsize=(14,8))\n\nplotting = sns.barplot(\n    y=\"product_name\",\n    x = \"engagement_index\",\n    data=group_01.head(20),\n    palette=\"Greys_d\",\n\n)\n\nfor container in plotting.containers:\n    plotting.bar_label(container,fontsize=14)\n\nplt.text(x = -3.5, y = -3, \n         s = \"Mean daily page-load events in top 20 tools\",fontsize = 20, weight = 'bold', alpha = .90);\n\nplt.text(x = -3.5, y = -2, \n         s = \"per 1 student\",fontsize = 14,  alpha = .90);\n\nplt.text(x = 11, y =0.1, s = 'Highest', weight = 'bold',fontsize=14)\nplt.text(x = 1, y = 19.2, s = 'Lowest', weight = 'bold',fontsize=14)\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\nplt.show()\n\n\n\n\n\n\n\n\nLet’s study the temporal behavior (at the level of weeks) of these tools during the year 2020, where the most three used tools will be shown with different colors, while the other tools will be visualized but with the same color (in order to understand their distribution).\n\nNote: The proposed analysis can be carried out at the day level and analyzing through time series each of the tools during the year 2020.\n\n\ncol = 'week'\n\ngroup_04  = (engagement_df_mix.groupby(['product_name',col])['engagement_index'].mean()/1000).reset_index().sort_values('engagement_index',ascending = False)\n\ng_high = group_01.head(3)['product_name']\ngroup_04_top = group_04.loc[lambda x: x.product_name.isin(g_high)]\n\nstates = group_04['product_name'].unique()\ntimes= group_04[col].unique()\n\nindex = pd.MultiIndex.from_product([states,times], names = [\"product_name\", col])\n\ndf_complete = pd.DataFrame(index = index).reset_index().fillna(0)\n\ngroup_04 = df_complete.merge(group_04,on = ['product_name',col],how='left').fillna(0)\n\nn = 3\ng_high = group_04.groupby('product_name')['engagement_index'].sum().sort_values(ascending=False).head(n).index.to_list()\n\n\ncolors = [    \n    'lightgray', \n    'dimgray', \n    'black', \n    'firebrick', \n    'darkred']\npalette_01 = {x:'lavender' for x in group_04['product_name'].unique() if x not in g_high}\npalette_02 = {g_high[i]:colors[i] for i in range(n)}\n\nplt.style.use('default')\nplt.figure(figsize=(20,6))\n\n\nsns.lineplot(\n    data=group_04.loc[lambda x: ~x.product_name.isin(g_high)], \n    x=col, \n    y=\"engagement_index\", \n    hue='product_name',\n    legend = False,\n    palette=palette_01,\n    linewidth = 1.\n\n    )\n\nsns.lineplot(\n    data=group_04.loc[lambda x: x.product_name.isin(g_high)], \n    x=col, \n    y=\"engagement_index\", \n    hue='product_name',\n    palette=palette_02,\n    linewidth = 1.\n\n    )\n\n\nplt.text(x = -2, y =23.7, s = 'Mean daily page-load events in top 3 tools', weight = 'bold',fontsize=14)\nplt.text(x = -2, y =22.3, s = 'by products and time, per 1 student',fontsize=12)\n\n\nplt.text(x = 12, y =20.7, s = '1,000 cases of COVID', weight = 'bold',fontsize=8)\nplt.text(x = 37, y =20.7, s = '1st September', weight = 'bold',fontsize=8)\n\n\nplt.axvline(x = 11, color = 'black', linestyle='--',linewidth = 0.5)\nplt.axvline(x = 36, color = 'black', linestyle='--',linewidth = 0.5)\nplt.show()\n\n\n\n\n\n\n\n\nNow, we can understand the engagement index for the most important tools about districts, where the districts of * Wisconsin ,  Missouri * and * Virginia * have the highest engagement index among the three most used tools.\n\ngroup_02 = (engagement_df_mix.groupby(['state','product_name'])['engagement_index'].mean()/1000)\\\n            .reset_index().sort_values('engagement_index',ascending = False).fillna(0)\n\ngripo_02_top = group_02.loc[lambda x: x.product_name.isin(g_high)]\ngripo_02_top['engagement_index'] = gripo_02_top['engagement_index'].apply(lambda x: round(x,2))\n#gripo_02_top = gripo_02_top.loc[lambda x: x['engagement_index']&gt;0]\n\n\nplt.style.use('default')\n\ng = sns.FacetGrid(gripo_02_top,hue='product_name',col = 'product_name',height=4, col_wrap= 3  )\ng.map(sns.barplot, \"engagement_index\",\"state\", palette=\"Greys_d\",)\n\ng.fig.set_size_inches(15, 8)\ng.fig.subplots_adjust(top=0.81, right=0.86)\n\naxes = g.axes.flatten()\nfor ax in axes:\n    for container in ax.containers:\n        ax.bar_label(container,fontsize=8)\n\n\nplt.text(x = -50, y = -4, s = \"Mean daily page-load events in top 3 tools\",fontsize = 16, weight = 'bold', alpha = .90);\nplt.text(x = -50, y = -3, s = \"by state and products, per 1 student\",fontsize = 14,  alpha = .90);\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nDepending on what you want to achieve you might want to carefully preselect districts. Note that we approach in this notebook might not necessarily suit your individual purposes.\nWhen looking at digital learning, you might want to spend sometime in figuring out which districts actually applied digital learning\n\n\n\n\n\nDiverging Color Maps for Scientific Visualization (Expanded) - Kenneth Moreland\nKaggle Competitions:\n\nEnthusiast to Data Professional - What changes?\nHow To Approach Analytics Challenges\nMost popular tools in 2020 Digital Learning"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html#overview-of-the-dataset",
    "href": "posts/2021/eda_learnplatform.html#overview-of-the-dataset",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "The objective of this section is to be able to read and give an interpretation to each one of the available datasets, analyzing column by column. For each dataset we will make a brief description:\n\nFile: File name (.csv).\nShape: Dimensionality of datasets.\nDescription: Basic description of the dataset.\nTop 5 rows: Show first 5 rows + explanation for some columns.\nSummary: Summary of datasets.\n\n\n# libraries\nimport glob\nimport re\n\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# read data\n\n## products dataset\npath = '../input/learnplatform-covid19-impact-on-digital-learning/'\nproducts_df = pd.read_csv(path + \"products_info.csv\")\nproducts_df.columns = [x.lower().replace(' ','_') for x in products_df.columns]\n\n## districts dataset\ndistricts_df = pd.read_csv(path +\"districts_info.csv\")\n#districts_df.state = districts_df.state.replace('District Of Columbia','District of Columbia')\n\n## engagement dataset\npath = '../input/learnplatform-covid19-impact-on-digital-learning/engagement_data/' \nall_files = glob.glob(path + \"/*.csv\")\n\nli = []\n\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"/\")[-1].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    li.append(df)\nengagement_df = pd.concat(li)\nengagement_df = engagement_df.reset_index(drop=True)\n\n# summary\n\ndf_list = [\n    districts_df,\n    products_df,\n    engagement_df\n]\n\ndf_name = [\n    'districts_df',\n    'products_df',\n    'engagement_df'\n]\n\ncols = [\n    'dataframe',\n    'column', \n    'dtype', \n    'Non-Null Count', \n    'Null Count',\n    'unique'\n    \n]\n\nframes=[]\n\n\nfor i in range(len(df_list)):\n    df = df_list[i].copy()\n    a = df.dtypes.reset_index().rename(columns = {'index':'column',0:'dtype'})\n    b = df.count().reset_index().rename(columns = {'index':'column',0:'Non-Null Count'})\n    c = df.isnull().sum().reset_index().rename(columns = {'index':'column',0:'Null Count'})\n    temp = a.merge(b,on = 'column').merge(c,on = 'column')\n    \n    dct = {col: len(df[col].unique()) for col in df.columns}\n    df_unique = pd.DataFrame({\n    'column':dct.keys(),\n    'unique':dct.values(),\n    })\n    temp = temp.merge(df_unique,on = 'column')\n    temp['dataframe'] = df_name[i]\n    frames.append(temp)\n\n\n\n\nFile: districts_info.csv.\nShape: \\(233\\) rows \\(\\times\\) \\(7\\) columns.\nDescription: file contains information about each school district.\nTop 5 rows::\n\n\n\nSummary:\n\n\n\n\n\n\nFile: products_info.csv\nShape: \\(372\\) rows \\(\\times\\) \\(6\\) columns.\nDescription: for each school district, there is an additional file that contains the engagement for each tool for everyday in 2020.\nTop 5 rows:: \nSummary:\n\n\n\n\n\n\nFile: engagement_data/*.csv.\nShape: \\(22324190\\) rows \\(\\times\\) \\(5\\) columns.\nDescription: file contains information about each school district. The files can be joined by the key columns district_id and lp_id.\nTop 5 rows:: \nSummary:"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html#preprocessing",
    "href": "posts/2021/eda_learnplatform.html#preprocessing",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "Preprocessing is an important step in any analytics competition. It helps you to handle your data more efficiently. However, please note that the way I preprocess the data may not be suited for your analysis purposes. Therefore, before you begin preprocessing your data, think about which data you would like to keep and/or modify and which data is not relevant for your analysis.\n\none-hot encoding the product sectors\nsplitting up the primary essential function into main and sub category\n\n\nNote: Preprocessing varies if you see other notebooks of this challenge. The processing will depend on the understanding of each of the datasets and the extra information that you may have.\n\n\n\n# products_df\n\nproducts_df['primary_function_main'] = products_df['primary_essential_function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproducts_df['primary_function_sub'] = products_df['primary_essential_function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproducts_df['primary_function_sub'] = products_df['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\n#products_df.drop(\"Primary Essential Function\", axis=1, inplace=True)\n\ntemp_sectors = products_df['sector(s)'].str.get_dummies(sep=\"; \")\ntemp_sectors.columns = [f\"sector_{re.sub(' ', '', c)}\" for c in temp_sectors.columns]\nproducts_df = products_df.join(temp_sectors)\n#products_df.drop(\"Sector(s)\", axis=1, inplace=True)\n\n#del temp_sectors\n\n# engagement_df\n\nengagement_df['time'] = pd.to_datetime(engagement_df['time'])\n\ntemp = engagement_df[['time']].drop_duplicates('time')\ntemp['week'] = temp['time'].apply(lambda x: x.isocalendar()[1])\nengagement_df = engagement_df.merge(temp,on ='time')\n\nengagement_df['lp_id'] = engagement_df['lp_id'].fillna(-1).astype(int)\nengagement_df['district_id'] = engagement_df['district_id'].fillna(-1).astype(int)\n\nengagement_df_mix = engagement_df.merge(\n    districts_df[['district_id','state']],\n    on = 'district_id'\n)\nengagement_df_mix = engagement_df_mix.merge(\n    products_df[['lp_id','product_name','sector_Corporate', 'sector_HigherEd','sector_PreK-12']],\n    on = 'lp_id'\n)"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html#eda",
    "href": "posts/2021/eda_learnplatform.html#eda",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "Exploratory data analysis is the most important part of the challenge, since this will make the difference between the winner and the other participants. You should keep in mind that your visualizations must be able to simply and easily summarize the datasets. Also, it is hoped that the proposed visualizations can help to understand behaviors that are not easy to analyze with a simple table.\nVisualizations will be made in matplotlib, seaborn y plotly. Based on the article by Diverging Color Maps for Scientific Visualization (Expanded) - Kenneth Moreland, we will occupy Grays scale next to the technique: dark text on a light background.\n\nNote: Visualizations made on this notebook are static. You can use different tools to be able to make dynamic visualizations (Altair, plotly, etc.). You can also perform tools like Streamlit to make Dashboards. On the other hand, if you fully understand python visualization tools and have knowledge of HTML/CSS, you can make beautiful notebook presentations like this one.\n\n\n\nFirst of all, I am interested how diverse the available school districts are. As you can see in below plot, the available data does not cover all the states in the U.S. . The states with the most available school districts are CT (30) and UT (29) while there are also states with only one school district (FL, TN, NY, AZ).\n\n# map plot: districts\n\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ndistricts_df['state_abbrev'] = districts_df['state'].replace(us_state_abbrev)\ndistricts_info_by_state = districts_df['state_abbrev'].value_counts().to_frame().reset_index(drop=False)\ndistricts_info_by_state.columns = ['state_abbrev', 'num_districts']\n\ntemp = pd.DataFrame({\n    'state_abbrev':us_state_abbrev.values(),\n})\n\ntemp = temp.merge(districts_info_by_state,on='state_abbrev',how='left').fillna(0)\ntemp['num_districts'] = temp['num_districts'].astype(int)\n\nfig = go.Figure()\nlayout = dict(\n    title_text = \"Number of Available School Districts per State\",\n    title_font_color=\"black\",\n    geo_scope='usa',\n)    \n\n\nfig.add_trace(\n    go.Choropleth(\n        locations=temp.state_abbrev,\n        zmax=1,\n        z = temp.num_districts,\n        locationmode = 'USA-states', # set of locations match entries in `locations`\n        marker_line_color='black',\n        geo='geo',\n        colorscale=px.colors.sequential.Greys, \n        \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()\n\n                                                \n\n\n\n# bar plot: districts\n\nplt.style.use('default')\nplt.figure(figsize=(14,8))\n\nplotting = sns.countplot(\n    y=\"state\",\n    data=districts_df,\n    order=districts_df.state.value_counts().index,\n    palette=\"Greys_d\",\n    linewidth=3\n)\n\nfor container in plotting.containers:\n    plotting.bar_label(container,fontsize=16)\n\n#Text\nplotting.text(x = -5, y = -4.2, s = \"State Distribution\",fontsize = 24, weight = 'bold', alpha = .90);\nplotting.text(x = -5, y = -3, s = \"Distribution of United States\",fontsize = 16, alpha = .85)\nplotting.text(x = 31.2, y = 0.08, s = 'Highest', weight = 'bold',fontsize = 14)\nplotting.text(x = 1.7, y = 22.3, s = 'Lowest', weight = 'bold',fontsize = 14)\n\nplt.yticks(fontsize=14)\nplt.xticks(fontsize=14)\n\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nLocales are separated into 4 categories: Suburb,Rural, City and Town, where most of the locales are concentrated in the Suburb category (104).\nFor the pct_black/hispanic variable, Rural and Town categories concentrate their entire population close to the interval $ [0,0.2 [$, while for the others sectors this percentage is varied.\nFor pctfree/reduced and pp_total_raw indicators, the distribution for each location is different, although they tend to focus on a particular interval.\n\n# heatmap: districts -&gt; locale\n\ntemp = districts_df.groupby('locale').pp_total_raw.value_counts().to_frame()\ntemp.columns = ['amount']\n\ntemp = temp.reset_index(drop=False)\n\ntemp = temp.pivot(index='locale', columns='pp_total_raw')['amount']\ntemp = temp[['[4000, 6000[', '[6000, 8000[', '[8000, 10000[', '[10000, 12000[',\n       '[12000, 14000[', '[14000, 16000[', '[16000, 18000[', \n       '[18000, 20000[', '[20000, 22000[', '[22000, 24000[', ]]\n\n\ntemp1 = districts_df.groupby('locale')['pct_black/hispanic'].value_counts().to_frame()\ntemp1.columns = ['amount']\n\ntemp1 = temp1.reset_index(drop=False)\ntemp1 = temp1.pivot(index='locale', columns='pct_black/hispanic')['amount']\n\ntemp2 = districts_df.groupby('locale')['pct_free/reduced'].value_counts().to_frame()\ntemp2.columns = ['amount']\n\ntemp2 = temp2.reset_index(drop=False)\n\ntemp2 = temp2.pivot(index='locale', columns='pct_free/reduced')['amount']\n\nplt.style.use('default')\n\nfig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(nrows=2, ncols=2, figsize=(24,18))\n\nsns.countplot(data=districts_df, x='locale', ax=ax1, palette='Greys_d')\nax1.text(x = -0.5, y = 120, s = \"Locale Distribution\",fontsize = 24, weight = 'bold', alpha = .90);\nax1.xaxis.set_tick_params(labelsize=16)\n\nfor container in ax1.containers:\n    ax1.bar_label(container,fontsize=16)\n\nsns.heatmap(temp1.fillna(0), annot=True,  cmap='Greys', ax=ax2,annot_kws={\"fontsize\":14})\nax2.set_title('Heatmap: locale and pct_black/hispanic',fontsize=16,loc='left')\nax2.xaxis.set_tick_params(labelsize=16)\nax2.yaxis.set_tick_params(labelsize=16)\n\nsns.heatmap(temp.fillna(0), annot=True,  cmap='Greys', ax=ax3,annot_kws={\"fontsize\":14})\nax3.set_title('Heatmap: locale and pp_total_raw',fontsize=16,loc='left')\nax3.xaxis.set_tick_params(labelsize=16)\nax3.yaxis.set_tick_params(labelsize=16)\n\nsns.heatmap(temp2.fillna(0), annot=True,  cmap='Greys', ax=ax4,annot_kws={\"fontsize\":14})\nax4.set_title('Heatmap: locale and pct_free/reduced',fontsize=16,loc='left')\nax4.xaxis.set_tick_params(labelsize=16)\nax4.yaxis.set_tick_params(labelsize=16)\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSectors are separated into 3 categories: sector_Corporate, sector_HigherEd and sector_PreK-12, donde la categoría mayoritaria corresponde a sector_PreK-12 (350). On the other hand, analyzing the primary_function_main variable, all sectors are focused on theLC category. It is worth mentioning that the distribution of the other categories remains almost the same between sectors.\n\nplt.style.use('default')\nnames = ['sector_Corporate', 'sector_HigherEd','sector_PreK-12']\ncounts = [products_df[x].sum() for x in names]\n\ntemp_bar = pd.DataFrame({\n    'sector':names,\n    'count':counts\n}).sort_values('count',ascending = False)\n\ntemp = products_df.groupby('primary_function_main')[names].sum()\n\n#fig, [ax1, ax2 ]= plt.subplots(nrows=1, ncols=2, figsize=(12,6))\nplt.figure(figsize=(18,18))\n\nplt.subplot(3,2,1)\nax = sns.barplot(x=\"sector\", y=\"count\", data=temp_bar,palette ='Greys_d')\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=12)\n\nplt.subplot(3,2,2)\n\nsns.heatmap(temp.T, annot=True,  cmap='Greys',annot_kws={\"fontsize\":10},fmt='g')\n\nplt.text(x = -6, y = -0.25, s = \"Sectors Distribution\",fontsize = 18, weight = 'bold', alpha = .90);\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nContinuing the analysis of the primary_function_main variable, it was observed that most of these are in theLC category (77%). Within this category, its subcategory is analyzed, where the predominant subcategory is Sites, Resources & Reference (101).\n\n# pieplot: products\n\ncolor = [\n    'darkgray',\n    'silver',\n    'lightgray',\n    'gainsboro',\n]\n\nproducts_df[\"primary_function_main\"].value_counts().plot(\n    kind = 'pie', \n    autopct='%1d%%', \n    figsize=(6,6), \n    colors=color,\n    wedgeprops={\"edgecolor\":\"k\",'linewidth': 0.8,},\n    textprops={'color':\"black\"},\n    startangle=0)\nplt.text(x = -1.4, y = 1.1, s = \"Categories\",fontsize = 18, weight = 'bold', alpha = .90);\nplt.show()\n\n\n\n\n\n\n\n\n\n# pieplot: products -&gt; subcategories\n\nplt.style.use('default')\nplt.figure(figsize=(18,8))\n\ntemp = products_df[products_df.primary_function_main == 'LC']\nax = sns.countplot(\n    data=temp, \n    y='primary_function_sub',\n    order=temp.primary_function_sub.value_counts().index,\n    palette ='Greys_d'\n)\n\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=16)\n\n\n#plt.title('Sub-Categories in Primary Function LC')\nplt.text(x = -50, y = -0.8, \n         s = \"Sub-Categories in Primary Function LC\",fontsize = 24, weight = 'bold', alpha = .90);\n\nplt.text(x = 105, y =0.08, s = 'Highest', weight = 'bold',fontsize=16)\nplt.text(x = 7, y = 6, s = 'Lowest', weight = 'bold',fontsize=16)\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nAfter understanding the functionality of each of the tools, it is necessary to understand the distribution of the tools. The first thing is to study the distribution of the providers of the products we have, where:\n\n258 providers have 1 occurrences.\n18 providers have 2 occurrences.\n9 providers have 3 occurrences.\n2 providers have 4 occurrences.\n2 providers have 6 occurrences.\n1 provider have 30 occurrences.\n\nBased on this, only the top 15 providers will be displayed.\n\ndct = {\n    'Savvas Learning Company | Formerly Pearson K12 Learning': 'Savvas Learning Company'\n}\n\ntemp = products_df['provider/company_name'].value_counts().reset_index()\ntemp.columns = ['provider/company_name','count']\ntemp = temp.replace( {\n    'Savvas Learning Company | Formerly Pearson K12 Learning': 'Savvas Learning Company'\n})\n\nn = 15\ntemp = temp.sort_values('count',ascending = False).head(n)\n\nplt.style.use('default')\nplt.figure(figsize=(18,8))\n\nax = sns.barplot(\n    data=temp, \n    y='provider/company_name',\n    x='count',\n    palette ='Greys_d'\n)\n\nfor container in ax.containers:\n    ax.bar_label(container,fontsize=15)\n    \nplt.text(x = -7, y = -1, \n         s = f\"Top {n} provider/company name\",fontsize = 20, weight = 'bold', alpha = .90);\n   \nplt.text(x = 31, y =0.08, s = 'Highest', weight = 'bold',fontsize=16)\nplt.text(x = 3, y = 14.2, s = 'Lowest', weight = 'bold',fontsize=16)\nplt.yticks(fontsize=16)\n\n\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\nplt.show()\n\n\n\n\n\n\n\n\nWith regard to products, there are about 372 different products.\nWe can make a word cloud to be able to analyze in a different way, words by themselves that are repeated the most in the product_name variable.\n\ncloud = WordCloud(\n    width=1080,\n    height=270,\n    colormap='Greys',\n    background_color='white'\n    ).generate(\" \".join(products_df['product_name'].astype(str)))\n\nplt.figure(figsize=(22, 10))\nplt.imshow(cloud)\nplt.axis('off');\n\n\n\n\n\n\n\n\nTo understand more in detail the use of these products, we will analyze the use of these products with respect to the variable engagement_index. The first graph is related to the average engagement_index (per student) for the year 2020, where the first 15 products will be displayed.\nAn important fact is that 362 products have an average of less than 1!.\n\ngroup_01 = (engagement_df_mix.groupby('product_name')['engagement_index'].mean()/1000).reset_index().sort_values('engagement_index',ascending = False)\ngroup_01['engagement_index'] = group_01['engagement_index'].apply(lambda x: round(x,2))\nless_1 = len(group_01.loc[lambda x:x['engagement_index']&lt;1])\n\n\nplt.style.use('default')\nplt.figure(figsize=(14,8))\n\nplotting = sns.barplot(\n    y=\"product_name\",\n    x = \"engagement_index\",\n    data=group_01.head(20),\n    palette=\"Greys_d\",\n\n)\n\nfor container in plotting.containers:\n    plotting.bar_label(container,fontsize=14)\n\nplt.text(x = -3.5, y = -3, \n         s = \"Mean daily page-load events in top 20 tools\",fontsize = 20, weight = 'bold', alpha = .90);\n\nplt.text(x = -3.5, y = -2, \n         s = \"per 1 student\",fontsize = 14,  alpha = .90);\n\nplt.text(x = 11, y =0.1, s = 'Highest', weight = 'bold',fontsize=14)\nplt.text(x = 1, y = 19.2, s = 'Lowest', weight = 'bold',fontsize=14)\nplt.yticks(fontsize=16)\nplt.xticks(fontsize=16)\nplt.show()\n\n\n\n\n\n\n\n\nLet’s study the temporal behavior (at the level of weeks) of these tools during the year 2020, where the most three used tools will be shown with different colors, while the other tools will be visualized but with the same color (in order to understand their distribution).\n\nNote: The proposed analysis can be carried out at the day level and analyzing through time series each of the tools during the year 2020.\n\n\ncol = 'week'\n\ngroup_04  = (engagement_df_mix.groupby(['product_name',col])['engagement_index'].mean()/1000).reset_index().sort_values('engagement_index',ascending = False)\n\ng_high = group_01.head(3)['product_name']\ngroup_04_top = group_04.loc[lambda x: x.product_name.isin(g_high)]\n\nstates = group_04['product_name'].unique()\ntimes= group_04[col].unique()\n\nindex = pd.MultiIndex.from_product([states,times], names = [\"product_name\", col])\n\ndf_complete = pd.DataFrame(index = index).reset_index().fillna(0)\n\ngroup_04 = df_complete.merge(group_04,on = ['product_name',col],how='left').fillna(0)\n\nn = 3\ng_high = group_04.groupby('product_name')['engagement_index'].sum().sort_values(ascending=False).head(n).index.to_list()\n\n\ncolors = [    \n    'lightgray', \n    'dimgray', \n    'black', \n    'firebrick', \n    'darkred']\npalette_01 = {x:'lavender' for x in group_04['product_name'].unique() if x not in g_high}\npalette_02 = {g_high[i]:colors[i] for i in range(n)}\n\nplt.style.use('default')\nplt.figure(figsize=(20,6))\n\n\nsns.lineplot(\n    data=group_04.loc[lambda x: ~x.product_name.isin(g_high)], \n    x=col, \n    y=\"engagement_index\", \n    hue='product_name',\n    legend = False,\n    palette=palette_01,\n    linewidth = 1.\n\n    )\n\nsns.lineplot(\n    data=group_04.loc[lambda x: x.product_name.isin(g_high)], \n    x=col, \n    y=\"engagement_index\", \n    hue='product_name',\n    palette=palette_02,\n    linewidth = 1.\n\n    )\n\n\nplt.text(x = -2, y =23.7, s = 'Mean daily page-load events in top 3 tools', weight = 'bold',fontsize=14)\nplt.text(x = -2, y =22.3, s = 'by products and time, per 1 student',fontsize=12)\n\n\nplt.text(x = 12, y =20.7, s = '1,000 cases of COVID', weight = 'bold',fontsize=8)\nplt.text(x = 37, y =20.7, s = '1st September', weight = 'bold',fontsize=8)\n\n\nplt.axvline(x = 11, color = 'black', linestyle='--',linewidth = 0.5)\nplt.axvline(x = 36, color = 'black', linestyle='--',linewidth = 0.5)\nplt.show()\n\n\n\n\n\n\n\n\nNow, we can understand the engagement index for the most important tools about districts, where the districts of * Wisconsin ,  Missouri * and * Virginia * have the highest engagement index among the three most used tools.\n\ngroup_02 = (engagement_df_mix.groupby(['state','product_name'])['engagement_index'].mean()/1000)\\\n            .reset_index().sort_values('engagement_index',ascending = False).fillna(0)\n\ngripo_02_top = group_02.loc[lambda x: x.product_name.isin(g_high)]\ngripo_02_top['engagement_index'] = gripo_02_top['engagement_index'].apply(lambda x: round(x,2))\n#gripo_02_top = gripo_02_top.loc[lambda x: x['engagement_index']&gt;0]\n\n\nplt.style.use('default')\n\ng = sns.FacetGrid(gripo_02_top,hue='product_name',col = 'product_name',height=4, col_wrap= 3  )\ng.map(sns.barplot, \"engagement_index\",\"state\", palette=\"Greys_d\",)\n\ng.fig.set_size_inches(15, 8)\ng.fig.subplots_adjust(top=0.81, right=0.86)\n\naxes = g.axes.flatten()\nfor ax in axes:\n    for container in ax.containers:\n        ax.bar_label(container,fontsize=8)\n\n\nplt.text(x = -50, y = -4, s = \"Mean daily page-load events in top 3 tools\",fontsize = 16, weight = 'bold', alpha = .90);\nplt.text(x = -50, y = -3, s = \"by state and products, per 1 student\",fontsize = 14,  alpha = .90);\nplt.show()"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html#summary",
    "href": "posts/2021/eda_learnplatform.html#summary",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "Depending on what you want to achieve you might want to carefully preselect districts. Note that we approach in this notebook might not necessarily suit your individual purposes.\nWhen looking at digital learning, you might want to spend sometime in figuring out which districts actually applied digital learning"
  },
  {
    "objectID": "posts/2021/eda_learnplatform.html#references",
    "href": "posts/2021/eda_learnplatform.html#references",
    "title": "Impact on Digital Learning",
    "section": "",
    "text": "Diverging Color Maps for Scientific Visualization (Expanded) - Kenneth Moreland\nKaggle Competitions:\n\nEnthusiast to Data Professional - What changes?\nHow To Approach Analytics Challenges\nMost popular tools in 2020 Digital Learning"
  },
  {
    "objectID": "posts/2021/2021-08-05-rise.html",
    "href": "posts/2021/2021-08-05-rise.html",
    "title": "RISE",
    "section": "",
    "text": "RISE es una extensión a los jupyter notebooks que permite transformar tus notebooks en presentaciones interactivas.\nToda las celdas pueden editarse y ejecutarse directamente, durante la presentación. Esto es práctico si necesitas corregir un error en una celda de texto. Más importante aún, puedes ejecutar código directamente en el kernel. En una misma diapositiva puedes tener múltiples celdas y elegir cuál ejecutar, o corregir el texto y volver a ejecutar.\n\nAlgunas características importantes del uso de RISE:\n\nSimplifica la generación de material.\nSe mantiene un archivo y no varios archivos para hablar de lo mismo.\nEs fácil de corregir, no se necesita mucho esfuerzo (similar a una PPT).\n\nEn esta sesión, se muestra un ejemplo de cómo crear una presentación con RISE.\n\nNota: Puede encontrar los códigos de este ejemplo en el siguiente repositorio. Por otro lado, puede revisar el siguente link para ver la compilación con GitLab CI/CD.\n\n\n\n\n\n\nPara instalar RISE, necesitará usar la línea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge rise\nDe lo contrario, puede instalar con pip:\npip install RISE\n\nNota: No interactuarás directamente con RISE. En su lugar, podrá acceder a él a través de Jupyter Notebooks.\n\n\n\n\n\nPara crear una presentación, deberá iniciar Jupyter Notebooks y abrir un nuevo notebook (tenga en cuenta que debe hacer esto después de haber instalado RISE). Una vez que tenga un Jupyter Notebook nuevo, deberá habilitar la presentación de diapositivas. Puede hacer esto haciendo lo siguiente:\n\nHaga clic en “Ver” en la barra de herramientas de Jupyter\nColoca el cursor sobre “Barra de herramientas de celda” en el menú “Ver”\nHaga clic en “Presentación de diapositivas” en el menú “Barra de herramientas de celda”\n\n\n\n\nEn este punto, debería tener una barra de herramientas de celda con un menú desplegable en el lado derecho: \nDebería ver seis opciones aquí. Este menú desplegable y sus opciones determinan cómo encaja cada celda en la presentación. Las opciones y sus descripciones se encuentran a continuación:\n\nslide: indica que la celda seleccionada debe ser el comienzo de una nueva diapositiva.\nsub-slide -: indica que la celda seleccionada debe ser el comienzo de una nueva sub-diapositiva, que aparece en un nuevo marco debajo de la diapositiva anterior.\nfragment: indica que la celda seleccionada debe aparecer como una compilación de la diapositiva anterior.\nskip: indica que la celda seleccionada debe omitirse y no ser parte de la presentación de diapositivas.\nnotes: indica que la celda seleccionada debe ser solo notas del presentador.\n- -: indica que la celda seleccionada debe seguir el comportamiento de la celda anterior, lo cual es útil cuando una celda de rebaja y una celda de código deben aparecer simultáneamente.\n\nCada una de estas opciones puede incluir código Python o código Markdown/HTML/LaTeX como un Jupyter Notebook tradicional.\n\n\n\nUna vez que se han utilizado las celdas para crear material para la presentación, la presentación se puede ver directamente desde el notebook.\nHay dos opciones para ver la presentación de diapositivas:\n\nUsar el acceso directo OPTION + R shortcut (ALT + R on Windows) para ingresar y salir del modo de presentación desde dentro de la computadora portátil\nAl hacer clic en el botón “Modo de presentación” de la computadora portátil, esto solo aparecerá si ha instalado RISE.\n\n\nDespués de ingresar al modo de presentación, debería ver una pantalla similar a esta:\n\n\n\n\nSi bien puede ser tentador usar las teclas &lt;- y -&gt; para cambiar las diapositivas en la presentación, esto no funcionará por completo: omitirá las celdas marcadas como sub-slides. En su lugar, se debe usar ESPACIO para mover la presentación de diapositivas hacia adelante y MAYÚS + ESPACIO para mover la presentación de diapositivas hacia atrás.\nHay muchos otros atajos de teclado a los que se puede acceder dentro de la presentación haciendo clic en el signo de interrogación (?) en la esquina inferior izquierda.\n\n\n\nUna de las mejores cosas de RISE es que funciona en una sesión de Python en vivo, lo que significa que puede editar y ejecutar código mientras se ejecuta la presentación.\n\n\n\n\nPuedes exportar tu presentación desplegando la opción: File -&gt; Download as.\n\nNota: Para poder descargar en formato .pdf, necesita tener instalado pandoc.\n\n\n\n\n\n\nRISE - Documentation\nCreating Interactive Slideshows in Jupyter Notebooks"
  },
  {
    "objectID": "posts/2021/2021-08-05-rise.html#introducción",
    "href": "posts/2021/2021-08-05-rise.html#introducción",
    "title": "RISE",
    "section": "",
    "text": "RISE es una extensión a los jupyter notebooks que permite transformar tus notebooks en presentaciones interactivas.\nToda las celdas pueden editarse y ejecutarse directamente, durante la presentación. Esto es práctico si necesitas corregir un error en una celda de texto. Más importante aún, puedes ejecutar código directamente en el kernel. En una misma diapositiva puedes tener múltiples celdas y elegir cuál ejecutar, o corregir el texto y volver a ejecutar.\n\nAlgunas características importantes del uso de RISE:\n\nSimplifica la generación de material.\nSe mantiene un archivo y no varios archivos para hablar de lo mismo.\nEs fácil de corregir, no se necesita mucho esfuerzo (similar a una PPT).\n\nEn esta sesión, se muestra un ejemplo de cómo crear una presentación con RISE.\n\nNota: Puede encontrar los códigos de este ejemplo en el siguiente repositorio. Por otro lado, puede revisar el siguente link para ver la compilación con GitLab CI/CD."
  },
  {
    "objectID": "posts/2021/2021-08-05-rise.html#primeros-pasos",
    "href": "posts/2021/2021-08-05-rise.html#primeros-pasos",
    "title": "RISE",
    "section": "",
    "text": "Para instalar RISE, necesitará usar la línea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge rise\nDe lo contrario, puede instalar con pip:\npip install RISE\n\nNota: No interactuarás directamente con RISE. En su lugar, podrá acceder a él a través de Jupyter Notebooks."
  },
  {
    "objectID": "posts/2021/2021-08-05-rise.html#habilitación-del-modo-de-presentación",
    "href": "posts/2021/2021-08-05-rise.html#habilitación-del-modo-de-presentación",
    "title": "RISE",
    "section": "",
    "text": "Para crear una presentación, deberá iniciar Jupyter Notebooks y abrir un nuevo notebook (tenga en cuenta que debe hacer esto después de haber instalado RISE). Una vez que tenga un Jupyter Notebook nuevo, deberá habilitar la presentación de diapositivas. Puede hacer esto haciendo lo siguiente:\n\nHaga clic en “Ver” en la barra de herramientas de Jupyter\nColoca el cursor sobre “Barra de herramientas de celda” en el menú “Ver”\nHaga clic en “Presentación de diapositivas” en el menú “Barra de herramientas de celda”\n\n\n\n\nEn este punto, debería tener una barra de herramientas de celda con un menú desplegable en el lado derecho: \nDebería ver seis opciones aquí. Este menú desplegable y sus opciones determinan cómo encaja cada celda en la presentación. Las opciones y sus descripciones se encuentran a continuación:\n\nslide: indica que la celda seleccionada debe ser el comienzo de una nueva diapositiva.\nsub-slide -: indica que la celda seleccionada debe ser el comienzo de una nueva sub-diapositiva, que aparece en un nuevo marco debajo de la diapositiva anterior.\nfragment: indica que la celda seleccionada debe aparecer como una compilación de la diapositiva anterior.\nskip: indica que la celda seleccionada debe omitirse y no ser parte de la presentación de diapositivas.\nnotes: indica que la celda seleccionada debe ser solo notas del presentador.\n- -: indica que la celda seleccionada debe seguir el comportamiento de la celda anterior, lo cual es útil cuando una celda de rebaja y una celda de código deben aparecer simultáneamente.\n\nCada una de estas opciones puede incluir código Python o código Markdown/HTML/LaTeX como un Jupyter Notebook tradicional.\n\n\n\nUna vez que se han utilizado las celdas para crear material para la presentación, la presentación se puede ver directamente desde el notebook.\nHay dos opciones para ver la presentación de diapositivas:\n\nUsar el acceso directo OPTION + R shortcut (ALT + R on Windows) para ingresar y salir del modo de presentación desde dentro de la computadora portátil\nAl hacer clic en el botón “Modo de presentación” de la computadora portátil, esto solo aparecerá si ha instalado RISE.\n\n\nDespués de ingresar al modo de presentación, debería ver una pantalla similar a esta:\n\n\n\n\nSi bien puede ser tentador usar las teclas &lt;- y -&gt; para cambiar las diapositivas en la presentación, esto no funcionará por completo: omitirá las celdas marcadas como sub-slides. En su lugar, se debe usar ESPACIO para mover la presentación de diapositivas hacia adelante y MAYÚS + ESPACIO para mover la presentación de diapositivas hacia atrás.\nHay muchos otros atajos de teclado a los que se puede acceder dentro de la presentación haciendo clic en el signo de interrogación (?) en la esquina inferior izquierda.\n\n\n\nUna de las mejores cosas de RISE es que funciona en una sesión de Python en vivo, lo que significa que puede editar y ejecutar código mientras se ejecuta la presentación.\n\n\n\n\nPuedes exportar tu presentación desplegando la opción: File -&gt; Download as.\n\nNota: Para poder descargar en formato .pdf, necesita tener instalado pandoc."
  },
  {
    "objectID": "posts/2021/2021-08-05-rise.html#referencias",
    "href": "posts/2021/2021-08-05-rise.html#referencias",
    "title": "RISE",
    "section": "",
    "text": "RISE - Documentation\nCreating Interactive Slideshows in Jupyter Notebooks"
  },
  {
    "objectID": "posts/2023/gitlab_pdf.html",
    "href": "posts/2023/gitlab_pdf.html",
    "title": "Gitlab PDF",
    "section": "",
    "text": "GitLab CI/CD es una potente herramienta que permite automatizar y gestionar el ciclo de vida de las aplicaciones de software.\nCI (Integración Continua) y CD (Entrega Continua) son prácticas esenciales en el desarrollo de software moderno que buscan mejorar la calidad del código, aumentar la eficiencia y reducir los errores. GitLab CI/CD se integra de manera nativa en el flujo de trabajo de GitLab, lo que lo convierte en una opción atractiva para equipos de desarrollo.\n\nCI (Integración Continua): Es el proceso de integrar cambios de código frecuentes en un repositorio compartido. Esto implica la ejecución automática de pruebas y análisis de calidad cada vez que se envía código. El objetivo es identificar y corregir problemas de manera temprana en el ciclo de desarrollo.\nCD (Entrega Continua): Una vez que las pruebas de CI se han superado con éxito, el código se considera apto para su implementación en entornos de producción o de pruebas. El objetivo es entregar de manera eficiente y confiable el software a los usuarios finales.\n\n\n\n\nAntes de profundizar en la generación de archivos PDF, es importante comprender el concepto de “artefactos” en GitLab CI/CD. Los artefactos son archivos o conjuntos de archivos generados como resultado de una ejecución exitosa de un pipeline.\nEstos artefactos se almacenan en GitLab y se pueden utilizar posteriormente en otros trabajos o pipelines.\nEn el contexto de la generación de archivos PDF, los artefactos son esenciales porque permiten que los archivos PDF generados en un trabajo se conserven y utilicen en otros trabajos o etapas del pipeline.\n\n\n\n\nLa generación de archivos PDF como parte de su proceso de CI/CD puede ser útil en varios escenarios, como la creación de informes automatizados, la generación de documentación técnica o la producción de facturas en línea.\nA continuación, detallaremos cómo lograrlo utilizando GitLab CI/CD:\n\nNota: Tomaremos como referencia el siguiente repositorio.\n\n\n\nAntes de comenzar, asegúrese de que su proyecto de GitLab esté configurado correctamente y tenga acceso a GitLab CI/CD. También debe tener un archivo de código fuente que desee convertir en un archivo PDF.\nAsegúrese de que cualquier dependencia necesaria esté especificada en su archivo de configuración de CI/CD.\n\n\n\n\nCree un script que sea capaz de generar el archivo PDF a partir de sus datos de entrada.\nEste script debería tomar los datos relevantes y formatearlos en un archivo PDF.\n\n\n\n\nEn su repositorio de GitLab, cree un archivo llamado .gitlab-ci.yml si aún no lo ha hecho.\nEste archivo contiene la configuración de su pipeline.\nAquí hay un ejemplo de cómo podría verse:\nstages:\n  - pdf\n\ngenerate_pdf:\n  stage: pdf\n  image: aergus/latex\n  script:\n    - latexmk -pdf **/*.tex\n\n  artifacts:\n    paths:\n      - ./*.pdf\nEn este ejemplo:\nstages:\n  - pdf\n\nstages: Esta sección define las etapas (stages). En este caso, solo se define una etapa llamada “pdf”. Las etapas son divisiones lógicas en el pipeline que agrupan trabajos relacionados. En este caso, el pipeline tiene una sola etapa llamada “pdf”.\n\ngenerate_pdf:\n  stage: pdf\n  image: aergus/latex\n  script:\n    - latexmk -pdf **/*.tex\n\ngenerate_pdf: Esta sección define un trabajo (job) llamado “generate_pdf”. Un trabajo es una unidad de ejecución en el pipeline. Aquí está el desglose de esta sección:\n\nstage: pdf: Esta línea especifica que este trabajo pertenece a la etapa “pdf” definida previamente. En otras palabras, este trabajo se ejecutará en la etapa “pdf” del pipeline.\nimage: aergus/latex: Esta línea especifica la imagen Docker que se utilizará para ejecutar este trabajo. En este caso, se utiliza la imagen “aergus/latex”, que contiene un entorno LaTeX para compilar documentos PDF. Esta imagen es esencial para compilar archivos LaTeX en archivos PDF.\nscript: Aquí se definen los comandos que se ejecutarán en el trabajo. En este caso, se utiliza el comando “latexmk -pdf **/*.tex”. Este comando utiliza “latexmk” para compilar todos los archivos “.tex” en el proyecto en archivos PDF. El uso de **/*.tex significa que buscará archivos “.tex” en todos los subdirectorios del proyecto.\n\n\nartifacts:\n  paths:\n    - ./*.pdf\n\nartifacts: Esta sección especifica qué archivos deben considerarse artefactos y, por lo tanto, se conservarán después de una ejecución exitosa del trabajo. Aquí está el desglose de esta sección:\n\npaths: ./*.pdf: Esta línea especifica que todos los archivos con extensión “.pdf” en el directorio actual deben considerarse artefactos. Esto significa que los archivos PDF generados como resultado de la ejecución de este trabajo se conservarán y estarán disponibles para su descarga después de el pipeline se haya ejecutado con éxito.\n\n\n\n\n\nCada vez que realice un envío de código (push) o active manualmente el pipeline, GitLab ejecutará el trabajo de generación de PDF. El script generará el archivo PDF y lo almacenará como un artefacto.\n\n\n\n\nUna vez que el pipeline se haya ejecutado con éxito, puede acceder a los archivos PDF generados en GitLab.\nVaya a la página de su proyecto en GitLab, seleccione “CI/CD” y luego “Artefactos”.\nAquí encontrará el archivo PDF generado que puede descargar.\n\n\n\n\nGitLab CI/CD es una herramienta poderosa que puede ayudar en la automatización de una amplia variedad de tareas, incluida la generación de archivos PDF.\nAl comprender cómo utilizar artefactos en GitLab CI/CD y seguir los pasos mencionados anteriormente, puede integrar fácilmente la generación de PDF en su flujo de trabajo de desarrollo, lo que ahorra tiempo y esfuerzo, y garantiza la consistencia y la calidad en la creación de documentos PDF automatizados.\n\n\n\n\nGet started with GitLab CI/CD\nJob artifacts"
  },
  {
    "objectID": "posts/2023/gitlab_pdf.html#artefactos-en-gitlab-cicd",
    "href": "posts/2023/gitlab_pdf.html#artefactos-en-gitlab-cicd",
    "title": "Gitlab PDF",
    "section": "",
    "text": "Antes de profundizar en la generación de archivos PDF, es importante comprender el concepto de “artefactos” en GitLab CI/CD. Los artefactos son archivos o conjuntos de archivos generados como resultado de una ejecución exitosa de un pipeline.\nEstos artefactos se almacenan en GitLab y se pueden utilizar posteriormente en otros trabajos o pipelines.\nEn el contexto de la generación de archivos PDF, los artefactos son esenciales porque permiten que los archivos PDF generados en un trabajo se conserven y utilicen en otros trabajos o etapas del pipeline."
  },
  {
    "objectID": "posts/2023/gitlab_pdf.html#generación-de-archivos-pdf-con-gitlab-cicd",
    "href": "posts/2023/gitlab_pdf.html#generación-de-archivos-pdf-con-gitlab-cicd",
    "title": "Gitlab PDF",
    "section": "",
    "text": "La generación de archivos PDF como parte de su proceso de CI/CD puede ser útil en varios escenarios, como la creación de informes automatizados, la generación de documentación técnica o la producción de facturas en línea.\nA continuación, detallaremos cómo lograrlo utilizando GitLab CI/CD:\n\nNota: Tomaremos como referencia el siguiente repositorio.\n\n\n\nAntes de comenzar, asegúrese de que su proyecto de GitLab esté configurado correctamente y tenga acceso a GitLab CI/CD. También debe tener un archivo de código fuente que desee convertir en un archivo PDF.\nAsegúrese de que cualquier dependencia necesaria esté especificada en su archivo de configuración de CI/CD.\n\n\n\n\nCree un script que sea capaz de generar el archivo PDF a partir de sus datos de entrada.\nEste script debería tomar los datos relevantes y formatearlos en un archivo PDF.\n\n\n\n\nEn su repositorio de GitLab, cree un archivo llamado .gitlab-ci.yml si aún no lo ha hecho.\nEste archivo contiene la configuración de su pipeline.\nAquí hay un ejemplo de cómo podría verse:\nstages:\n  - pdf\n\ngenerate_pdf:\n  stage: pdf\n  image: aergus/latex\n  script:\n    - latexmk -pdf **/*.tex\n\n  artifacts:\n    paths:\n      - ./*.pdf\nEn este ejemplo:\nstages:\n  - pdf\n\nstages: Esta sección define las etapas (stages). En este caso, solo se define una etapa llamada “pdf”. Las etapas son divisiones lógicas en el pipeline que agrupan trabajos relacionados. En este caso, el pipeline tiene una sola etapa llamada “pdf”.\n\ngenerate_pdf:\n  stage: pdf\n  image: aergus/latex\n  script:\n    - latexmk -pdf **/*.tex\n\ngenerate_pdf: Esta sección define un trabajo (job) llamado “generate_pdf”. Un trabajo es una unidad de ejecución en el pipeline. Aquí está el desglose de esta sección:\n\nstage: pdf: Esta línea especifica que este trabajo pertenece a la etapa “pdf” definida previamente. En otras palabras, este trabajo se ejecutará en la etapa “pdf” del pipeline.\nimage: aergus/latex: Esta línea especifica la imagen Docker que se utilizará para ejecutar este trabajo. En este caso, se utiliza la imagen “aergus/latex”, que contiene un entorno LaTeX para compilar documentos PDF. Esta imagen es esencial para compilar archivos LaTeX en archivos PDF.\nscript: Aquí se definen los comandos que se ejecutarán en el trabajo. En este caso, se utiliza el comando “latexmk -pdf **/*.tex”. Este comando utiliza “latexmk” para compilar todos los archivos “.tex” en el proyecto en archivos PDF. El uso de **/*.tex significa que buscará archivos “.tex” en todos los subdirectorios del proyecto.\n\n\nartifacts:\n  paths:\n    - ./*.pdf\n\nartifacts: Esta sección especifica qué archivos deben considerarse artefactos y, por lo tanto, se conservarán después de una ejecución exitosa del trabajo. Aquí está el desglose de esta sección:\n\npaths: ./*.pdf: Esta línea especifica que todos los archivos con extensión “.pdf” en el directorio actual deben considerarse artefactos. Esto significa que los archivos PDF generados como resultado de la ejecución de este trabajo se conservarán y estarán disponibles para su descarga después de el pipeline se haya ejecutado con éxito.\n\n\n\n\n\nCada vez que realice un envío de código (push) o active manualmente el pipeline, GitLab ejecutará el trabajo de generación de PDF. El script generará el archivo PDF y lo almacenará como un artefacto.\n\n\n\n\nUna vez que el pipeline se haya ejecutado con éxito, puede acceder a los archivos PDF generados en GitLab.\nVaya a la página de su proyecto en GitLab, seleccione “CI/CD” y luego “Artefactos”.\nAquí encontrará el archivo PDF generado que puede descargar."
  },
  {
    "objectID": "posts/2023/gitlab_pdf.html#conclusiones",
    "href": "posts/2023/gitlab_pdf.html#conclusiones",
    "title": "Gitlab PDF",
    "section": "",
    "text": "GitLab CI/CD es una herramienta poderosa que puede ayudar en la automatización de una amplia variedad de tareas, incluida la generación de archivos PDF.\nAl comprender cómo utilizar artefactos en GitLab CI/CD y seguir los pasos mencionados anteriormente, puede integrar fácilmente la generación de PDF en su flujo de trabajo de desarrollo, lo que ahorra tiempo y esfuerzo, y garantiza la consistencia y la calidad en la creación de documentos PDF automatizados."
  },
  {
    "objectID": "posts/2023/gitlab_pdf.html#referencias",
    "href": "posts/2023/gitlab_pdf.html#referencias",
    "title": "Gitlab PDF",
    "section": "",
    "text": "Get started with GitLab CI/CD\nJob artifacts"
  },
  {
    "objectID": "posts/2024/github_actions.html",
    "href": "posts/2024/github_actions.html",
    "title": "Github Actions",
    "section": "",
    "text": "En el vertiginoso mundo del desarrollo de software, la capacidad de implementar cambios de forma rápida y fiable se ha vuelto crucial para mantenerse competitivo. La Integración Continua (CI) y la Entrega Continua (CD) son prácticas fundamentales que permiten a los equipos de desarrollo automatizar y optimizar el ciclo completo de construcción, pruebas y despliegue de aplicaciones.\nEn este artículo, exploraremos los conceptos de CI/CD y su importancia para los equipos de desarrollo, centrándonos en GitHub Actions y GitHub Pages. Además, aprenderemos cómo aplicar estos conceptos en la generación de documentación y sitios web estáticos mediante un ejemplo práctico.\n\n🔑 Nota: Para seguir este tutorial, es necesario disponer de una Cuenta en GitHub. Además, se recomienda actualizar tu foto de perfil y tu nombre de usuario.\n\n\n\n\n\nLa Integración Continua (CI) es un enfoque en el que los desarrolladores integran su código en un repositorio compartido de manera frecuente, desencadenando automáticamente un proceso de construcción y pruebas para verificar la calidad del código.\nPor otro lado, la Entrega Continua (CD) es una extensión de la CI que se enfoca en automatizar la entrega de software probado y validado a entornos de producción o preproducción de manera rápida y confiable.\nBeneficios de CI/CD\n\nMayor Calidad del Software: La detección temprana de errores y la automatización de pruebas garantizan una mayor calidad del código.\nEntrega Más Rápida: La automatización de los procesos de construcción y despliegue acelera el tiempo de lanzamiento al mercado.\nMenor Riesgo: La entrega frecuente y confiable reduce el riesgo de implementaciones fallidas.\nRetroalimentación Instantánea: Los desarrolladores reciben retroalimentación inmediata sobre la calidad de su código.\nMayor Colaboración: La integración frecuente fomenta la colaboración entre los miembros del equipo y mejora la transparencia en el proceso de desarrollo.\n\n\n\n\nGitHub Actions es una plataforma de automatización de flujo de trabajo integrada en GitHub que permite a los equipos de desarrollo automatizar todo el ciclo de vida del desarrollo de software, incluyendo la integración continua (CI) y la entrega continua (CD).\nCon GitHub Actions, los equipos pueden definir flujos de trabajo personalizados en archivos YAML dentro de sus repositorios de GitHub, lo que les permite automatizar tareas como la construcción, las pruebas y el despliegue de aplicaciones de manera fácil y flexible.\n\n\n\nA continuación, se muestra un ejemplo básico de un archivo YAML de GitHub Actions para un flujo de trabajo de CI/CD:\nname: CI/CD Pipeline\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout Repository\n      uses: actions/checkout@v2\n\n    - name: Build and Test\n      run: |\n        npm install\n        npm test\n\n    - name: Deploy to Production\n      if: success()\n      run: |\n        npm run build\n        # Comandos para desplegar la aplicación en producción\nEn este ejemplo, el flujo de trabajo se desencadena en cada push al branch “main”.\nEl flujo de trabajo incluye tres pasos:\n\ncheckout del repositorio,\nconstrucción y prueba de la aplicación, y\ndespliegue de la aplicación en producción si las pruebas son exitosas.\n\n\n\n\n\n\n\nGitHub Pages es un servicio de alojamiento web gratuito proporcionado por GitHub que permite a los usuarios crear y publicar sitios web estáticos directamente desde sus repositorios de GitHub.\nCon GitHub Pages, los desarrolladores pueden aprovechar la infraestructura de GitHub para alojar y compartir documentación, sitios web personales, blogs y más. La configuración de GitHub Pages es sencilla, y los sitios web se actualizan automáticamente cada vez que se realiza un cambio en el repositorio, lo que facilita la publicación de contenido nuevo y actualizado.\n\n\n\nPara habilitar GitHub Pages para un repositorio, sigue estos pasos:\n\nVe a la pestaña “Settings” (Configuración) de tu repositorio en GitHub.\nDesplázate hacia abajo hasta la sección “GitHub Pages”.\nSelecciona la rama y la carpeta del repositorio que deseas utilizar para publicar tu sitio web.\nHaz clic en “Save” (Guardar).\n\n\n\n\n\nFacilidad de Uso: Configuración simple y actualizaciones automáticas hacen que sea fácil publicar y mantener sitios web estáticos.\nGratuito y Sin Limitaciones: GitHub Pages es un servicio gratuito y no tiene limitaciones en cuanto a la cantidad de sitios web que puedes alojar.\nIntegración con GitHub: GitHub Pages está integrado directamente en GitHub, lo que facilita la administración y la colaboración en el contenido del sitio web.\n\n\n\n\n\nEl repositorio Online CV tiene como propósito facilitar la creación de tu propio currículum vitae en línea utilizando mkdocs (python).\nEl objetivo principal es utilizar GitHub Actions y GitHub Pages para mostrar tu CV de manera online. Sería ideal que los usuarios clonaran el repositorio utilizando la opción fork o Use this template para poder personalizar su propio currículum vitae.\n\n\n🔑 Nota:\n\nMás información sobre forks.\nMás información sobre template.\n\n\n\n\n\n\n.github/workflows: Contiene archivos YAML que definen flujos de trabajo automáticos con GitHub Actions. Estos flujos especifican acciones ante eventos específicos como confirmaciones o solicitudes de extracción.\ndocs: Es el lugar para la documentación del proyecto, usualmente en formatos como Markdown o HTML. Incluye guías de uso, contribución y normas de codificación.\n.gitignore: Define qué archivos y carpetas Git debe ignorar. Evita que archivos no deseados se incluyan en los commits o ramas, como archivos de configuración local o dependencias.\nLICENSE: Contiene los términos legales de distribución del proyecto, estableciendo los derechos y restricciones para los usuarios. Tipos comunes de licencias son MIT, GPL y Apache.\nREADME.md: Un archivo Markdown que ofrece información básica sobre el proyecto, incluyendo su propósito, instrucciones de instalación y cómo contribuir. Es el primer punto de contacto para desarrolladores y usuarios.\nmkdocs.yml: Configura MkDocs, una herramienta para generar documentación estática desde archivos Markdown. Define la estructura y ajustes del proyecto, como los temas y archivos de documentación.\npyproject.toml: Un archivo de configuración en proyectos Python según PEP 518. Define las dependencias del proyecto, versiones de Python compatibles y otras configuraciones usando TOML.\n\n\n🔑 Nota: Aunque la estructura para crear otros sitios estáticos con diferentes lenguajes de programación puede variar según los requisitos del proyecto, la lógica para ejecutar GitHub Actions sigue siendo la misma. Esto significa que puedes adaptar estos pasos a tus necesidades específicas, independientemente del lenguaje o la tecnología que estés utilizando.\n\n\n\n\nEn la carpeta .github/workflows existe el archivo documentation.yml, que gatilla el pipeline cada vez que se realiza un push.\nname: documentation\non: [push]\njobs:\n  Pages:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.10.x ]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Install dependencies\n        run: pip install poetry\n      - name: Activate venv\n        run: poetry install\n      - name: Build the book\n        run: poetry run mkdocs build --site-dir public\n      - name: GitHub Pages action\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./public\n\nEn primer lugar, se especifica que el trabajo se ejecutará en la plataforma Ubuntu más reciente disponible en GitHub Actions.\nSe utiliza una estrategia de matriz para ejecutar el trabajo en diferentes versiones de Python. En este caso, se ejecutará en la versión 3.10.x.\nLos pasos del trabajo comienzan clonando el repositorio utilizando la acción predefinida actions/checkout@v2.\nLuego, se configura un entorno Python utilizando la acción actions/setup-python@v2, asegurándose de que la versión coincida con la especificada en la matriz.\nA continuación, se instala la herramienta de gestión de dependencias Poetry mediante el comando pip install poetry.\nUna vez instaladas las dependencias de Poetry, se ejecuta el comando poetry install para instalar las dependencias del proyecto.\nDespués, se activa el entorno virtual creado por Poetry ejecutando poetry run.\nSe genera la documentación del proyecto utilizando MkDocs con el comando mkdocs build --site-dir public.\nFinalmente, se implementa la documentación en GitHub Pages utilizando la acción de terceros peaceiris/actions-gh-pages@v3. Se proporciona el token de acceso de GitHub almacenado en la variable secreta GITHUB_TOKEN y se especifica el directorio de publicación de la documentación como ./public.\n\nActivando Github Actions\n\nDirígete a Setting -&gt; Actions -&gt; General:\n\nEn Workflow permissions, seleccionar Read and write permissions y Allow GitHub Actions to create and approve pull requests, luego guarda los cambios en Save.\n\n\n\n🔑 Nota: El pipeline se activará automáticamente al realizar tu primer push a la rama main. Asegúrate de tener GitHub Actions activado para que funcione correctamente. Para obtener más detalles, consulta la Documentación Oficial de GitHub Actions.\n\n\n\n\n\nDirígete a Setting -&gt; Pages:\n\nIr Branch, seleccionar gh-pages, luego guarda los cambios enSave.\n\n\n\n🔑 Nota : El pipeline se activará automáticamente al realizar tu primer push a la rama main. Una vez finalizado, podrás llevar a cabo los pasos mencionados anteriormente. Para obtener más detalles, consulta la Documentación Oficial de GitHub Pages.\n\n\n\n\nPara verificar que todo esté funcionando correctamente, dirígete a Actions y deberías ver lo siguiente:\n\n\n\nCaptura de pantalla de GitHub Actions\n\n\nAquí tienes una descripción de lo que ves:\n\nonline cv - update april: Representa el commit que desencadenó el pipeline de GitHub Actions.\npages build and deployment: Es el pipeline de trabajo que se ejecuta una vez que el pipeline del commit esté completo.\n\n\n🔑 Nota: Si necesitas más detalles sobre los pipelines, simplemente haz clic en cada uno de ellos. También puedes acceder a los pipelines de trabajo del repositorio online-cv/actions para obtener más información.\n\n\n\n\nUna vez completado el proceso, dirígete a tu proyecto. En la parte derecha, donde se muestra la descripción del proyecto, encontrarás el icono de un engranaje ⚙️.\nHaz clic en él y verás una imagen similar a esta:\n\n\n\nConfiguración de GitHub Pages\n\n\nSelecciona la opción Use your GitHub Pages website y verás automáticamente debajo de la descripción el enlace hacia la documentación generada por GitHub Actions y GitHub Pages.\n\n🔑 Nota: La documentación de este proyecto está disponible en el siguiente enlace: fralfaro.github.io/online-cv/\n\n\n\n\n\nEn conclusión, hemos implementado con éxito GitHub Actions y GitHub Pages en nuestro proyecto, lo que ha mejorado significativamente su gestión y visibilidad:\n\nGitHub Actions: Configuramos flujos de trabajo automatizados que se activan en respuesta a eventos específicos, como los cambios en el repositorio. Estos flujos de trabajo automatizan tareas como la generación de la documentación del proyecto utilizando MkDocs y la implementación de esta documentación en GitHub Pages.\nGitHub Pages: Configuramos GitHub Pages para desplegar automáticamente la documentación generada por nuestros flujos de trabajo de GitHub Actions. Esto proporciona un acceso fácil y conveniente a la documentación del proyecto para los colaboradores y usuarios potenciales.\n\nEn conjunto, estas herramientas nos permiten mantener la documentación del proyecto actualizada de manera automática y proporcionar un acceso rápido y sencillo a esta documentación a través de GitHub Pages. Esto mejora la colaboración y la visibilidad del proyecto, facilitando su uso y contribución para todos los involucrados."
  },
  {
    "objectID": "posts/2024/github_actions.html#github-actions",
    "href": "posts/2024/github_actions.html#github-actions",
    "title": "Github Actions",
    "section": "",
    "text": "La Integración Continua (CI) es un enfoque en el que los desarrolladores integran su código en un repositorio compartido de manera frecuente, desencadenando automáticamente un proceso de construcción y pruebas para verificar la calidad del código.\nPor otro lado, la Entrega Continua (CD) es una extensión de la CI que se enfoca en automatizar la entrega de software probado y validado a entornos de producción o preproducción de manera rápida y confiable.\nBeneficios de CI/CD\n\nMayor Calidad del Software: La detección temprana de errores y la automatización de pruebas garantizan una mayor calidad del código.\nEntrega Más Rápida: La automatización de los procesos de construcción y despliegue acelera el tiempo de lanzamiento al mercado.\nMenor Riesgo: La entrega frecuente y confiable reduce el riesgo de implementaciones fallidas.\nRetroalimentación Instantánea: Los desarrolladores reciben retroalimentación inmediata sobre la calidad de su código.\nMayor Colaboración: La integración frecuente fomenta la colaboración entre los miembros del equipo y mejora la transparencia en el proceso de desarrollo.\n\n\n\n\nGitHub Actions es una plataforma de automatización de flujo de trabajo integrada en GitHub que permite a los equipos de desarrollo automatizar todo el ciclo de vida del desarrollo de software, incluyendo la integración continua (CI) y la entrega continua (CD).\nCon GitHub Actions, los equipos pueden definir flujos de trabajo personalizados en archivos YAML dentro de sus repositorios de GitHub, lo que les permite automatizar tareas como la construcción, las pruebas y el despliegue de aplicaciones de manera fácil y flexible.\n\n\n\nA continuación, se muestra un ejemplo básico de un archivo YAML de GitHub Actions para un flujo de trabajo de CI/CD:\nname: CI/CD Pipeline\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout Repository\n      uses: actions/checkout@v2\n\n    - name: Build and Test\n      run: |\n        npm install\n        npm test\n\n    - name: Deploy to Production\n      if: success()\n      run: |\n        npm run build\n        # Comandos para desplegar la aplicación en producción\nEn este ejemplo, el flujo de trabajo se desencadena en cada push al branch “main”.\nEl flujo de trabajo incluye tres pasos:\n\ncheckout del repositorio,\nconstrucción y prueba de la aplicación, y\ndespliegue de la aplicación en producción si las pruebas son exitosas."
  },
  {
    "objectID": "posts/2024/github_actions.html#github-pages",
    "href": "posts/2024/github_actions.html#github-pages",
    "title": "Github Actions",
    "section": "",
    "text": "GitHub Pages es un servicio de alojamiento web gratuito proporcionado por GitHub que permite a los usuarios crear y publicar sitios web estáticos directamente desde sus repositorios de GitHub.\nCon GitHub Pages, los desarrolladores pueden aprovechar la infraestructura de GitHub para alojar y compartir documentación, sitios web personales, blogs y más. La configuración de GitHub Pages es sencilla, y los sitios web se actualizan automáticamente cada vez que se realiza un cambio en el repositorio, lo que facilita la publicación de contenido nuevo y actualizado.\n\n\n\nPara habilitar GitHub Pages para un repositorio, sigue estos pasos:\n\nVe a la pestaña “Settings” (Configuración) de tu repositorio en GitHub.\nDesplázate hacia abajo hasta la sección “GitHub Pages”.\nSelecciona la rama y la carpeta del repositorio que deseas utilizar para publicar tu sitio web.\nHaz clic en “Save” (Guardar).\n\n\n\n\n\nFacilidad de Uso: Configuración simple y actualizaciones automáticas hacen que sea fácil publicar y mantener sitios web estáticos.\nGratuito y Sin Limitaciones: GitHub Pages es un servicio gratuito y no tiene limitaciones en cuanto a la cantidad de sitios web que puedes alojar.\nIntegración con GitHub: GitHub Pages está integrado directamente en GitHub, lo que facilita la administración y la colaboración en el contenido del sitio web."
  },
  {
    "objectID": "posts/2024/github_actions.html#ejemplo-práctico",
    "href": "posts/2024/github_actions.html#ejemplo-práctico",
    "title": "Github Actions",
    "section": "",
    "text": "El repositorio Online CV tiene como propósito facilitar la creación de tu propio currículum vitae en línea utilizando mkdocs (python).\nEl objetivo principal es utilizar GitHub Actions y GitHub Pages para mostrar tu CV de manera online. Sería ideal que los usuarios clonaran el repositorio utilizando la opción fork o Use this template para poder personalizar su propio currículum vitae.\n\n\n🔑 Nota:\n\nMás información sobre forks.\nMás información sobre template.\n\n\n\n\n\n\n.github/workflows: Contiene archivos YAML que definen flujos de trabajo automáticos con GitHub Actions. Estos flujos especifican acciones ante eventos específicos como confirmaciones o solicitudes de extracción.\ndocs: Es el lugar para la documentación del proyecto, usualmente en formatos como Markdown o HTML. Incluye guías de uso, contribución y normas de codificación.\n.gitignore: Define qué archivos y carpetas Git debe ignorar. Evita que archivos no deseados se incluyan en los commits o ramas, como archivos de configuración local o dependencias.\nLICENSE: Contiene los términos legales de distribución del proyecto, estableciendo los derechos y restricciones para los usuarios. Tipos comunes de licencias son MIT, GPL y Apache.\nREADME.md: Un archivo Markdown que ofrece información básica sobre el proyecto, incluyendo su propósito, instrucciones de instalación y cómo contribuir. Es el primer punto de contacto para desarrolladores y usuarios.\nmkdocs.yml: Configura MkDocs, una herramienta para generar documentación estática desde archivos Markdown. Define la estructura y ajustes del proyecto, como los temas y archivos de documentación.\npyproject.toml: Un archivo de configuración en proyectos Python según PEP 518. Define las dependencias del proyecto, versiones de Python compatibles y otras configuraciones usando TOML.\n\n\n🔑 Nota: Aunque la estructura para crear otros sitios estáticos con diferentes lenguajes de programación puede variar según los requisitos del proyecto, la lógica para ejecutar GitHub Actions sigue siendo la misma. Esto significa que puedes adaptar estos pasos a tus necesidades específicas, independientemente del lenguaje o la tecnología que estés utilizando.\n\n\n\n\nEn la carpeta .github/workflows existe el archivo documentation.yml, que gatilla el pipeline cada vez que se realiza un push.\nname: documentation\non: [push]\njobs:\n  Pages:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.10.x ]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Install dependencies\n        run: pip install poetry\n      - name: Activate venv\n        run: poetry install\n      - name: Build the book\n        run: poetry run mkdocs build --site-dir public\n      - name: GitHub Pages action\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./public\n\nEn primer lugar, se especifica que el trabajo se ejecutará en la plataforma Ubuntu más reciente disponible en GitHub Actions.\nSe utiliza una estrategia de matriz para ejecutar el trabajo en diferentes versiones de Python. En este caso, se ejecutará en la versión 3.10.x.\nLos pasos del trabajo comienzan clonando el repositorio utilizando la acción predefinida actions/checkout@v2.\nLuego, se configura un entorno Python utilizando la acción actions/setup-python@v2, asegurándose de que la versión coincida con la especificada en la matriz.\nA continuación, se instala la herramienta de gestión de dependencias Poetry mediante el comando pip install poetry.\nUna vez instaladas las dependencias de Poetry, se ejecuta el comando poetry install para instalar las dependencias del proyecto.\nDespués, se activa el entorno virtual creado por Poetry ejecutando poetry run.\nSe genera la documentación del proyecto utilizando MkDocs con el comando mkdocs build --site-dir public.\nFinalmente, se implementa la documentación en GitHub Pages utilizando la acción de terceros peaceiris/actions-gh-pages@v3. Se proporciona el token de acceso de GitHub almacenado en la variable secreta GITHUB_TOKEN y se especifica el directorio de publicación de la documentación como ./public.\n\nActivando Github Actions\n\nDirígete a Setting -&gt; Actions -&gt; General:\n\nEn Workflow permissions, seleccionar Read and write permissions y Allow GitHub Actions to create and approve pull requests, luego guarda los cambios en Save.\n\n\n\n🔑 Nota: El pipeline se activará automáticamente al realizar tu primer push a la rama main. Asegúrate de tener GitHub Actions activado para que funcione correctamente. Para obtener más detalles, consulta la Documentación Oficial de GitHub Actions.\n\n\n\n\n\nDirígete a Setting -&gt; Pages:\n\nIr Branch, seleccionar gh-pages, luego guarda los cambios enSave.\n\n\n\n🔑 Nota : El pipeline se activará automáticamente al realizar tu primer push a la rama main. Una vez finalizado, podrás llevar a cabo los pasos mencionados anteriormente. Para obtener más detalles, consulta la Documentación Oficial de GitHub Pages.\n\n\n\n\nPara verificar que todo esté funcionando correctamente, dirígete a Actions y deberías ver lo siguiente:\n\n\n\nCaptura de pantalla de GitHub Actions\n\n\nAquí tienes una descripción de lo que ves:\n\nonline cv - update april: Representa el commit que desencadenó el pipeline de GitHub Actions.\npages build and deployment: Es el pipeline de trabajo que se ejecuta una vez que el pipeline del commit esté completo.\n\n\n🔑 Nota: Si necesitas más detalles sobre los pipelines, simplemente haz clic en cada uno de ellos. También puedes acceder a los pipelines de trabajo del repositorio online-cv/actions para obtener más información.\n\n\n\n\nUna vez completado el proceso, dirígete a tu proyecto. En la parte derecha, donde se muestra la descripción del proyecto, encontrarás el icono de un engranaje ⚙️.\nHaz clic en él y verás una imagen similar a esta:\n\n\n\nConfiguración de GitHub Pages\n\n\nSelecciona la opción Use your GitHub Pages website y verás automáticamente debajo de la descripción el enlace hacia la documentación generada por GitHub Actions y GitHub Pages.\n\n🔑 Nota: La documentación de este proyecto está disponible en el siguiente enlace: fralfaro.github.io/online-cv/"
  },
  {
    "objectID": "posts/2024/github_actions.html#conclusion",
    "href": "posts/2024/github_actions.html#conclusion",
    "title": "Github Actions",
    "section": "",
    "text": "En conclusión, hemos implementado con éxito GitHub Actions y GitHub Pages en nuestro proyecto, lo que ha mejorado significativamente su gestión y visibilidad:\n\nGitHub Actions: Configuramos flujos de trabajo automatizados que se activan en respuesta a eventos específicos, como los cambios en el repositorio. Estos flujos de trabajo automatizan tareas como la generación de la documentación del proyecto utilizando MkDocs y la implementación de esta documentación en GitHub Pages.\nGitHub Pages: Configuramos GitHub Pages para desplegar automáticamente la documentación generada por nuestros flujos de trabajo de GitHub Actions. Esto proporciona un acceso fácil y conveniente a la documentación del proyecto para los colaboradores y usuarios potenciales.\n\nEn conjunto, estas herramientas nos permiten mantener la documentación del proyecto actualizada de manera automática y proporcionar un acceso rápido y sencillo a esta documentación a través de GitHub Pages. Esto mejora la colaboración y la visibilidad del proyecto, facilitando su uso y contribución para todos los involucrados."
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html",
    "href": "posts/2022/2022-03-16-polars.html",
    "title": "Polars",
    "section": "",
    "text": "Polars es una librería de DataFrames increíblemente rápida implementada en Rust utilizando Arrow Columnar Format de Apache como modelo de memoria.\n\nLazy | eager execution\nMulti-threaded\nSIMD (Single Instruction, Multiple Data)\nQuery optimization\nPowerful expression API\nRust | Python\n\nEsta sección tiene como objetivos presentarle Polars a través de ejemplos y comparándolo con otras soluciones.\n\nNota: Si usted no esta familiarizado con la manipulación de datos en Python, se recomienda partir leyendo sobre la librería de Pandas. También, se deja como referencia mi curso de Manipulación de Datos.\n\n\n\n\n\n\nPara instalar Polars, necesitará usar la línea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge polars\nDe lo contrario, puede instalar con pip:\npip install polars\n\nNota: Todos los binarios están preconstruidos para Python v3.6+.\n\n\n\n\n\nPolars es muy rápido y, de hecho, es una de las mejores soluciones disponibles. Tomemos como referencia db-benchmark de h2oai. Esta página tiene como objetivo comparar varias herramientas similares a bases de datos populares en la ciencia de datos de código abierto. Se ejecuta regularmente con las últimas versiones de estos paquetes y se actualiza automáticamente.\nTambién se incluye la sintaxis que se cronometra junto con el tiempo. De esta manera, puede ver de inmediato si está realizando estas tareas o no, y si las diferencias de tiempo le importan o no. Una diferencia de 10x puede ser irrelevante si eso es solo 1s frente a 0,1s en el tamaño de sus datos.\nA modo de ejemplo, veamos algunos ejemplos de performances de distintas librerías para ejecutar distintos tipos de tareas sobre datasets con distintos tamaños. Para el caso de tareas básicas sobre un dataset de 50 GB, Polars supera a librerías espacializadas en distribución de Dataframes como Spark (143 segundos vs 568 segundos). Por otro lado, librerías conocidas en Python como Pandas o Dask se tiene el problema de out of memory.\n\n\n\n\nPolars tiene un poderoso concepto llamado expresiones. Las expresiones polares se pueden usar en varios contextos y son un mapeo funcional de Fn(Series) -&gt; Series, lo que significa que tienen Series como entrada y Series como salida. Al observar esta definición funcional, podemos ver que la salida de un Expr también puede servir como entrada de un Expr.\nEso puede sonar un poco extraño, así que vamos a dar un ejemplo.\nLa siguiente es una expresión:\npl.col(\"foo\").sort().head(2)\nEl fragmento anterior dice seleccionar la columna \"foo\", luego ordenar esta columna y luego tomar los primeros 2 valores de la salida ordenada. El poder de las expresiones es que cada expresión produce una nueva expresión y que se pueden canalizar juntas. Puede ejecutar una expresión pasándola en uno de los contextos de ejecución polares. Aquí ejecutamos dos expresiones ejecutando df.select:\ndf.select([\n     pl.col(\"foo\").sort().head(2),\n     pl.col(\"barra\").filter(pl.col(\"foo\") == 1).sum()\n])\nTodas las expresiones se ejecutan en paralelo. (Tenga en cuenta que dentro de una expresión puede haber más paralelización).\n\n\nEn esta sección veremos algunos ejemplos, pero primero vamos a crear un conjunto de datos:\n\nimport polars as pl\nimport numpy as np\n\n\nnp.random.seed(12)\n\ndf = pl.DataFrame(\n    {\n        \"nrs\": [1, 2, 3, None, 5],\n        \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", None],\n        \"random\": np.random.rand(5),\n        \"groups\": [\"A\", \"A\", \"B\", \"C\", \"B\"],\n    }\n)\nprint(df)\n\nshape: (5, 4)\n┌──────┬───────┬──────────┬────────┐\n│ nrs  ┆ names ┆ random   ┆ groups │\n│ ---  ┆ ---   ┆ ---      ┆ ---    │\n│ i64  ┆ str   ┆ f64      ┆ str    │\n╞══════╪═══════╪══════════╪════════╡\n│ 1    ┆ foo   ┆ 0.154163 ┆ A      │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤\n│ 2    ┆ ham   ┆ 0.74     ┆ A      │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤\n│ 3    ┆ spam  ┆ 0.263315 ┆ B      │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤\n│ null ┆ egg   ┆ 0.533739 ┆ C      │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤\n│ 5    ┆ null  ┆ 0.014575 ┆ B      │\n└──────┴───────┴──────────┴────────┘\n\n\nPuedes hacer mucho con las expresiones, veamos algunos ejemplos:\n\n\nPodemos contar los valores únicos en una columna. Tenga en cuenta que estamos creando el mismo resultado de diferentes maneras. Para no tener nombres de columna duplicados en el DataFrame, usamos una expresión de alias, que cambia el nombre de una expresión.\n\nout = df.select(\n    [\n        pl.col(\"names\").n_unique().alias(\"unique_names_1\"),\n        pl.col(\"names\").unique().count().alias(\"unique_names_2\"),\n    ]\n)\nprint(out)\n\nshape: (1, 2)\n┌────────────────┬────────────────┐\n│ unique_names_1 ┆ unique_names_2 │\n│ ---            ┆ ---            │\n│ u32            ┆ u32            │\n╞════════════════╪════════════════╡\n│ 5              ┆ 5              │\n└────────────────┴────────────────┘\n\n\n\n\n\n\nPodemos hacer varias agregaciones. A continuación mostramos algunas de ellas, pero hay más, como median, mean, first, etc.\n\nout = df.select(\n    [\n        pl.sum(\"random\").alias(\"sum\"),\n        pl.min(\"random\").alias(\"min\"),\n        pl.max(\"random\").alias(\"max\"),\n        pl.col(\"random\").max().alias(\"other_max\"),\n        pl.std(\"random\").alias(\"std dev\"),\n        pl.var(\"random\").alias(\"variance\"),\n    ]\n)\nprint(out)\n\nshape: (1, 6)\n┌──────────┬──────────┬──────┬───────────┬──────────┬──────────┐\n│ sum      ┆ min      ┆ max  ┆ other_max ┆ std dev  ┆ variance │\n│ ---      ┆ ---      ┆ ---  ┆ ---       ┆ ---      ┆ ---      │\n│ f64      ┆ f64      ┆ f64  ┆ f64       ┆ f64      ┆ f64      │\n╞══════════╪══════════╪══════╪═══════════╪══════════╪══════════╡\n│ 1.705842 ┆ 0.014575 ┆ 0.74 ┆ 0.74      ┆ 0.293209 ┆ 0.085971 │\n└──────────┴──────────┴──────┴───────────┴──────────┴──────────┘\n\n\n\n\n\nTambién podemos hacer cosas bastante complejas. En el siguiente fragmento, contamos todos los nombres que terminan con la cadena \"am\".\n\nout = df.select(\n    [\n        pl.col(\"names\").filter(pl.col(\"names\").str.contains(r\"am$\")).count(),\n    ]\n)\nprint(out)\n\nshape: (1, 1)\n┌───────┐\n│ names │\n│ ---   │\n│ u32   │\n╞═══════╡\n│ 2     │\n└───────┘\n\n\n\n\n\nEn el ejemplo a continuación, usamos un condicional para crear una nueva expresión when -&gt; then -&gt; otherwise.\nLa función when() requiere una expresión de predicado (y, por lo tanto, conduce a una serie booleana), luego espera una expresión que se usará en caso de que el predicado se evalúe como verdadero y, de lo contrario, espera una expresión que se usará en caso de que el predicado se evalúe.\nTenga en cuenta que puede pasar cualquier expresión, o simplemente expresiones base como pl.col(\"foo\"), pl.lit(3), pl.lit(\"bar\"), etc.\nFinalmente, multiplicamos esto con el resultado de una expresión de suma.\n\nout = df.select(\n    [\n        pl.when(pl.col(\"random\") &gt; 0.5).then(0).otherwise(pl.col(\"random\")) * pl.sum(\"nrs\"),\n    ]\n)\nprint(out)\n\nshape: (5, 1)\n┌──────────┐\n│ literal  │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 1.695791 │\n├╌╌╌╌╌╌╌╌╌╌┤\n│ 0.0      │\n├╌╌╌╌╌╌╌╌╌╌┤\n│ 2.896465 │\n├╌╌╌╌╌╌╌╌╌╌┤\n│ 0.0      │\n├╌╌╌╌╌╌╌╌╌╌┤\n│ 0.160325 │\n└──────────┘\n\n\n\n\n\nUna expresión polar también puede hacer un GROUPBY, AGGREGATION y JOIN implícitos en una sola expresión.\nEn los ejemplos a continuación, hacemos un GROUPBY sobre \"groups\" y AGREGATE SUM de \"random\", y en la siguiente expresión GROUPBY OVER \"names\" y AGREGATE una lista de \"random\". Estas funciones de ventana se pueden combinar con otras expresiones y son una forma eficaz de determinar estadísticas de grupo. Vea más expresiones en el siguiente link.\n\nout = df[\n    [\n        pl.col(\"*\"),  # select all\n        pl.col(\"random\").sum().over(\"groups\").alias(\"sum[random]/groups\"),\n        pl.col(\"random\").list().over(\"names\").alias(\"random/name\"),\n    ]\n]\nprint(out)\n\nshape: (5, 6)\n┌──────┬───────┬──────────┬────────┬────────────────────┬─────────────┐\n│ nrs  ┆ names ┆ random   ┆ groups ┆ sum[random]/groups ┆ random/name │\n│ ---  ┆ ---   ┆ ---      ┆ ---    ┆ ---                ┆ ---         │\n│ i64  ┆ str   ┆ f64      ┆ str    ┆ f64                ┆ list [f64]  │\n╞══════╪═══════╪══════════╪════════╪════════════════════╪═════════════╡\n│ 1    ┆ foo   ┆ 0.154163 ┆ A      ┆ 0.894213           ┆ [0.154163]  │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ 2    ┆ ham   ┆ 0.74     ┆ A      ┆ 0.894213           ┆ [0.74]      │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ 3    ┆ spam  ┆ 0.263315 ┆ B      ┆ 0.2778             ┆ [0.263315]  │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ null ┆ egg   ┆ 0.533739 ┆ C      ┆ 0.533739           ┆ [0.533739]  │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ 5    ┆ null  ┆ 0.014575 ┆ B      ┆ 0.2778             ┆ [0.014575]  │\n└──────┴───────┴──────────┴────────┴────────────────────┴─────────────┘\n\n\n\n\n\n\n\n\nUna de las formas más eficientes de procesar datos tabulares es paralelizar su procesamiento a través del enfoque “dividir-aplicar-combinar”. Esta operación es el núcleo de la implementación del agrupamiento de Polars, lo que le permite lograr operaciones ultrarrápidas. Más específicamente, las fases de “división” y “aplicación” se ejecutan de forma multiproceso.\nUna operación de agrupación simple se toma a continuación como ejemplo para ilustrar este enfoque:\n\nPara las operaciones hash realizadas durante la fase de “división”, Polars utiliza un enfoque sin bloqueo de subprocesos múltiples que se ilustra en el siguiente esquema:\n\n¡Esta paralelización permite que las operaciones de agrupación y unión (por ejemplo) sean increíblemente rápidas!\n\n\n\nTodos hemos escuchado que Python es lento y “no escala”. Además de la sobrecarga de ejecutar el código de bytes “lento”, Python debe permanecer dentro de las restricciones del Global interpreter lock (GIL). Esto significa que si se usa la operación lambda o una función de Python personalizada para aplicar durante una fase de paralelización, la velocidad de Polars se limita al ejecutar el código de Python, lo que evita que varios subprocesos ejecuten la función.\nTodo esto se siente terriblemente limitante, especialmente porque a menudo necesitamos esos lambda en un paso .groupby(), por ejemplo. Este enfoque aún es compatible con Polars, pero teniendo en cuenta el código de bytes Y el precio GIL deben pagarse.\nPara mitigar esto, Polars implementa una poderosa sintaxis definida no solo en su lazy, sino también en su uso eager.\n\n\n\nEn la introducción de la página anterior, discutimos que el uso de funciones personalizadas de Python eliminaba la paralelización y que podemos usar las expresiones de la API diferida para mitigar esto. Echemos un vistazo a lo que eso significa.\nComencemos con el conjunto de datos simple del congreso de EE. UU.\n\nimport polars as pl\n\ndataset = pl.read_csv(\"legislators-current.csv\")\ndataset = dataset.with_column(pl.col(\"birthday\").str.strptime(pl.Date))\nprint(dataset.head())\n\nshape: (5, 34)\n┌───────────┬────────────┬─────────────┬────────┬─────┬────────────────┬────────────────────┬──────────┬────────────────┐\n│ last_name ┆ first_name ┆ middle_name ┆ suffix ┆ ... ┆ ballotpedia_id ┆ washington_post_id ┆ icpsr_id ┆ wikipedia_id   │\n│ ---       ┆ ---        ┆ ---         ┆ ---    ┆     ┆ ---            ┆ ---                ┆ ---      ┆ ---            │\n│ str       ┆ str        ┆ str         ┆ str    ┆     ┆ str            ┆ str                ┆ i64      ┆ str            │\n╞═══════════╪════════════╪═════════════╪════════╪═════╪════════════════╪════════════════════╪══════════╪════════════════╡\n│ Brown     ┆ Sherrod    ┆ null        ┆ null   ┆ ... ┆ Sherrod Brown  ┆ null               ┆ 29389    ┆ Sherrod Brown  │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ Cantwell  ┆ Maria      ┆ null        ┆ null   ┆ ... ┆ Maria Cantwell ┆ null               ┆ 39310    ┆ Maria Cantwell │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ Cardin    ┆ Benjamin   ┆ L.          ┆ null   ┆ ... ┆ Ben Cardin     ┆ null               ┆ 15408    ┆ Ben Cardin     │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ Carper    ┆ Thomas     ┆ Richard     ┆ null   ┆ ... ┆ Tom Carper     ┆ null               ┆ 15015    ┆ Tom Carper     │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ Casey     ┆ Robert     ┆ P.          ┆ Jr.    ┆ ... ┆ Bob Casey, Jr. ┆ null               ┆ 40703    ┆ Bob Casey Jr.  │\n└───────────┴────────────┴─────────────┴────────┴─────┴────────────────┴────────────────────┴──────────┴────────────────┘\n\n\n\n\n\nPuede combinar fácilmente diferentes agregaciones agregando varias expresiones en una lista. No hay un límite superior en el número de agregaciones que puede hacer y puede hacer cualquier combinación que desee. En el fragmento a continuación, hacemos las siguientes agregaciones:\nPor grupo \"first_name\":\n\ncuente el número de filas en el grupo:\n\nforma abreviada: pl.count(\"party\")\nforma completa: pl.col(\"party\").count()\n\nagregue el grupo de valores de género a una lista:\n\nforma completa: pl.col(\"gender\").list()\n\nobtenga el primer valor de la columna \"last_name\" en el grupo:\n\nforma abreviada: pl.primero(\"last_name\")\nforma completa: pl.col(\"last_name\").first()\n\n\nAdemás de la agregación, clasificamos inmediatamente el resultado y lo limitamos a los 5 principales para que tengamos un buen resumen general.\n\nq = (\n    dataset.lazy()\n    .groupby(\"first_name\")\n    .agg(\n        [\n            pl.count(),\n            pl.col(\"gender\").list(),\n            pl.first(\"last_name\"),\n        ]\n    )\n    .sort(\"count\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 4)\n┌────────────┬───────┬─────────────────────┬───────────┐\n│ first_name ┆ count ┆ gender              ┆ last_name │\n│ ---        ┆ ---   ┆ ---                 ┆ ---       │\n│ str        ┆ u32   ┆ list [str]          ┆ str       │\n╞════════════╪═══════╪═════════════════════╪═══════════╡\n│ John       ┆ 19    ┆ [\"M\", \"M\", ... \"M\"] ┆ Barrasso  │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ Mike       ┆ 13    ┆ [\"M\", \"M\", ... \"M\"] ┆ Kelly     │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ Michael    ┆ 11    ┆ [\"M\", \"M\", ... \"M\"] ┆ Bennet    │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ David      ┆ 11    ┆ [\"M\", \"M\", ... \"M\"] ┆ Cicilline │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ James      ┆ 9     ┆ [\"M\", \"M\", ... \"M\"] ┆ Inhofe    │\n└────────────┴───────┴─────────────────────┴───────────┘\n\n\n\n\n\nOk, eso fue bastante fácil, ¿verdad? Subamos un nivel. Digamos que queremos saber cuántos delegados de un “estado” (state) son administración “Democrat” o “Republican”. Podríamos consultarlo directamente en la agregación sin la necesidad de lambda o arreglar el DataFrame.\n\nq = (\n    dataset.lazy()\n    .groupby(\"state\")\n    .agg(\n        [\n            (pl.col(\"party\") == \"Democrat\").sum().alias(\"demo\"),\n            (pl.col(\"party\") == \"Republican\").sum().alias(\"repu\"),\n        ]\n    )\n    .sort(\"demo\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 3)\n┌───────┬──────┬──────┐\n│ state ┆ demo ┆ repu │\n│ ---   ┆ ---  ┆ ---  │\n│ str   ┆ u32  ┆ u32  │\n╞═══════╪══════╪══════╡\n│ CA    ┆ 44   ┆ 10   │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤\n│ NY    ┆ 21   ┆ 8    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤\n│ IL    ┆ 15   ┆ 5    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤\n│ TX    ┆ 13   ┆ 25   │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤\n│ NJ    ┆ 12   ┆ 2    │\n└───────┴──────┴──────┘\n\n\nPor supuesto, también se podría hacer algo similar con un GROUPBY anidado, pero eso no me permitiría mostrar estas características agradables. 😉\n\nq = (\n    dataset.lazy()\n    .groupby([\"state\", \"party\"])\n    .agg([pl.count(\"party\").alias(\"count\")])\n    .filter((pl.col(\"party\") == \"Democrat\") | (pl.col(\"party\") == \"Republican\"))\n    .sort(\"count\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 3)\n┌───────┬────────────┬───────┐\n│ state ┆ party      ┆ count │\n│ ---   ┆ ---        ┆ ---   │\n│ str   ┆ str        ┆ u32   │\n╞═══════╪════════════╪═══════╡\n│ CA    ┆ Democrat   ┆ 44    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n│ TX    ┆ Republican ┆ 25    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n│ NY    ┆ Democrat   ┆ 21    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n│ FL    ┆ Republican ┆ 18    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n│ IL    ┆ Democrat   ┆ 15    │\n└───────┴────────────┴───────┘\n\n\n\n\n\nTambién podemos filtrar los grupos. Digamos que queremos calcular una media por grupo, pero no queremos incluir todos los valores de ese grupo y tampoco queremos filtrar las filas del DataFrame (porque necesitamos esas filas para otra agregación).\nEn el siguiente ejemplo, mostramos cómo se puede hacer eso. Tenga en cuenta que podemos hacer funciones de Python para mayor claridad. Estas funciones no nos cuestan nada. Esto se debe a que solo creamos Polars expression, no aplicamos una función personalizada sobre Series durante el tiempo de ejecución de la consulta.\n\nfrom datetime import date\n\ndef compute_age() -&gt; pl.Expr:\n    return date(2021, 1, 1).year - pl.col(\"birthday\").dt.year()\n\n\ndef avg_birthday(gender: str) -&gt; pl.Expr:\n    return compute_age().filter(pl.col(\"gender\") == gender).mean().alias(f\"avg {gender} birthday\")\n\n\nq = (\n    dataset.lazy()\n    .groupby([\"state\"])\n    .agg(\n        [\n            avg_birthday(\"M\"),\n            avg_birthday(\"F\"),\n            (pl.col(\"gender\") == \"M\").sum().alias(\"# male\"),\n            (pl.col(\"gender\") == \"F\").sum().alias(\"# female\"),\n        ]\n    )\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 5)\n┌───────┬────────────────┬────────────────┬────────┬──────────┐\n│ state ┆ avg M birthday ┆ avg F birthday ┆ # male ┆ # female │\n│ ---   ┆ ---            ┆ ---            ┆ ---    ┆ ---      │\n│ str   ┆ f64            ┆ f64            ┆ u32    ┆ u32      │\n╞═══════╪════════════════╪════════════════╪════════╪══════════╡\n│ MS    ┆ 60.0           ┆ 62.0           ┆ 5      ┆ 1        │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤\n│ NV    ┆ 55.5           ┆ 61.75          ┆ 2      ┆ 4        │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤\n│ KS    ┆ 54.2           ┆ 41.0           ┆ 5      ┆ 1        │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤\n│ IN    ┆ 55.0           ┆ 50.5           ┆ 9      ┆ 2        │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤\n│ IL    ┆ 60.923077      ┆ 58.428571      ┆ 13     ┆ 7        │\n└───────┴────────────────┴────────────────┴────────┴──────────┘\n\n\n\n\n\nA menudo veo que se ordena un DataFrame con el único propósito de ordenar durante la operación GROUPBY. Digamos que queremos obtener los nombres de los políticos más antiguos y más jóvenes (no es que todavía estén vivos) por estado, podríamos ORDENAR y AGRUPAR.\n\ndef get_person() -&gt; pl.Expr:\n    return pl.col(\"first_name\") + pl.lit(\" \") + pl.col(\"last_name\")\n\n\nq = (\n    dataset.lazy()\n    .sort(\"birthday\")\n    .groupby([\"state\"])\n    .agg(\n        [\n            get_person().first().alias(\"youngest\"),\n            get_person().last().alias(\"oldest\"),\n        ]\n    )\n    .limit(5)\n)\n\ndf = q.collect()\n\nprint(df)\n\nshape: (5, 3)\n┌───────┬──────────────────────────┬──────────────────────────┐\n│ state ┆ youngest                 ┆ oldest                   │\n│ ---   ┆ ---                      ┆ ---                      │\n│ str   ┆ str                      ┆ str                      │\n╞═══════╪══════════════════════════╪══════════════════════════╡\n│ PR    ┆ Jenniffer González-Colón ┆ Jenniffer González-Colón │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ ND    ┆ John Hoeven              ┆ Kelly Armstrong          │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ KY    ┆ Harold Rogers            ┆ Garland Barr             │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ NM    ┆ Teresa Leger Fernandez   ┆ Melanie Stansbury        │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ OR    ┆ Peter DeFazio            ┆ Jeff Merkley             │\n└───────┴──────────────────────────┴──────────────────────────┘\n\n\n\n\n\n\n\nPolars - User Guide\nPolars - Github"
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#introducción",
    "href": "posts/2022/2022-03-16-polars.html#introducción",
    "title": "Polars",
    "section": "",
    "text": "Polars es una librería de DataFrames increíblemente rápida implementada en Rust utilizando Arrow Columnar Format de Apache como modelo de memoria.\n\nLazy | eager execution\nMulti-threaded\nSIMD (Single Instruction, Multiple Data)\nQuery optimization\nPowerful expression API\nRust | Python\n\nEsta sección tiene como objetivos presentarle Polars a través de ejemplos y comparándolo con otras soluciones.\n\nNota: Si usted no esta familiarizado con la manipulación de datos en Python, se recomienda partir leyendo sobre la librería de Pandas. También, se deja como referencia mi curso de Manipulación de Datos."
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#primeros-pasos",
    "href": "posts/2022/2022-03-16-polars.html#primeros-pasos",
    "title": "Polars",
    "section": "",
    "text": "Para instalar Polars, necesitará usar la línea de comando. Si ha instalado Anaconda, puede usar:\nconda install -c conda-forge polars\nDe lo contrario, puede instalar con pip:\npip install polars\n\nNota: Todos los binarios están preconstruidos para Python v3.6+."
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#rendimiento",
    "href": "posts/2022/2022-03-16-polars.html#rendimiento",
    "title": "Polars",
    "section": "",
    "text": "Polars es muy rápido y, de hecho, es una de las mejores soluciones disponibles. Tomemos como referencia db-benchmark de h2oai. Esta página tiene como objetivo comparar varias herramientas similares a bases de datos populares en la ciencia de datos de código abierto. Se ejecuta regularmente con las últimas versiones de estos paquetes y se actualiza automáticamente.\nTambién se incluye la sintaxis que se cronometra junto con el tiempo. De esta manera, puede ver de inmediato si está realizando estas tareas o no, y si las diferencias de tiempo le importan o no. Una diferencia de 10x puede ser irrelevante si eso es solo 1s frente a 0,1s en el tamaño de sus datos.\nA modo de ejemplo, veamos algunos ejemplos de performances de distintas librerías para ejecutar distintos tipos de tareas sobre datasets con distintos tamaños. Para el caso de tareas básicas sobre un dataset de 50 GB, Polars supera a librerías espacializadas en distribución de Dataframes como Spark (143 segundos vs 568 segundos). Por otro lado, librerías conocidas en Python como Pandas o Dask se tiene el problema de out of memory."
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#expresiones-en-polars",
    "href": "posts/2022/2022-03-16-polars.html#expresiones-en-polars",
    "title": "Polars",
    "section": "",
    "text": "Polars tiene un poderoso concepto llamado expresiones. Las expresiones polares se pueden usar en varios contextos y son un mapeo funcional de Fn(Series) -&gt; Series, lo que significa que tienen Series como entrada y Series como salida. Al observar esta definición funcional, podemos ver que la salida de un Expr también puede servir como entrada de un Expr.\nEso puede sonar un poco extraño, así que vamos a dar un ejemplo.\nLa siguiente es una expresión:\npl.col(\"foo\").sort().head(2)\nEl fragmento anterior dice seleccionar la columna \"foo\", luego ordenar esta columna y luego tomar los primeros 2 valores de la salida ordenada. El poder de las expresiones es que cada expresión produce una nueva expresión y que se pueden canalizar juntas. Puede ejecutar una expresión pasándola en uno de los contextos de ejecución polares. Aquí ejecutamos dos expresiones ejecutando df.select:\ndf.select([\n     pl.col(\"foo\").sort().head(2),\n     pl.col(\"barra\").filter(pl.col(\"foo\") == 1).sum()\n])\nTodas las expresiones se ejecutan en paralelo. (Tenga en cuenta que dentro de una expresión puede haber más paralelización).\n\n\nEn esta sección veremos algunos ejemplos, pero primero vamos a crear un conjunto de datos:\n\nimport polars as pl\nimport numpy as np\n\n\nnp.random.seed(12)\n\ndf = pl.DataFrame(\n    {\n        \"nrs\": [1, 2, 3, None, 5],\n        \"names\": [\"foo\", \"ham\", \"spam\", \"egg\", None],\n        \"random\": np.random.rand(5),\n        \"groups\": [\"A\", \"A\", \"B\", \"C\", \"B\"],\n    }\n)\nprint(df)\n\nshape: (5, 4)\n┌──────┬───────┬──────────┬────────┐\n│ nrs  ┆ names ┆ random   ┆ groups │\n│ ---  ┆ ---   ┆ ---      ┆ ---    │\n│ i64  ┆ str   ┆ f64      ┆ str    │\n╞══════╪═══════╪══════════╪════════╡\n│ 1    ┆ foo   ┆ 0.154163 ┆ A      │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤\n│ 2    ┆ ham   ┆ 0.74     ┆ A      │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤\n│ 3    ┆ spam  ┆ 0.263315 ┆ B      │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤\n│ null ┆ egg   ┆ 0.533739 ┆ C      │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┤\n│ 5    ┆ null  ┆ 0.014575 ┆ B      │\n└──────┴───────┴──────────┴────────┘\n\n\nPuedes hacer mucho con las expresiones, veamos algunos ejemplos:\n\n\nPodemos contar los valores únicos en una columna. Tenga en cuenta que estamos creando el mismo resultado de diferentes maneras. Para no tener nombres de columna duplicados en el DataFrame, usamos una expresión de alias, que cambia el nombre de una expresión.\n\nout = df.select(\n    [\n        pl.col(\"names\").n_unique().alias(\"unique_names_1\"),\n        pl.col(\"names\").unique().count().alias(\"unique_names_2\"),\n    ]\n)\nprint(out)\n\nshape: (1, 2)\n┌────────────────┬────────────────┐\n│ unique_names_1 ┆ unique_names_2 │\n│ ---            ┆ ---            │\n│ u32            ┆ u32            │\n╞════════════════╪════════════════╡\n│ 5              ┆ 5              │\n└────────────────┴────────────────┘\n\n\n\n\n\n\nPodemos hacer varias agregaciones. A continuación mostramos algunas de ellas, pero hay más, como median, mean, first, etc.\n\nout = df.select(\n    [\n        pl.sum(\"random\").alias(\"sum\"),\n        pl.min(\"random\").alias(\"min\"),\n        pl.max(\"random\").alias(\"max\"),\n        pl.col(\"random\").max().alias(\"other_max\"),\n        pl.std(\"random\").alias(\"std dev\"),\n        pl.var(\"random\").alias(\"variance\"),\n    ]\n)\nprint(out)\n\nshape: (1, 6)\n┌──────────┬──────────┬──────┬───────────┬──────────┬──────────┐\n│ sum      ┆ min      ┆ max  ┆ other_max ┆ std dev  ┆ variance │\n│ ---      ┆ ---      ┆ ---  ┆ ---       ┆ ---      ┆ ---      │\n│ f64      ┆ f64      ┆ f64  ┆ f64       ┆ f64      ┆ f64      │\n╞══════════╪══════════╪══════╪═══════════╪══════════╪══════════╡\n│ 1.705842 ┆ 0.014575 ┆ 0.74 ┆ 0.74      ┆ 0.293209 ┆ 0.085971 │\n└──────────┴──────────┴──────┴───────────┴──────────┴──────────┘\n\n\n\n\n\nTambién podemos hacer cosas bastante complejas. En el siguiente fragmento, contamos todos los nombres que terminan con la cadena \"am\".\n\nout = df.select(\n    [\n        pl.col(\"names\").filter(pl.col(\"names\").str.contains(r\"am$\")).count(),\n    ]\n)\nprint(out)\n\nshape: (1, 1)\n┌───────┐\n│ names │\n│ ---   │\n│ u32   │\n╞═══════╡\n│ 2     │\n└───────┘\n\n\n\n\n\nEn el ejemplo a continuación, usamos un condicional para crear una nueva expresión when -&gt; then -&gt; otherwise.\nLa función when() requiere una expresión de predicado (y, por lo tanto, conduce a una serie booleana), luego espera una expresión que se usará en caso de que el predicado se evalúe como verdadero y, de lo contrario, espera una expresión que se usará en caso de que el predicado se evalúe.\nTenga en cuenta que puede pasar cualquier expresión, o simplemente expresiones base como pl.col(\"foo\"), pl.lit(3), pl.lit(\"bar\"), etc.\nFinalmente, multiplicamos esto con el resultado de una expresión de suma.\n\nout = df.select(\n    [\n        pl.when(pl.col(\"random\") &gt; 0.5).then(0).otherwise(pl.col(\"random\")) * pl.sum(\"nrs\"),\n    ]\n)\nprint(out)\n\nshape: (5, 1)\n┌──────────┐\n│ literal  │\n│ ---      │\n│ f64      │\n╞══════════╡\n│ 1.695791 │\n├╌╌╌╌╌╌╌╌╌╌┤\n│ 0.0      │\n├╌╌╌╌╌╌╌╌╌╌┤\n│ 2.896465 │\n├╌╌╌╌╌╌╌╌╌╌┤\n│ 0.0      │\n├╌╌╌╌╌╌╌╌╌╌┤\n│ 0.160325 │\n└──────────┘\n\n\n\n\n\nUna expresión polar también puede hacer un GROUPBY, AGGREGATION y JOIN implícitos en una sola expresión.\nEn los ejemplos a continuación, hacemos un GROUPBY sobre \"groups\" y AGREGATE SUM de \"random\", y en la siguiente expresión GROUPBY OVER \"names\" y AGREGATE una lista de \"random\". Estas funciones de ventana se pueden combinar con otras expresiones y son una forma eficaz de determinar estadísticas de grupo. Vea más expresiones en el siguiente link.\n\nout = df[\n    [\n        pl.col(\"*\"),  # select all\n        pl.col(\"random\").sum().over(\"groups\").alias(\"sum[random]/groups\"),\n        pl.col(\"random\").list().over(\"names\").alias(\"random/name\"),\n    ]\n]\nprint(out)\n\nshape: (5, 6)\n┌──────┬───────┬──────────┬────────┬────────────────────┬─────────────┐\n│ nrs  ┆ names ┆ random   ┆ groups ┆ sum[random]/groups ┆ random/name │\n│ ---  ┆ ---   ┆ ---      ┆ ---    ┆ ---                ┆ ---         │\n│ i64  ┆ str   ┆ f64      ┆ str    ┆ f64                ┆ list [f64]  │\n╞══════╪═══════╪══════════╪════════╪════════════════════╪═════════════╡\n│ 1    ┆ foo   ┆ 0.154163 ┆ A      ┆ 0.894213           ┆ [0.154163]  │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ 2    ┆ ham   ┆ 0.74     ┆ A      ┆ 0.894213           ┆ [0.74]      │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ 3    ┆ spam  ┆ 0.263315 ┆ B      ┆ 0.2778             ┆ [0.263315]  │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ null ┆ egg   ┆ 0.533739 ┆ C      ┆ 0.533739           ┆ [0.533739]  │\n├╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ 5    ┆ null  ┆ 0.014575 ┆ B      ┆ 0.2778             ┆ [0.014575]  │\n└──────┴───────┴──────────┴────────┴────────────────────┴─────────────┘"
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#groupby",
    "href": "posts/2022/2022-03-16-polars.html#groupby",
    "title": "Polars",
    "section": "",
    "text": "Una de las formas más eficientes de procesar datos tabulares es paralelizar su procesamiento a través del enfoque “dividir-aplicar-combinar”. Esta operación es el núcleo de la implementación del agrupamiento de Polars, lo que le permite lograr operaciones ultrarrápidas. Más específicamente, las fases de “división” y “aplicación” se ejecutan de forma multiproceso.\nUna operación de agrupación simple se toma a continuación como ejemplo para ilustrar este enfoque:\n\nPara las operaciones hash realizadas durante la fase de “división”, Polars utiliza un enfoque sin bloqueo de subprocesos múltiples que se ilustra en el siguiente esquema:\n\n¡Esta paralelización permite que las operaciones de agrupación y unión (por ejemplo) sean increíblemente rápidas!\n\n\n\nTodos hemos escuchado que Python es lento y “no escala”. Además de la sobrecarga de ejecutar el código de bytes “lento”, Python debe permanecer dentro de las restricciones del Global interpreter lock (GIL). Esto significa que si se usa la operación lambda o una función de Python personalizada para aplicar durante una fase de paralelización, la velocidad de Polars se limita al ejecutar el código de Python, lo que evita que varios subprocesos ejecuten la función.\nTodo esto se siente terriblemente limitante, especialmente porque a menudo necesitamos esos lambda en un paso .groupby(), por ejemplo. Este enfoque aún es compatible con Polars, pero teniendo en cuenta el código de bytes Y el precio GIL deben pagarse.\nPara mitigar esto, Polars implementa una poderosa sintaxis definida no solo en su lazy, sino también en su uso eager.\n\n\n\nEn la introducción de la página anterior, discutimos que el uso de funciones personalizadas de Python eliminaba la paralelización y que podemos usar las expresiones de la API diferida para mitigar esto. Echemos un vistazo a lo que eso significa.\nComencemos con el conjunto de datos simple del congreso de EE. UU.\n\nimport polars as pl\n\ndataset = pl.read_csv(\"legislators-current.csv\")\ndataset = dataset.with_column(pl.col(\"birthday\").str.strptime(pl.Date))\nprint(dataset.head())\n\nshape: (5, 34)\n┌───────────┬────────────┬─────────────┬────────┬─────┬────────────────┬────────────────────┬──────────┬────────────────┐\n│ last_name ┆ first_name ┆ middle_name ┆ suffix ┆ ... ┆ ballotpedia_id ┆ washington_post_id ┆ icpsr_id ┆ wikipedia_id   │\n│ ---       ┆ ---        ┆ ---         ┆ ---    ┆     ┆ ---            ┆ ---                ┆ ---      ┆ ---            │\n│ str       ┆ str        ┆ str         ┆ str    ┆     ┆ str            ┆ str                ┆ i64      ┆ str            │\n╞═══════════╪════════════╪═════════════╪════════╪═════╪════════════════╪════════════════════╪══════════╪════════════════╡\n│ Brown     ┆ Sherrod    ┆ null        ┆ null   ┆ ... ┆ Sherrod Brown  ┆ null               ┆ 29389    ┆ Sherrod Brown  │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ Cantwell  ┆ Maria      ┆ null        ┆ null   ┆ ... ┆ Maria Cantwell ┆ null               ┆ 39310    ┆ Maria Cantwell │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ Cardin    ┆ Benjamin   ┆ L.          ┆ null   ┆ ... ┆ Ben Cardin     ┆ null               ┆ 15408    ┆ Ben Cardin     │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ Carper    ┆ Thomas     ┆ Richard     ┆ null   ┆ ... ┆ Tom Carper     ┆ null               ┆ 15015    ┆ Tom Carper     │\n├╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ Casey     ┆ Robert     ┆ P.          ┆ Jr.    ┆ ... ┆ Bob Casey, Jr. ┆ null               ┆ 40703    ┆ Bob Casey Jr.  │\n└───────────┴────────────┴─────────────┴────────┴─────┴────────────────┴────────────────────┴──────────┴────────────────┘\n\n\n\n\n\nPuede combinar fácilmente diferentes agregaciones agregando varias expresiones en una lista. No hay un límite superior en el número de agregaciones que puede hacer y puede hacer cualquier combinación que desee. En el fragmento a continuación, hacemos las siguientes agregaciones:\nPor grupo \"first_name\":\n\ncuente el número de filas en el grupo:\n\nforma abreviada: pl.count(\"party\")\nforma completa: pl.col(\"party\").count()\n\nagregue el grupo de valores de género a una lista:\n\nforma completa: pl.col(\"gender\").list()\n\nobtenga el primer valor de la columna \"last_name\" en el grupo:\n\nforma abreviada: pl.primero(\"last_name\")\nforma completa: pl.col(\"last_name\").first()\n\n\nAdemás de la agregación, clasificamos inmediatamente el resultado y lo limitamos a los 5 principales para que tengamos un buen resumen general.\n\nq = (\n    dataset.lazy()\n    .groupby(\"first_name\")\n    .agg(\n        [\n            pl.count(),\n            pl.col(\"gender\").list(),\n            pl.first(\"last_name\"),\n        ]\n    )\n    .sort(\"count\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 4)\n┌────────────┬───────┬─────────────────────┬───────────┐\n│ first_name ┆ count ┆ gender              ┆ last_name │\n│ ---        ┆ ---   ┆ ---                 ┆ ---       │\n│ str        ┆ u32   ┆ list [str]          ┆ str       │\n╞════════════╪═══════╪═════════════════════╪═══════════╡\n│ John       ┆ 19    ┆ [\"M\", \"M\", ... \"M\"] ┆ Barrasso  │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ Mike       ┆ 13    ┆ [\"M\", \"M\", ... \"M\"] ┆ Kelly     │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ Michael    ┆ 11    ┆ [\"M\", \"M\", ... \"M\"] ┆ Bennet    │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ David      ┆ 11    ┆ [\"M\", \"M\", ... \"M\"] ┆ Cicilline │\n├╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┤\n│ James      ┆ 9     ┆ [\"M\", \"M\", ... \"M\"] ┆ Inhofe    │\n└────────────┴───────┴─────────────────────┴───────────┘\n\n\n\n\n\nOk, eso fue bastante fácil, ¿verdad? Subamos un nivel. Digamos que queremos saber cuántos delegados de un “estado” (state) son administración “Democrat” o “Republican”. Podríamos consultarlo directamente en la agregación sin la necesidad de lambda o arreglar el DataFrame.\n\nq = (\n    dataset.lazy()\n    .groupby(\"state\")\n    .agg(\n        [\n            (pl.col(\"party\") == \"Democrat\").sum().alias(\"demo\"),\n            (pl.col(\"party\") == \"Republican\").sum().alias(\"repu\"),\n        ]\n    )\n    .sort(\"demo\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 3)\n┌───────┬──────┬──────┐\n│ state ┆ demo ┆ repu │\n│ ---   ┆ ---  ┆ ---  │\n│ str   ┆ u32  ┆ u32  │\n╞═══════╪══════╪══════╡\n│ CA    ┆ 44   ┆ 10   │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤\n│ NY    ┆ 21   ┆ 8    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤\n│ IL    ┆ 15   ┆ 5    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤\n│ TX    ┆ 13   ┆ 25   │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┤\n│ NJ    ┆ 12   ┆ 2    │\n└───────┴──────┴──────┘\n\n\nPor supuesto, también se podría hacer algo similar con un GROUPBY anidado, pero eso no me permitiría mostrar estas características agradables. 😉\n\nq = (\n    dataset.lazy()\n    .groupby([\"state\", \"party\"])\n    .agg([pl.count(\"party\").alias(\"count\")])\n    .filter((pl.col(\"party\") == \"Democrat\") | (pl.col(\"party\") == \"Republican\"))\n    .sort(\"count\", reverse=True)\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 3)\n┌───────┬────────────┬───────┐\n│ state ┆ party      ┆ count │\n│ ---   ┆ ---        ┆ ---   │\n│ str   ┆ str        ┆ u32   │\n╞═══════╪════════════╪═══════╡\n│ CA    ┆ Democrat   ┆ 44    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n│ TX    ┆ Republican ┆ 25    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n│ NY    ┆ Democrat   ┆ 21    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n│ FL    ┆ Republican ┆ 18    │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n│ IL    ┆ Democrat   ┆ 15    │\n└───────┴────────────┴───────┘\n\n\n\n\n\nTambién podemos filtrar los grupos. Digamos que queremos calcular una media por grupo, pero no queremos incluir todos los valores de ese grupo y tampoco queremos filtrar las filas del DataFrame (porque necesitamos esas filas para otra agregación).\nEn el siguiente ejemplo, mostramos cómo se puede hacer eso. Tenga en cuenta que podemos hacer funciones de Python para mayor claridad. Estas funciones no nos cuestan nada. Esto se debe a que solo creamos Polars expression, no aplicamos una función personalizada sobre Series durante el tiempo de ejecución de la consulta.\n\nfrom datetime import date\n\ndef compute_age() -&gt; pl.Expr:\n    return date(2021, 1, 1).year - pl.col(\"birthday\").dt.year()\n\n\ndef avg_birthday(gender: str) -&gt; pl.Expr:\n    return compute_age().filter(pl.col(\"gender\") == gender).mean().alias(f\"avg {gender} birthday\")\n\n\nq = (\n    dataset.lazy()\n    .groupby([\"state\"])\n    .agg(\n        [\n            avg_birthday(\"M\"),\n            avg_birthday(\"F\"),\n            (pl.col(\"gender\") == \"M\").sum().alias(\"# male\"),\n            (pl.col(\"gender\") == \"F\").sum().alias(\"# female\"),\n        ]\n    )\n    .limit(5)\n)\n\ndf = q.collect()\nprint(df)\n\nshape: (5, 5)\n┌───────┬────────────────┬────────────────┬────────┬──────────┐\n│ state ┆ avg M birthday ┆ avg F birthday ┆ # male ┆ # female │\n│ ---   ┆ ---            ┆ ---            ┆ ---    ┆ ---      │\n│ str   ┆ f64            ┆ f64            ┆ u32    ┆ u32      │\n╞═══════╪════════════════╪════════════════╪════════╪══════════╡\n│ MS    ┆ 60.0           ┆ 62.0           ┆ 5      ┆ 1        │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤\n│ NV    ┆ 55.5           ┆ 61.75          ┆ 2      ┆ 4        │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤\n│ KS    ┆ 54.2           ┆ 41.0           ┆ 5      ┆ 1        │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤\n│ IN    ┆ 55.0           ┆ 50.5           ┆ 9      ┆ 2        │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┤\n│ IL    ┆ 60.923077      ┆ 58.428571      ┆ 13     ┆ 7        │\n└───────┴────────────────┴────────────────┴────────┴──────────┘\n\n\n\n\n\nA menudo veo que se ordena un DataFrame con el único propósito de ordenar durante la operación GROUPBY. Digamos que queremos obtener los nombres de los políticos más antiguos y más jóvenes (no es que todavía estén vivos) por estado, podríamos ORDENAR y AGRUPAR.\n\ndef get_person() -&gt; pl.Expr:\n    return pl.col(\"first_name\") + pl.lit(\" \") + pl.col(\"last_name\")\n\n\nq = (\n    dataset.lazy()\n    .sort(\"birthday\")\n    .groupby([\"state\"])\n    .agg(\n        [\n            get_person().first().alias(\"youngest\"),\n            get_person().last().alias(\"oldest\"),\n        ]\n    )\n    .limit(5)\n)\n\ndf = q.collect()\n\nprint(df)\n\nshape: (5, 3)\n┌───────┬──────────────────────────┬──────────────────────────┐\n│ state ┆ youngest                 ┆ oldest                   │\n│ ---   ┆ ---                      ┆ ---                      │\n│ str   ┆ str                      ┆ str                      │\n╞═══════╪══════════════════════════╪══════════════════════════╡\n│ PR    ┆ Jenniffer González-Colón ┆ Jenniffer González-Colón │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ ND    ┆ John Hoeven              ┆ Kelly Armstrong          │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ KY    ┆ Harold Rogers            ┆ Garland Barr             │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ NM    ┆ Teresa Leger Fernandez   ┆ Melanie Stansbury        │\n├╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n│ OR    ┆ Peter DeFazio            ┆ Jeff Merkley             │\n└───────┴──────────────────────────┴──────────────────────────┘"
  },
  {
    "objectID": "posts/2022/2022-03-16-polars.html#referencias",
    "href": "posts/2022/2022-03-16-polars.html#referencias",
    "title": "Polars",
    "section": "",
    "text": "Polars - User Guide\nPolars - Github"
  }
]